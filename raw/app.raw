2017-04-05 15:55:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:55:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:55:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 85, so the initial offset will be set to 84
2017-04-05 15:55:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 95, so the initial offset will be set to 94
2017-04-05 15:57:47 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 15:57:47 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 15:57:48 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 15:57:48 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 15:57:48 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 15:57:48 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-2dd707bb-718a-4a27-873f-b2c1648c6436
2017-04-05 15:57:48 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:64705 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 15:57:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 15:57:48 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 15:57:48 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 15:57:48 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 15:57:48 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 15:57:48 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 15:57:48 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 15:57:48 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1778952782] - leader session null
2017-04-05 15:57:48 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 15:57:48 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 15:57:48 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-97e591b8-10f1-4b61-8227-649e660c7c0c for spill files.
2017-04-05 15:57:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 15:57:48 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-7c45b5ad-32be-40ac-ad5d-297d033f048a
2017-04-05 15:57:48 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1678007449.
2017-04-05 15:57:48 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='70b87e6646d04232b20a64ef604f3820'} @ localhost (dataPort=-1)
2017-04-05 15:57:48 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 15:57:48 INFO  TaskManager:128 - Memory usage stats: [HEAP: 170/900/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 15:57:48 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 15:57:48 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='70b87e6646d04232b20a64ef604f3820'} has started.
2017-04-05 15:57:48 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 7ea307380c4214c4cbed35eb6bd9d87d. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 15:57:48 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 15:57:48 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:64705. Starting BLOB cache.
2017-04-05 15:57:48 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-a5b556b7-fc5a-499d-98e2-88cc6f193f96
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 7663066bd03232a5929a207dbaf9b24a)) but there is no connection to a JobManager yet.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a).
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1778952782].
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1778952782]
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a) and wait for progress
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  JobManager:128 - Submitting job 7663066bd03232a5929a207dbaf9b24a (Flink Streaming Job).
2017-04-05 15:57:48 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 7663066bd03232a5929a207dbaf9b24a.
2017-04-05 15:57:49 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a).
2017-04-05 15:57:49 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:111 - Job 7663066bd03232a5929a207dbaf9b24a was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 15:57:49 INFO  JobManager:128 - Scheduling job 7663066bd03232a5929a207dbaf9b24a (Flink Streaming Job).
2017-04-05 15:57:49 INFO  ExecutionGraph:965 - Job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a) switched from state CREATED to RUNNING.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:275 - 04/05/2017 15:57:49	Job execution switched to status RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1dfc6136 for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) [DEPLOYING].
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25414767 for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3a53065d for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) [DEPLOYING].
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4853eb2b for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3055f5ab for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@47b83ae3 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1cc3cc for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5341a594 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:57:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:57:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 85, so the initial offset will be set to 84
2017-04-05 15:57:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 96, so the initial offset will be set to 95
2017-04-05 16:58:59 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 16:58:59 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 16:59:00 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 16:59:00 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 16:59:01 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 16:59:01 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-d3e51685-1ff7-4d75-b03c-8d93a38969a7
2017-04-05 16:59:01 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65402 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 16:59:01 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 16:59:01 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 16:59:01 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 16:59:01 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 16:59:01 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 16:59:01 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 16:59:01 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 16:59:01 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-165705821] - leader session null
2017-04-05 16:59:01 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 16:59:01 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 16:59:01 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-02e4d31c-c858-42ae-bae5-bf6c5674173d for spill files.
2017-04-05 16:59:01 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 16:59:01 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-2418aa15-57ea-47aa-bee8-05c60c919d5a
2017-04-05 16:59:01 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1195441776.
2017-04-05 16:59:01 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='149829834498fbef35cd416fe5c676e7'} @ localhost (dataPort=-1)
2017-04-05 16:59:01 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 16:59:01 INFO  TaskManager:128 - Memory usage stats: [HEAP: 170/832/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 16:59:01 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 16:59:01 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='149829834498fbef35cd416fe5c676e7'} has started.
2017-04-05 16:59:01 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 2b3dfc15d5eb627557ad4562a9539566. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 16:59:01 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 16:59:01 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65402. Starting BLOB cache.
2017-04-05 16:59:01 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-de19550f-5152-41b8-a432-a355b1485594
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 4747ae356cddee0d014e003fa89639c1)) but there is no connection to a JobManager yet.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1).
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-165705821].
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-165705821]
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1) and wait for progress
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  JobManager:128 - Submitting job 4747ae356cddee0d014e003fa89639c1 (Flink Streaming Job).
2017-04-05 16:59:01 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 4747ae356cddee0d014e003fa89639c1.
2017-04-05 16:59:01 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1).
2017-04-05 16:59:01 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:111 - Job 4747ae356cddee0d014e003fa89639c1 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 16:59:01 INFO  JobManager:128 - Scheduling job 4747ae356cddee0d014e003fa89639c1 (Flink Streaming Job).
2017-04-05 16:59:01 INFO  ExecutionGraph:965 - Job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1) switched from state CREATED to RUNNING.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:275 - 04/05/2017 16:59:01	Job execution switched to status RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6051f97 for Source: Custom Source -> Map (1/4)
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@365669bf for Source: Custom Source -> Map (2/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e586fe2 for Source: Custom Source -> Map (3/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@190b4dc for Source: Custom Source -> Map (4/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@76652bd1 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@18e8ee85 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@727cc153 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@707f6dbf for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 16:59:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 16:59:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 85, so the initial offset will be set to 84
2017-04-05 16:59:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 97, so the initial offset will be set to 96
2017-04-05 17:09:50 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:09:51 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:09:51 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:09:51 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:09:52 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:09:52 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-b3637273-1ea1-4416-a85f-e84908317d1a
2017-04-05 17:09:52 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65451 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:09:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:09:52 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:09:52 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:09:52 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:09:52 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:09:52 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:09:52 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:09:52 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#125829115] - leader session null
2017-04-05 17:09:52 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:09:52 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:09:52 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-69df1e56-4ae5-4624-8fcb-65db265cc071 for spill files.
2017-04-05 17:09:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:09:52 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-52d3e188-cd57-4273-9c2a-193f943f4bdc
2017-04-05 17:09:52 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1711511985.
2017-04-05 17:09:52 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='e30227376a4c352ca4df04703d1fccd0'} @ localhost (dataPort=-1)
2017-04-05 17:09:52 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:09:52 INFO  TaskManager:128 - Memory usage stats: [HEAP: 176/828/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 17:09:52 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:09:52 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='e30227376a4c352ca4df04703d1fccd0'} has started.
2017-04-05 17:09:52 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 20b3daa537469f3874426f529cc9ddeb. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:09:52 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:09:52 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65451. Starting BLOB cache.
2017-04-05 17:09:52 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-ccc137ec-a044-4a39-821b-ab052dd0aa66
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 9b4a51226fe166899574ab9259d8c728)) but there is no connection to a JobManager yet.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728).
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#125829115].
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#125829115]
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728) and wait for progress
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  JobManager:128 - Submitting job 9b4a51226fe166899574ab9259d8c728 (Flink Streaming Job).
2017-04-05 17:09:52 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 9b4a51226fe166899574ab9259d8c728.
2017-04-05 17:09:52 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728).
2017-04-05 17:09:52 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:111 - Job 9b4a51226fe166899574ab9259d8c728 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:09:52 INFO  JobManager:128 - Scheduling job 9b4a51226fe166899574ab9259d8c728 (Flink Streaming Job).
2017-04-05 17:09:52 INFO  ExecutionGraph:965 - Job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728) switched from state CREATED to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:09:52	Job execution switched to status RUNNING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@28d7e9e0 for Source: Custom Source -> Map (1/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) [DEPLOYING].
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@18058b10 for Source: Custom Source -> Map (3/4)
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@418ed92b for Source: Custom Source -> Map (4/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) [DEPLOYING].
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@142f6a01 for Source: Custom Source -> Map (2/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) [DEPLOYING].
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7747fd84 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) [DEPLOYING].
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@27550ee7 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) [DEPLOYING].
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@286c8f79 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) [DEPLOYING].
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7d56c15b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:09:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:09:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 100, so the initial offset will be set to 99
2017-04-05 17:09:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 93, so the initial offset will be set to 92
2017-04-05 17:14:01 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:14:07 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:14:08 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:14:08 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:14:08 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:14:08 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c358b0e4-01bb-4269-991e-9cff855f0fc2
2017-04-05 17:14:08 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65477 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:14:08 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:14:08 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:14:08 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:14:08 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:14:08 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:14:08 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:14:08 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:14:08 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:14:08 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-750048606] - leader session null
2017-04-05 17:14:08 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:14:08 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:14:08 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-30ddb3bc-70a1-4789-8d41-ab4763e9793b for spill files.
2017-04-05 17:14:08 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:14:09 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-8da80d2d-0a2e-4380-988d-e87217505ad2
2017-04-05 17:14:09 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#538401304.
2017-04-05 17:14:09 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='43bd2350995c7b98ca2c33bebe5c1b53'} @ localhost (dataPort=-1)
2017-04-05 17:14:09 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:14:09 INFO  TaskManager:128 - Memory usage stats: [HEAP: 178/879/910 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-05 17:14:09 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:14:09 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='43bd2350995c7b98ca2c33bebe5c1b53'} has started.
2017-04-05 17:14:09 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as cafce6f8351c2614190d4d083354e1a1. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:14:09 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:14:09 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65477. Starting BLOB cache.
2017-04-05 17:14:09 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-98cec4d0-c5aa-443d-b14d-bf355b465ef5
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 3e497f9d8e1b7d202ab67ee137787acd)) but there is no connection to a JobManager yet.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd).
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-750048606].
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-750048606]
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd) and wait for progress
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:14:09 INFO  JobManager:128 - Submitting job 3e497f9d8e1b7d202ab67ee137787acd (Flink Streaming Job).
2017-04-05 17:14:09 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 3e497f9d8e1b7d202ab67ee137787acd.
2017-04-05 17:14:09 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd).
2017-04-05 17:14:09 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:111 - Job 3e497f9d8e1b7d202ab67ee137787acd was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:14:09 INFO  JobManager:128 - Scheduling job 3e497f9d8e1b7d202ab67ee137787acd (Flink Streaming Job).
2017-04-05 17:14:09 INFO  ExecutionGraph:965 - Job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd) switched from state CREATED to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:14:09	Job execution switched to status RUNNING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4c1b341f for Source: Custom Source -> Map (1/4)
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@e777874 for Source: Custom Source -> Map (2/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) [DEPLOYING].
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21464451 for Source: Custom Source -> Map (3/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@34c219c9 for Source: Custom Source -> Map (4/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4300ea74 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) [DEPLOYING].
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@40a2ac44 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@61ea7ba4 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@674a2c68 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:14:10 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:14:10 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 103, so the initial offset will be set to 102
2017-04-05 17:14:10 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 93, so the initial offset will be set to 92
2017-04-05 17:32:37 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:32:37 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:32:38 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:32:38 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:32:39 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:32:39 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-eaa07766-8911-4e7d-b448-060e04d4bf7a
2017-04-05 17:32:39 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49212 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:32:39 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:32:39 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:32:39 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:32:39 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:32:39 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:32:39 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:32:39 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:32:39 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1144756162] - leader session null
2017-04-05 17:32:40 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:32:40 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:32:40 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:32:40 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-4e0eb67e-0163-4d46-8c9c-b4958838aa9d for spill files.
2017-04-05 17:32:40 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:32:40 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-7148ea02-9b59-4bfb-9bbe-3c90dfedab2a
2017-04-05 17:32:40 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#582981956.
2017-04-05 17:32:40 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='23fe96635c7078d8f67c91f2315ea448'} @ localhost (dataPort=-1)
2017-04-05 17:32:40 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:32:40 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/841/910 MB, NON HEAP: 125/129/-1 MB (used/committed/max)]
2017-04-05 17:32:40 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:32:40 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='23fe96635c7078d8f67c91f2315ea448'} has started.
2017-04-05 17:32:40 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 466e62c38d91a32e6c20c6e639e09187. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:32:40 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:32:40 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49212. Starting BLOB cache.
2017-04-05 17:32:40 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6ca15e72-471a-4b2c-9ba3-da4915ccef59
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 7d52f0f4f523317ac118d6ec881dd269)) but there is no connection to a JobManager yet.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269).
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1144756162].
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1144756162]
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269) and wait for progress
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:32:40 INFO  JobManager:128 - Submitting job 7d52f0f4f523317ac118d6ec881dd269 (Flink Streaming Job).
2017-04-05 17:32:40 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 7d52f0f4f523317ac118d6ec881dd269.
2017-04-05 17:32:40 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269).
2017-04-05 17:32:40 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:111 - Job 7d52f0f4f523317ac118d6ec881dd269 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:32:40 INFO  JobManager:128 - Scheduling job 7d52f0f4f523317ac118d6ec881dd269 (Flink Streaming Job).
2017-04-05 17:32:40 INFO  ExecutionGraph:965 - Job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269) switched from state CREATED to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:32:40	Job execution switched to status RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4c1d0c93 for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) [DEPLOYING].
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4f34e8d3 for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5660560d for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@61edd45a for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@658cfaf9 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e417713 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3f40409d for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) [DEPLOYING].
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3fc60ecf for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:32:41 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:32:42 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 104, so the initial offset will be set to 103
2017-04-05 17:32:42 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 95, so the initial offset will be set to 94
2017-04-05 17:54:18 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:54:19 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:54:19 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:54:19 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:54:20 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:54:20 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-a4f092d1-9c83-41da-a4ab-279a7afd2039
2017-04-05 17:54:20 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49307 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:54:20 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:54:20 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:54:20 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:54:20 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:54:20 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:54:20 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:54:20 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-537810066] - leader session null
2017-04-05 17:54:20 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:54:20 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:54:20 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:54:20 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1e55bd35-cb36-4287-a438-7a0b8991ceb3 for spill files.
2017-04-05 17:54:20 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:54:20 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-af374586-15ce-435a-a257-3f9087ceddfb
2017-04-05 17:54:20 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-853602967.
2017-04-05 17:54:20 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='229944996b8c35fca86228f3a6f75d58'} @ localhost (dataPort=-1)
2017-04-05 17:54:20 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:54:20 INFO  TaskManager:128 - Memory usage stats: [HEAP: 174/860/910 MB, NON HEAP: 125/129/-1 MB (used/committed/max)]
2017-04-05 17:54:20 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:54:20 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='229944996b8c35fca86228f3a6f75d58'} has started.
2017-04-05 17:54:20 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 6721e9dfac2db6e41e13af0048dafb73. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:54:20 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:54:20 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49307. Starting BLOB cache.
2017-04-05 17:54:20 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-9e93bdde-88ea-4e90-960f-c4d2971a2174
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 2bba1cec7b12ec92a1b967c7c86ad0d7)) but there is no connection to a JobManager yet.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7).
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-537810066].
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-537810066]
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) and wait for progress
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  JobManager:128 - Submitting job 2bba1cec7b12ec92a1b967c7c86ad0d7 (Flink Streaming Job).
2017-04-05 17:54:20 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 2bba1cec7b12ec92a1b967c7c86ad0d7.
2017-04-05 17:54:20 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7).
2017-04-05 17:54:20 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:111 - Job 2bba1cec7b12ec92a1b967c7c86ad0d7 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:54:20 INFO  JobManager:128 - Scheduling job 2bba1cec7b12ec92a1b967c7c86ad0d7 (Flink Streaming Job).
2017-04-05 17:54:20 INFO  ExecutionGraph:965 - Job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) switched from state CREATED to RUNNING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:54:20	Job execution switched to status RUNNING.
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21464451 for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@12a6816c for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) [DEPLOYING].
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@12dc0b76 for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1594b3e2 for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:20 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:20 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7c3e52c5 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@28edad46 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) [DEPLOYING].
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@32ebc724 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2a96c10b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:54:21 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:54:21 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 106, so the initial offset will be set to 105
2017-04-05 17:54:21 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 97, so the initial offset will be set to 96
2017-04-05 17:54:30 INFO  Task:875 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from RUNNING to FAILED.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (d4df409c6a75bd48f0539d493afca953)
2017-04-05 17:54:30 INFO  ExecutionGraph:1027 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from RUNNING to FAILED.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  ExecutionGraph:965 - Job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) switched from state RUNNING to FAILING.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to FAILED 
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:280 - 04/05/2017 17:54:30	Job execution switched to status FAILING.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076).
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  TaskManager:128 - Discarding the results produced by task execution d4df409c6a75bd48f0539d493afca953
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2).
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (090a3afa2372967bd630884ffd158076)
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2).
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734).
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (b4676fb77e2bb01b68357ad7fe862aca)
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (b2763d111246a28b4f694751137856a7)
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (c22292e8b8bf8dc76611ae5ebb25c904)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (0891ebde647479dcb0c25158ebecc734)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (6c6ddbb5ce9cd9ffdd1ab439a77565e2)
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (b33e2c0b47173fa65d7c6584307a3e22)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) if no longer possible.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:965 - Job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) switched from state FAILING to FAILED.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:54:30	Job execution switched to status FAILED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#-537810066].
2017-04-05 17:54:30 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) because the restart strategy prevented it.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job 2bba1cec7b12ec92a1b967c7c86ad0d7
2017-04-05 17:54:30 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-05 17:54:30 INFO  JobClient:320 - Job execution failed
2017-04-05 17:54:30 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-05 17:54:30 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#-853602967.
2017-04-05 17:54:30 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-05 17:54:30 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:54:30 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-05 17:54:30 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:49307
2017-04-05 17:54:30 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1e55bd35-cb36-4287-a438-7a0b8991ceb3
2017-04-05 17:54:30 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-05 17:54:30 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-05 18:08:25 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:08:25 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:08:25 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:08:25 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:08:26 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:08:26 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-3c442964-dbba-4cbb-83c5-a78037326cdf
2017-04-05 18:08:26 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49334 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:08:26 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:08:26 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:08:26 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:08:26 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:08:26 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 18:08:26 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:08:26 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:08:26 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1226324929] - leader session null
2017-04-05 18:08:26 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:08:26 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 18:08:26 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-5b2b6251-44f6-4dbd-8a31-aaffabfbe0e8 for spill files.
2017-04-05 18:08:26 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:08:26 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-486ef175-df49-42da-bdd2-0562bdd67d2c
2017-04-05 18:08:26 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1214731962.
2017-04-05 18:08:26 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='932d8c3dd5dc7cfca926147fff22a38d'} @ localhost (dataPort=-1)
2017-04-05 18:08:26 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:08:26 INFO  TaskManager:128 - Memory usage stats: [HEAP: 172/853/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 18:08:26 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:08:26 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='932d8c3dd5dc7cfca926147fff22a38d'} has started.
2017-04-05 18:08:26 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as f02057d45753cee7b280d2958405f0ed. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:08:26 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:08:26 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49334. Starting BLOB cache.
2017-04-05 18:08:26 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-db0f6fb2-dcff-43bc-bd2f-8e86de2e5357
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 04e81d830f13ba257fb5651a504777c1)) but there is no connection to a JobManager yet.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1).
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1226324929].
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1226324929]
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1) and wait for progress
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  JobManager:128 - Submitting job 04e81d830f13ba257fb5651a504777c1 (Flink Streaming Job).
2017-04-05 18:08:26 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 04e81d830f13ba257fb5651a504777c1.
2017-04-05 18:08:26 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1).
2017-04-05 18:08:26 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:111 - Job 04e81d830f13ba257fb5651a504777c1 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:08:27 INFO  JobManager:128 - Scheduling job 04e81d830f13ba257fb5651a504777c1 (Flink Streaming Job).
2017-04-05 18:08:27 INFO  ExecutionGraph:965 - Job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1) switched from state CREATED to RUNNING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:08:27	Job execution switched to status RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21c3f8cd for Source: Custom Source -> Map (1/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) [DEPLOYING].
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@77da1602 for Source: Custom Source -> Map (2/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) [DEPLOYING].
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7f48430e for Source: Custom Source -> Map (4/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) [DEPLOYING].
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49dc85e2 for Source: Custom Source -> Map (3/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@72c95fb5 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@231bb157 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) [DEPLOYING].
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@588b630 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) [DEPLOYING].
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@729453e1 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:28 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:28 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:28 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:08:28 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:08:28 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 97, so the initial offset will be set to 96
2017-04-05 18:08:28 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 107, so the initial offset will be set to 106
2017-04-05 18:13:46 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:13:47 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:13:47 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:13:47 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:13:48 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:13:48 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-feb2c1c9-bb38-4a3e-9fe7-d16104d05019
2017-04-05 18:13:48 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49361 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:13:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:13:48 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:13:48 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:13:48 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:13:48 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:13:48 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 18:13:48 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1227038263] - leader session null
2017-04-05 18:13:48 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:13:48 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:13:48 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 18:13:48 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-4bc9c59b-aaf3-4714-9473-b5e7963c47c4 for spill files.
2017-04-05 18:13:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:13:48 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-3a9c4e56-7797-40ba-8642-e7d33d14321f
2017-04-05 18:13:48 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1718370412.
2017-04-05 18:13:48 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='1b3bd274e8d2e1332fb73acc18bebb37'} @ localhost (dataPort=-1)
2017-04-05 18:13:48 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:13:48 INFO  TaskManager:128 - Memory usage stats: [HEAP: 178/848/910 MB, NON HEAP: 124/129/-1 MB (used/committed/max)]
2017-04-05 18:13:48 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:13:48 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='1b3bd274e8d2e1332fb73acc18bebb37'} has started.
2017-04-05 18:13:48 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 59d793d66689e2a80aef5c358fc5161f. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:13:48 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:13:48 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49361. Starting BLOB cache.
2017-04-05 18:13:48 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c544b3b4-45fc-4a50-99fd-302130da60b6
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 6722c410008234a62da538d901b0df00)) but there is no connection to a JobManager yet.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (6722c410008234a62da538d901b0df00).
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1227038263].
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1227038263]
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (6722c410008234a62da538d901b0df00) and wait for progress
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  JobManager:128 - Submitting job 6722c410008234a62da538d901b0df00 (Flink Streaming Job).
2017-04-05 18:13:48 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 6722c410008234a62da538d901b0df00.
2017-04-05 18:13:48 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (6722c410008234a62da538d901b0df00).
2017-04-05 18:13:48 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:111 - Job 6722c410008234a62da538d901b0df00 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:13:48 INFO  JobManager:128 - Scheduling job 6722c410008234a62da538d901b0df00 (Flink Streaming Job).
2017-04-05 18:13:48 INFO  ExecutionGraph:965 - Job Flink Streaming Job (6722c410008234a62da538d901b0df00) switched from state CREATED to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:13:48	Job execution switched to status RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4f255bb2 for Source: Custom Source -> Map (3/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) [DEPLOYING].
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@9e18a33 for Source: Custom Source -> Map (4/4)
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4050f019 for Source: Custom Source -> Map (2/4)
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5bfd1c91 for Source: Custom Source -> Map (1/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3b5b100a for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6ead8c9f for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@751db6e4 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) [DEPLOYING].
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2098a8f8 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:13:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:13:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 100, so the initial offset will be set to 99
2017-04-05 18:13:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 107, so the initial offset will be set to 106
2017-04-05 18:26:31 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:26:32 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:26:32 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:26:32 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:26:33 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:26:33 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c7e64288-f900-49d6-a283-2bef1aa9ab6a
2017-04-05 18:26:33 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49403 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:26:33 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:26:33 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:26:33 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:26:33 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:26:33 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:26:34 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#364019187] - leader session null
2017-04-05 18:26:34 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:26:34 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 12 GB (10,81% usable)
2017-04-05 18:26:34 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:26:34 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:26:34 INFO  TaskManager:128 - Limiting managed memory to 262 MB, memory will be allocated lazily.
2017-04-05 18:26:34 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-30774dd5-77c8-497e-bbaa-dd93b5e3caf0 for spill files.
2017-04-05 18:26:34 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:26:34 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-0f276644-8d25-4c34-8b46-04f10f86757a
2017-04-05 18:26:34 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1749889302.
2017-04-05 18:26:34 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='efda1b416438bae96aeb82373cec5e7a'} @ localhost (dataPort=-1)
2017-04-05 18:26:34 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:26:34 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/930/930 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-05 18:26:34 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:26:34 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='efda1b416438bae96aeb82373cec5e7a'} has started.
2017-04-05 18:26:34 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as aecf718c0e7de5b2e5843b526f44df73. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:26:34 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:26:34 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49403. Starting BLOB cache.
2017-04-05 18:26:34 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-e2bbdaff-f715-4a00-a6f5-ae6718d27222
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 049b9e884eef8930762f3520cbea6a29)) but there is no connection to a JobManager yet.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29).
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#364019187].
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#364019187]
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29) and wait for progress
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:26:34 INFO  JobManager:128 - Submitting job 049b9e884eef8930762f3520cbea6a29 (Flink Streaming Job).
2017-04-05 18:26:34 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 049b9e884eef8930762f3520cbea6a29.
2017-04-05 18:26:34 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29).
2017-04-05 18:26:34 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:111 - Job 049b9e884eef8930762f3520cbea6a29 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:26:34 INFO  JobManager:128 - Scheduling job 049b9e884eef8930762f3520cbea6a29 (Flink Streaming Job).
2017-04-05 18:26:34 INFO  ExecutionGraph:965 - Job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29) switched from state CREATED to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:26:34	Job execution switched to status RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@767f7ba3 for Source: Custom Source -> Map (1/4)
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@27c26170 for Source: Custom Source -> Map (2/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) [DEPLOYING].
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2d04a34b for Source: Custom Source -> Map (3/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@68ff89c8 for Source: Custom Source -> Map (4/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1c559c17 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3153451b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25d790c0 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@45643206 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:26:35 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 109, so the initial offset will be set to 108
2017-04-05 18:26:35 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:26:35 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 100, so the initial offset will be set to 99
2017-04-05 18:29:49 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:29:49 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:29:50 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:29:50 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:29:50 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:29:50 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-8e78cb7a-8870-4e64-838f-2c6b0dff4610
2017-04-05 18:29:50 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49423 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:29:50 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:29:50 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:29:50 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:29:50 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:29:50 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:29:50 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 12 GB (10,81% usable)
2017-04-05 18:29:50 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:29:50 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#56451658] - leader session null
2017-04-05 18:29:50 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:29:50 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:29:50 INFO  TaskManager:128 - Limiting managed memory to 264 MB, memory will be allocated lazily.
2017-04-05 18:29:50 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-ba6602bd-5de3-4474-ad07-a4a16be14b4f for spill files.
2017-04-05 18:29:51 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:29:51 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-f5111c75-51ce-4d93-93f3-625ff7cb8d4a
2017-04-05 18:29:51 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#323181437.
2017-04-05 18:29:51 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='50b7dc738eda5e24f49e8d323f7b4ce7'} @ localhost (dataPort=-1)
2017-04-05 18:29:51 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:29:51 INFO  TaskManager:128 - Memory usage stats: [HEAP: 172/934/934 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 18:29:51 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:29:51 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='50b7dc738eda5e24f49e8d323f7b4ce7'} has started.
2017-04-05 18:29:51 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as cdcb20ddecfca0cf698caaed963b3596. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:29:51 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:29:51 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49423. Starting BLOB cache.
2017-04-05 18:29:51 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-24ea038f-fb75-4206-896c-c8cbf596143b
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: e141bf12e96eaf61fd6b196a90604eac)) but there is no connection to a JobManager yet.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac).
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#56451658].
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#56451658]
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac) and wait for progress
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:29:51 INFO  JobManager:128 - Submitting job e141bf12e96eaf61fd6b196a90604eac (Flink Streaming Job).
2017-04-05 18:29:51 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for e141bf12e96eaf61fd6b196a90604eac.
2017-04-05 18:29:51 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac).
2017-04-05 18:29:51 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:111 - Job e141bf12e96eaf61fd6b196a90604eac was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:29:51 INFO  JobManager:128 - Scheduling job e141bf12e96eaf61fd6b196a90604eac (Flink Streaming Job).
2017-04-05 18:29:51 INFO  ExecutionGraph:965 - Job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac) switched from state CREATED to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:29:51	Job execution switched to status RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@738e8b72 for Source: Custom Source -> Map (2/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) [DEPLOYING].
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@10cc93b for Source: Custom Source -> Map (1/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@776c8f06 for Source: Custom Source -> Map (3/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@464387dc for Source: Custom Source -> Map (4/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@679e31eb for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1eb8f25f for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@958277f for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@12fa75fc for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:29:52 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:29:52 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 109, so the initial offset will be set to 108
2017-04-05 18:29:52 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 101, so the initial offset will be set to 100
2017-04-05 20:16:58 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:16:58 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:16:59 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:16:59 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:16:59 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:16:59 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-fb530415-c2d8-4756-8bb0-a94c0b2d1f7d
2017-04-05 20:17:00 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49975 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:17:00 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:17:00 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:17:00 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:17:00 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:17:00 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:17:00 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:17:00 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#273657099] - leader session null
2017-04-05 20:17:00 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:17:00 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:17:00 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:17:00 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-3c5b9b74-70da-4fca-91ec-3ad2427ba7db for spill files.
2017-04-05 20:17:00 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:17:00 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-3b8efeea-d864-4411-aec7-0be607c087df
2017-04-05 20:17:00 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1155939688.
2017-04-05 20:17:00 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='41552bede422dad1c79365708a95c6a4'} @ localhost (dataPort=-1)
2017-04-05 20:17:00 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:17:00 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/870/910 MB, NON HEAP: 125/127/-1 MB (used/committed/max)]
2017-04-05 20:17:00 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:17:00 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='41552bede422dad1c79365708a95c6a4'} has started.
2017-04-05 20:17:00 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 50ce07c5490c7075fb22c900c3a349ad. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:17:00 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:17:00 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49975. Starting BLOB cache.
2017-04-05 20:17:00 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-21cf5ce2-ba00-4705-b916-728601aebd53
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 12ec278e028f3c7eaef30ea8796ed768)) but there is no connection to a JobManager yet.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768).
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#273657099].
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#273657099]
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768) and wait for progress
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  JobManager:128 - Submitting job 12ec278e028f3c7eaef30ea8796ed768 (Flink Streaming Job).
2017-04-05 20:17:00 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 12ec278e028f3c7eaef30ea8796ed768.
2017-04-05 20:17:00 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768).
2017-04-05 20:17:00 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:17:00 INFO  JobManager:128 - Scheduling job 12ec278e028f3c7eaef30ea8796ed768 (Flink Streaming Job).
2017-04-05 20:17:00 INFO  ExecutionGraph:965 - Job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768) switched from state CREATED to RUNNING.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:111 - Job 12ec278e028f3c7eaef30ea8796ed768 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:17:00	Job execution switched to status RUNNING.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@8235b82 for Source: Custom Source -> Map (1/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) [DEPLOYING].
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@132c6b3a for Source: Custom Source -> Map (2/4)
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3751cc96 for Source: Custom Source -> Map (3/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) [DEPLOYING].
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@20aba2 for Source: Custom Source -> Map (4/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) [DEPLOYING].
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4e9926a2 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5286b4a6 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7a4079b1 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@445df11e for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:17:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:17:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 111, so the initial offset will be set to 110
2017-04-05 20:17:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 105, so the initial offset will be set to 104
2017-04-05 20:18:41 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:18:42 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:18:42 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:18:42 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:18:43 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:18:43 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-f57abe2a-31af-4934-a8dd-4fbe698b17ae
2017-04-05 20:18:43 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50011 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:18:43 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:18:43 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:18:43 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:18:43 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:18:43 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:18:43 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:18:43 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:18:43 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-790443083] - leader session null
2017-04-05 20:18:43 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:18:43 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:18:43 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-b21c41d5-cd6d-4bca-bb4d-65e39b4f300b for spill files.
2017-04-05 20:18:43 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:18:43 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-13211b9a-7500-4ddc-91fe-2736e6ca5fc1
2017-04-05 20:18:43 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1773129487.
2017-04-05 20:18:43 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='523645c9c18aa3956a5c0c538a85665d'} @ localhost (dataPort=-1)
2017-04-05 20:18:43 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:18:43 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/869/910 MB, NON HEAP: 125/128/-1 MB (used/committed/max)]
2017-04-05 20:18:43 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:18:43 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='523645c9c18aa3956a5c0c538a85665d'} has started.
2017-04-05 20:18:43 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 1e2b2b3712266dda7304d6f7bd883b2c. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:18:43 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:18:43 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50011. Starting BLOB cache.
2017-04-05 20:18:43 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-83a5352a-eb55-4bc1-aca9-47bb8b9e2da3
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: dbce4e4719c7e73bb0c0a6f439704d4a)) but there is no connection to a JobManager yet.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a).
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-790443083].
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-790443083]
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a) and wait for progress
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  JobManager:128 - Submitting job dbce4e4719c7e73bb0c0a6f439704d4a (Flink Streaming Job).
2017-04-05 20:18:43 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for dbce4e4719c7e73bb0c0a6f439704d4a.
2017-04-05 20:18:43 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a).
2017-04-05 20:18:43 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:111 - Job dbce4e4719c7e73bb0c0a6f439704d4a was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:18:43 INFO  JobManager:128 - Scheduling job dbce4e4719c7e73bb0c0a6f439704d4a (Flink Streaming Job).
2017-04-05 20:18:43 INFO  ExecutionGraph:965 - Job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a) switched from state CREATED to RUNNING.
2017-04-05 20:18:43 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from CREATED to SCHEDULED.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:18:43	Job execution switched to status RUNNING.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:43	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:18:43 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:43	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:18:43 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@500bea57 for Source: Custom Source -> Map (1/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d7f4423 for Source: Custom Source -> Map (2/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) [DEPLOYING].
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2098a8f8 for Source: Custom Source -> Map (3/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@39d0f011 for Source: Custom Source -> Map (4/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) [DEPLOYING].
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21b91983 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) [DEPLOYING].
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) [DEPLOYING].
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e742846 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3c1a7d5e for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@303d4ad2 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:18:45 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:18:45 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 112, so the initial offset will be set to 111
2017-04-05 20:18:45 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 105, so the initial offset will be set to 104
2017-04-05 20:20:03 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:20:03 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:20:04 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:20:04 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:20:04 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:20:04 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0c708173-d69f-42e1-a70b-75dcd8880e01
2017-04-05 20:20:04 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50030 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:20:04 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:20:04 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:20:04 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:20:04 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:20:05 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:20:05 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:20:05 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:20:05 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1335381870] - leader session null
2017-04-05 20:20:05 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:20:05 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:20:05 INFO  TaskManager:128 - Limiting managed memory to 256 MB, memory will be allocated lazily.
2017-04-05 20:20:05 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1deea318-87f5-447b-b1a2-7cfb04387365 for spill files.
2017-04-05 20:20:05 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:20:05 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-ae930504-7718-4e4a-8182-afe63bfdb543
2017-04-05 20:20:05 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#708318888.
2017-04-05 20:20:05 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='76fbbea7e472e23b61242c1382af65af'} @ localhost (dataPort=-1)
2017-04-05 20:20:05 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:20:05 INFO  TaskManager:128 - Memory usage stats: [HEAP: 172/912/912 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:20:05 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:20:05 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='76fbbea7e472e23b61242c1382af65af'} has started.
2017-04-05 20:20:05 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 5240fdcaf60257a16d46c346c6d2d11e. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:20:05 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:20:05 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50030. Starting BLOB cache.
2017-04-05 20:20:05 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-e72ce0f6-f8ec-4f1c-a159-8e80338055c3
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 88af4eba71fff074d95630ef3675bf42)) but there is no connection to a JobManager yet.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42).
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1335381870].
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1335381870]
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42) and wait for progress
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:20:05 INFO  JobManager:128 - Submitting job 88af4eba71fff074d95630ef3675bf42 (Flink Streaming Job).
2017-04-05 20:20:05 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 88af4eba71fff074d95630ef3675bf42.
2017-04-05 20:20:05 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42).
2017-04-05 20:20:05 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:111 - Job 88af4eba71fff074d95630ef3675bf42 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:20:05 INFO  JobManager:128 - Scheduling job 88af4eba71fff074d95630ef3675bf42 (Flink Streaming Job).
2017-04-05 20:20:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42) switched from state CREATED to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:20:05	Job execution switched to status RUNNING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@586c4498 for Source: Custom Source -> Map (4/4)
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@72c95fb5 for Source: Custom Source -> Map (3/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) [DEPLOYING].
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@77dfe0d8 for Source: Custom Source -> Map (2/4)
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5460e2ca for Source: Custom Source -> Map (1/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@776c8f06 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e742846 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3924b24b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3910a064 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:20:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:20:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 113, so the initial offset will be set to 112
2017-04-05 20:20:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 106, so the initial offset will be set to 105
2017-04-05 20:24:29 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:24:29 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:24:29 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:24:30 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:24:30 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:24:30 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0b91a19f-64fd-4e74-bad5-5f601ccf222b
2017-04-05 20:24:30 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50074 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:24:30 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:24:30 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:24:30 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:24:30 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:24:30 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:24:30 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:24:30 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#687904542] - leader session null
2017-04-05 20:24:30 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:24:30 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:24:30 INFO  TaskManager:128 - Limiting managed memory to 261 MB, memory will be allocated lazily.
2017-04-05 20:24:30 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-a5e048d4-fc73-4e5a-87ef-0bd60b7a985c for spill files.
2017-04-05 20:24:30 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:24:30 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-eccdfed0-81e5-4cb2-86c6-87d7f85cd11c
2017-04-05 20:24:30 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-451548543.
2017-04-05 20:24:30 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='28961281f49daf82317f7fd4cc9d46ae'} @ localhost (dataPort=-1)
2017-04-05 20:24:30 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:24:30 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/927/927 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:24:30 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:24:30 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='28961281f49daf82317f7fd4cc9d46ae'} has started.
2017-04-05 20:24:30 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 639082f5057c2c9d5b6b937de6a7aea3. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:24:30 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:24:30 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50074. Starting BLOB cache.
2017-04-05 20:24:30 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-3aa0ed42-8606-436d-98ca-f0f6b8f5d377
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 05f189d2f511af676fe53b34025908fd)) but there is no connection to a JobManager yet.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (05f189d2f511af676fe53b34025908fd).
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#687904542].
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#687904542]
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (05f189d2f511af676fe53b34025908fd) and wait for progress
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  JobManager:128 - Submitting job 05f189d2f511af676fe53b34025908fd (Flink Streaming Job).
2017-04-05 20:24:30 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 05f189d2f511af676fe53b34025908fd.
2017-04-05 20:24:31 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (05f189d2f511af676fe53b34025908fd).
2017-04-05 20:24:31 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:111 - Job 05f189d2f511af676fe53b34025908fd was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:24:31 INFO  JobManager:128 - Scheduling job 05f189d2f511af676fe53b34025908fd (Flink Streaming Job).
2017-04-05 20:24:31 INFO  ExecutionGraph:965 - Job Flink Streaming Job (05f189d2f511af676fe53b34025908fd) switched from state CREATED to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:24:31	Job execution switched to status RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2295631b for Source: Custom Source -> Map (2/4)
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@476664eb for Source: Custom Source -> Map (1/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@699dcb4a for Source: Custom Source -> Map (3/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2099fc3 for Source: Custom Source -> Map (4/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2aba7436 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@30334796 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3b5cf8e8 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1e574b0b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:24:32 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:24:32 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 106, so the initial offset will be set to 105
2017-04-05 20:24:32 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 114, so the initial offset will be set to 113
2017-04-05 20:32:43 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:32:44 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:32:45 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:32:45 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:32:45 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:32:45 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-f63793bf-91ef-49a1-b96c-28b593b9a34d
2017-04-05 20:32:45 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50147 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:32:45 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:32:45 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:32:45 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:32:45 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:32:45 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:32:45 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:32:45 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:32:45 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1973105179] - leader session null
2017-04-05 20:32:45 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:32:45 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:32:45 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:32:45 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1273f216-4848-4446-b1fe-ef4cb97233bb for spill files.
2017-04-05 20:32:45 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:32:45 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-76a884cd-9e17-43dc-8afb-0d3ea4a1dd97
2017-04-05 20:32:45 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#70152146.
2017-04-05 20:32:45 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='393047e8aa734e0ae0aa6a89237a12b8'} @ localhost (dataPort=-1)
2017-04-05 20:32:45 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:32:45 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/897/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:32:45 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:32:45 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='393047e8aa734e0ae0aa6a89237a12b8'} has started.
2017-04-05 20:32:45 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 6f31f765f85b02782c3d4cc34d7dff10. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:32:46 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:32:46 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50147. Starting BLOB cache.
2017-04-05 20:32:46 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-642fcfa3-aaa1-4dc1-9a68-b404c5f87bf6
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: ab7ea14f665a8ff53aab52ef7c7c663b)) but there is no connection to a JobManager yet.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b).
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1973105179].
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1973105179]
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b) and wait for progress
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:32:46 INFO  JobManager:128 - Submitting job ab7ea14f665a8ff53aab52ef7c7c663b (Flink Streaming Job).
2017-04-05 20:32:46 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for ab7ea14f665a8ff53aab52ef7c7c663b.
2017-04-05 20:32:46 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b).
2017-04-05 20:32:46 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:111 - Job ab7ea14f665a8ff53aab52ef7c7c663b was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:32:46 INFO  JobManager:128 - Scheduling job ab7ea14f665a8ff53aab52ef7c7c663b (Flink Streaming Job).
2017-04-05 20:32:46 INFO  ExecutionGraph:965 - Job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b) switched from state CREATED to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:32:46	Job execution switched to status RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@377ac88d for Source: Custom Source -> Map (1/4)
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@65d1aebb for Source: Custom Source -> Map (2/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) [DEPLOYING].
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3a46462f for Source: Custom Source -> Map (3/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@630862bb for Source: Custom Source -> Map (4/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) [DEPLOYING].
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5ff37b3c for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) [DEPLOYING].
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@28846d1d for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) [DEPLOYING].
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1f1bfea8 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) [DEPLOYING].
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1869f67b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) [DEPLOYING].
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:47 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:47 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:47 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:47 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:32:47 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:32:47 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 116, so the initial offset will be set to 115
2017-04-05 20:32:47 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 107, so the initial offset will be set to 106
2017-04-05 20:39:49 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:39:49 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:39:50 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:39:50 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:39:51 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:39:51 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6cadf92e-c0d9-4a09-93ca-c22022aa42ef
2017-04-05 20:39:52 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50314 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:39:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:39:52 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:39:52 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:39:52 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:39:52 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:39:52 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:39:52 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#644205278] - leader session null
2017-04-05 20:39:52 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:39:52 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:39:52 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:39:52 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-587fd470-e186-4afb-975d-fe8a23dbbff7 for spill files.
2017-04-05 20:39:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:39:52 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-138c4a6c-29e6-425a-aa40-105661b38d16
2017-04-05 20:39:52 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1461939588.
2017-04-05 20:39:52 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='609f84850b823c00d85b6edea6a3255b'} @ localhost (dataPort=-1)
2017-04-05 20:39:52 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:39:52 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/879/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:39:52 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:39:52 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='609f84850b823c00d85b6edea6a3255b'} has started.
2017-04-05 20:39:52 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 7316b0777d3e338f7c92cce217732641. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:39:52 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:39:52 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50314. Starting BLOB cache.
2017-04-05 20:39:52 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6ed05c96-d706-4557-b7ae-adb9d544bf81
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: c081b7d81df0f50fabc0151cac02f2dc)) but there is no connection to a JobManager yet.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc).
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#644205278].
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#644205278]
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc) and wait for progress
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  JobManager:128 - Submitting job c081b7d81df0f50fabc0151cac02f2dc (Flink Streaming Job).
2017-04-05 20:39:52 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for c081b7d81df0f50fabc0151cac02f2dc.
2017-04-05 20:39:52 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc).
2017-04-05 20:39:52 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:111 - Job c081b7d81df0f50fabc0151cac02f2dc was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:39:52 INFO  JobManager:128 - Scheduling job c081b7d81df0f50fabc0151cac02f2dc (Flink Streaming Job).
2017-04-05 20:39:52 INFO  ExecutionGraph:965 - Job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc) switched from state CREATED to RUNNING.
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:39:52	Job execution switched to status RUNNING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@706f10ee for Source: Custom Source -> Map (1/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) [DEPLOYING].
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4aa9a182 for Source: Custom Source -> Map (3/4)
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@75c01b31 for Source: Custom Source -> Map (2/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@578bbec6 for Source: Custom Source -> Map (4/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@22edffdb for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@102201d3 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@53fd5740 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6fbedb6c for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:39:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:39:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 117, so the initial offset will be set to 116
2017-04-05 20:39:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 129, so the initial offset will be set to 128
2017-04-05 21:23:01 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 21:23:02 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 21:23:02 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 21:23:02 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 21:23:03 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 21:23:03 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-31a2d85a-f037-4f3c-81c6-5ced7100f230
2017-04-05 21:23:03 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50664 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 21:23:03 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 21:23:03 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 21:23:03 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 21:23:03 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 21:23:03 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 21:23:03 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 21:23:03 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1097320115] - leader session null
2017-04-05 21:23:03 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 21:23:03 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 21:23:03 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 21:23:03 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-62badd41-737a-4499-8077-a34b0fa70f48 for spill files.
2017-04-05 21:23:03 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 21:23:03 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-c29f0469-1ca8-47c3-ae3c-573925660c6c
2017-04-05 21:23:03 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1144019418.
2017-04-05 21:23:03 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='2a43b32694e030c5138deb48fa37d510'} @ localhost (dataPort=-1)
2017-04-05 21:23:03 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 21:23:03 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/848/910 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-05 21:23:03 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 21:23:03 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='2a43b32694e030c5138deb48fa37d510'} has started.
2017-04-05 21:23:03 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 26b156eddafc5de36f42c72aee20cfff. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 21:23:03 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 21:23:03 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50664. Starting BLOB cache.
2017-04-05 21:23:03 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-7accbd28-6b6b-46ae-8de8-8ba95660d0aa
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 833b98f5c5adb3ab2a2b0bb9290f82ea)) but there is no connection to a JobManager yet.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea).
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1097320115].
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1097320115]
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea) and wait for progress
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  JobManager:128 - Submitting job 833b98f5c5adb3ab2a2b0bb9290f82ea (Flink Streaming Job).
2017-04-05 21:23:03 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 833b98f5c5adb3ab2a2b0bb9290f82ea.
2017-04-05 21:23:03 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea).
2017-04-05 21:23:03 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:111 - Job 833b98f5c5adb3ab2a2b0bb9290f82ea was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 21:23:04 INFO  JobManager:128 - Scheduling job 833b98f5c5adb3ab2a2b0bb9290f82ea (Flink Streaming Job).
2017-04-05 21:23:04 INFO  ExecutionGraph:965 - Job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea) switched from state CREATED to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:275 - 04/05/2017 21:23:04	Job execution switched to status RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@71ff9151 for Source: Custom Source -> Map (2/4)
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2d029e99 for Source: Custom Source -> Map (1/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1ca5a964 for Source: Custom Source -> Map (3/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) [DEPLOYING].
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@19f9ec0c for Source: Custom Source -> Map (4/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2099fc3 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6b0cb342 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@597e22a4 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) [DEPLOYING].
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6385882 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 21:23:05 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 21:23:05 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 131, so the initial offset will be set to 130
2017-04-05 21:23:05 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 120, so the initial offset will be set to 119
2017-04-05 22:01:53 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 22:01:53 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 22:01:54 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 22:01:54 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 22:01:54 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 22:01:54 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-1bdc134d-ebf1-4116-b0df-9af5476a3136
2017-04-05 22:01:55 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50761 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 22:01:55 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:01:55 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 22:01:55 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 22:01:55 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 22:01:55 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 22:01:55 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 22:01:55 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1051615375] - leader session null
2017-04-05 22:01:55 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 22:01:55 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 22:01:55 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 22:01:55 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-c97e0f28-9d64-459b-a09f-dc22fc9cfb2f for spill files.
2017-04-05 22:01:55 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:01:55 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-00f350d6-4168-48ef-ae37-d38c28e93f85
2017-04-05 22:01:55 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-238883264.
2017-04-05 22:01:55 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='158f03e527a93da72c6f15a39c70dd39'} @ localhost (dataPort=-1)
2017-04-05 22:01:55 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 22:01:55 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/861/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 22:01:55 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 22:01:55 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='158f03e527a93da72c6f15a39c70dd39'} has started.
2017-04-05 22:01:55 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 538cb67627da10829a585f66fd1044e1. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 22:01:55 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 22:01:55 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50761. Starting BLOB cache.
2017-04-05 22:01:55 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0052ab92-3b5f-42a7-a0f9-ccf8508974d1
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 17b58dff67098ddb0fb21f0921c619ee)) but there is no connection to a JobManager yet.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee).
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1051615375].
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1051615375]
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee) and wait for progress
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  JobManager:128 - Submitting job 17b58dff67098ddb0fb21f0921c619ee (Flink Streaming Job).
2017-04-05 22:01:55 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 17b58dff67098ddb0fb21f0921c619ee.
2017-04-05 22:01:55 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee).
2017-04-05 22:01:55 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:111 - Job 17b58dff67098ddb0fb21f0921c619ee was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 22:01:55 INFO  JobManager:128 - Scheduling job 17b58dff67098ddb0fb21f0921c619ee (Flink Streaming Job).
2017-04-05 22:01:55 INFO  ExecutionGraph:965 - Job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee) switched from state CREATED to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:275 - 04/05/2017 22:01:55	Job execution switched to status RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2ecda439 for Source: Custom Source -> Map (1/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@e6178c for Source: Custom Source -> Map (2/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) [DEPLOYING].
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7eecea5a for Source: Custom Source -> Map (3/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) [DEPLOYING].
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@57793384 for Source: Custom Source -> Map (4/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@57b2a6b3 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3be67fad for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4d28250d for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@37907ead for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:57 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:01:57 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:01:57 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 131, so the initial offset will be set to 130
2017-04-05 22:01:57 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 123, so the initial offset will be set to 122
2017-04-05 22:24:23 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 22:24:23 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 22:24:24 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 22:24:24 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 22:24:24 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 22:24:24 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c4934890-d7bb-467f-a136-bcd4399cb461
2017-04-05 22:24:24 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50874 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 22:24:24 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:24:24 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 22:24:24 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 22:24:24 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 22:24:24 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 22:24:24 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 22:24:24 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 22:24:24 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 22:24:24 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-727700569] - leader session null
2017-04-05 22:24:24 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 22:24:24 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 22:24:25 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-e59c0823-8c35-4c8c-840c-ffc888a645ee for spill files.
2017-04-05 22:24:25 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:24:25 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-af6d95c5-1f69-4af1-82b6-d2ca83aab347
2017-04-05 22:24:25 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1329948128.
2017-04-05 22:24:25 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='f7e561919e14bc0649ff26d0803918c1'} @ localhost (dataPort=-1)
2017-04-05 22:24:25 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 22:24:25 INFO  TaskManager:128 - Memory usage stats: [HEAP: 171/831/910 MB, NON HEAP: 122/126/-1 MB (used/committed/max)]
2017-04-05 22:24:25 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 22:24:25 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='f7e561919e14bc0649ff26d0803918c1'} has started.
2017-04-05 22:24:25 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 2ff0fd7e798e1645a27197f50b327465. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 22:24:25 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 22:24:25 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50874. Starting BLOB cache.
2017-04-05 22:24:25 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-ed9e9f8b-827b-49cf-9aab-dd0d7c676a9a
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: e61e490082c7ea768359afa1c9a7e3cc)) but there is no connection to a JobManager yet.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc).
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-727700569].
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-727700569]
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc) and wait for progress
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 22:24:25 INFO  JobManager:128 - Submitting job e61e490082c7ea768359afa1c9a7e3cc (Flink Streaming Job).
2017-04-05 22:24:25 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for e61e490082c7ea768359afa1c9a7e3cc.
2017-04-05 22:24:25 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc).
2017-04-05 22:24:25 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:111 - Job e61e490082c7ea768359afa1c9a7e3cc was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 22:24:25 INFO  JobManager:128 - Scheduling job e61e490082c7ea768359afa1c9a7e3cc (Flink Streaming Job).
2017-04-05 22:24:25 INFO  ExecutionGraph:965 - Job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc) switched from state CREATED to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:275 - 04/05/2017 22:24:25	Job execution switched to status RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2891a710 for Source: Custom Source -> Map (2/4)
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6affde57 for Source: Custom Source -> Map (3/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) [DEPLOYING].
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@453c965e for Source: Custom Source -> Map (1/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) [DEPLOYING].
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3751cc96 for Source: Custom Source -> Map (4/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) [DEPLOYING].
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@41726f29 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) [DEPLOYING].
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@270a258f for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d76e4d5 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@31220e97 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:24:26 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:24:26 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 123, so the initial offset will be set to 122
2017-04-05 22:24:26 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 134, so the initial offset will be set to 133
2017-04-07 09:28:41 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-07 09:28:41 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-07 09:28:43 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-07 09:28:43 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-07 09:28:44 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-07 09:28:44 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-1b75f3f5-bc5e-474f-bd45-4f5795400258
2017-04-07 09:28:44 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:61962 - max concurrent requests: 50 - max backlog: 1000
2017-04-07 09:28:44 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-07 09:28:44 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-07 09:28:44 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-07 09:28:44 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-07 09:28:44 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 8 GB (7,21% usable)
2017-04-07 09:28:44 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-07 09:28:44 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#639493118] - leader session null
2017-04-07 09:28:44 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-07 09:28:44 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-07 09:28:44 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-07 09:28:44 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-f4901cbc-66cb-4891-b442-01b0953cfbce for spill files.
2017-04-07 09:28:44 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-07 09:28:44 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-1f09bdb6-2708-438e-809d-3445fa8dd4ae
2017-04-07 09:28:44 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1848223155.
2017-04-07 09:28:44 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='26777db6d11cd5a2606300b55be39d20'} @ localhost (dataPort=-1)
2017-04-07 09:28:44 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-07 09:28:44 INFO  TaskManager:128 - Memory usage stats: [HEAP: 176/806/910 MB, NON HEAP: 131/134/-1 MB (used/committed/max)]
2017-04-07 09:28:44 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-07 09:28:44 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='26777db6d11cd5a2606300b55be39d20'} has started.
2017-04-07 09:28:44 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 3ad2d2029ac30a8f4dc3a0db06346d0c. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-07 09:28:44 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-07 09:28:44 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:61962. Starting BLOB cache.
2017-04-07 09:28:44 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-b3e191d5-3be8-4f33-8760-91017ea601a6
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 304c91fe338f6ff9a58d269ce1453a1e)) but there is no connection to a JobManager yet.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e).
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#639493118].
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#639493118]
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e) and wait for progress
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  JobManager:128 - Submitting job 304c91fe338f6ff9a58d269ce1453a1e (Flink Streaming Job).
2017-04-07 09:28:44 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 304c91fe338f6ff9a58d269ce1453a1e.
2017-04-07 09:28:44 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e).
2017-04-07 09:28:44 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:111 - Job 304c91fe338f6ff9a58d269ce1453a1e was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-07 09:28:44 INFO  JobManager:128 - Scheduling job 304c91fe338f6ff9a58d269ce1453a1e (Flink Streaming Job).
2017-04-07 09:28:44 INFO  ExecutionGraph:965 - Job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e) switched from state CREATED to RUNNING.
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:275 - 04/07/2017 09:28:44	Job execution switched to status RUNNING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from CREATED to DEPLOYING.
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from CREATED to DEPLOYING.
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from CREATED to DEPLOYING.
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49f8d852 for Source: Custom Source -> Map (3/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) [DEPLOYING].
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25632b7 for Source: Custom Source -> Map (4/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) [DEPLOYING].
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3472d14f for Source: Custom Source -> Map (1/4)
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@38a4dcc9 for Source: Custom Source -> Map (2/4)
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@77f8f4a5 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4762109a for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@379157e9 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@460271e2 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:46 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-07 09:28:46 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-07 09:28:46 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 124, so the initial offset will be set to 123
2017-04-07 09:28:46 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 136, so the initial offset will be set to 135
