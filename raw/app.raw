2017-04-05 15:55:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:55:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:55:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:55:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:55:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:55:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 85, so the initial offset will be set to 84
2017-04-05 15:55:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 95, so the initial offset will be set to 94
2017-04-05 15:57:47 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 15:57:47 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 15:57:48 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 15:57:48 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 15:57:48 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 15:57:48 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-2dd707bb-718a-4a27-873f-b2c1648c6436
2017-04-05 15:57:48 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:64705 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 15:57:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 15:57:48 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 15:57:48 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 15:57:48 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 15:57:48 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 15:57:48 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 15:57:48 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 15:57:48 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1778952782] - leader session null
2017-04-05 15:57:48 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 15:57:48 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 15:57:48 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-97e591b8-10f1-4b61-8227-649e660c7c0c for spill files.
2017-04-05 15:57:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 15:57:48 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-7c45b5ad-32be-40ac-ad5d-297d033f048a
2017-04-05 15:57:48 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1678007449.
2017-04-05 15:57:48 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='70b87e6646d04232b20a64ef604f3820'} @ localhost (dataPort=-1)
2017-04-05 15:57:48 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 15:57:48 INFO  TaskManager:128 - Memory usage stats: [HEAP: 170/900/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 15:57:48 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 15:57:48 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='70b87e6646d04232b20a64ef604f3820'} has started.
2017-04-05 15:57:48 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 7ea307380c4214c4cbed35eb6bd9d87d. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 15:57:48 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 15:57:48 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:64705. Starting BLOB cache.
2017-04-05 15:57:48 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-a5b556b7-fc5a-499d-98e2-88cc6f193f96
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 7663066bd03232a5929a207dbaf9b24a)) but there is no connection to a JobManager yet.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a).
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1778952782].
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1778952782]
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a) and wait for progress
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 15:57:48 INFO  JobManager:128 - Submitting job 7663066bd03232a5929a207dbaf9b24a (Flink Streaming Job).
2017-04-05 15:57:48 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 7663066bd03232a5929a207dbaf9b24a.
2017-04-05 15:57:49 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a).
2017-04-05 15:57:49 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:111 - Job 7663066bd03232a5929a207dbaf9b24a was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 15:57:49 INFO  JobManager:128 - Scheduling job 7663066bd03232a5929a207dbaf9b24a (Flink Streaming Job).
2017-04-05 15:57:49 INFO  ExecutionGraph:965 - Job Flink Streaming Job (7663066bd03232a5929a207dbaf9b24a) switched from state CREATED to RUNNING.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:275 - 04/05/2017 15:57:49	Job execution switched to status RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from CREATED to SCHEDULED.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from SCHEDULED to DEPLOYING.
2017-04-05 15:57:49 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1dfc6136 for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) [DEPLOYING].
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25414767 for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3a53065d for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) [DEPLOYING].
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4853eb2b for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3055f5ab for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@47b83ae3 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1cc3cc for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from CREATED to DEPLOYING.
2017-04-05 15:57:49 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5341a594 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 15:57:49 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) [DEPLOYING].
2017-04-05 15:57:49 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 15:57:49 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (feee380aa229c2d6ccb399348ea8bede) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (5f8990079675122c17e5286d7b1ee931) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (41ca35f4e6eb381d48b0b896f76d917b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (27647cd038df6087072f77e946b7c1bc) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (ef1816b4c307c0b7b1e9cd28a493a020) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (11bbe4e0a3f39f0c4c6ee7783c81a17b) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (eef8bbe1d13b29d60e22cbcfe4a2076f) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (28b60421dce06cd3dd55cbff512dae18) switched from DEPLOYING to RUNNING.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  JobSubmissionClientActor:265 - 04/05/2017 15:57:49	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a21a276e}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 15:57:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 15:57:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:57:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 15:57:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 85, so the initial offset will be set to 84
2017-04-05 15:57:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 96, so the initial offset will be set to 95
2017-04-05 16:58:59 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 16:58:59 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 16:59:00 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 16:59:00 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 16:59:01 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 16:59:01 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-d3e51685-1ff7-4d75-b03c-8d93a38969a7
2017-04-05 16:59:01 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65402 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 16:59:01 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 16:59:01 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 16:59:01 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 16:59:01 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 16:59:01 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 16:59:01 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 16:59:01 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 16:59:01 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-165705821] - leader session null
2017-04-05 16:59:01 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 16:59:01 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 16:59:01 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-02e4d31c-c858-42ae-bae5-bf6c5674173d for spill files.
2017-04-05 16:59:01 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 16:59:01 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-2418aa15-57ea-47aa-bee8-05c60c919d5a
2017-04-05 16:59:01 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1195441776.
2017-04-05 16:59:01 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='149829834498fbef35cd416fe5c676e7'} @ localhost (dataPort=-1)
2017-04-05 16:59:01 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 16:59:01 INFO  TaskManager:128 - Memory usage stats: [HEAP: 170/832/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 16:59:01 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 16:59:01 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='149829834498fbef35cd416fe5c676e7'} has started.
2017-04-05 16:59:01 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 2b3dfc15d5eb627557ad4562a9539566. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 16:59:01 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 16:59:01 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65402. Starting BLOB cache.
2017-04-05 16:59:01 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-de19550f-5152-41b8-a432-a355b1485594
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 4747ae356cddee0d014e003fa89639c1)) but there is no connection to a JobManager yet.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1).
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-165705821].
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-165705821]
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1) and wait for progress
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 16:59:01 INFO  JobManager:128 - Submitting job 4747ae356cddee0d014e003fa89639c1 (Flink Streaming Job).
2017-04-05 16:59:01 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 4747ae356cddee0d014e003fa89639c1.
2017-04-05 16:59:01 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1).
2017-04-05 16:59:01 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:111 - Job 4747ae356cddee0d014e003fa89639c1 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 16:59:01 INFO  JobManager:128 - Scheduling job 4747ae356cddee0d014e003fa89639c1 (Flink Streaming Job).
2017-04-05 16:59:01 INFO  ExecutionGraph:965 - Job Flink Streaming Job (4747ae356cddee0d014e003fa89639c1) switched from state CREATED to RUNNING.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:275 - 04/05/2017 16:59:01	Job execution switched to status RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from CREATED to SCHEDULED.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from SCHEDULED to DEPLOYING.
2017-04-05 16:59:01 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6051f97 for Source: Custom Source -> Map (1/4)
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@365669bf for Source: Custom Source -> Map (2/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e586fe2 for Source: Custom Source -> Map (3/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@190b4dc for Source: Custom Source -> Map (4/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@76652bd1 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@18e8ee85 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@727cc153 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from CREATED to DEPLOYING.
2017-04-05 16:59:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@707f6dbf for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 16:59:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) [DEPLOYING].
2017-04-05 16:59:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 16:59:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5bef6526119b74644cbdb812e9203486) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6588f26a91ffab6640808e9cfd35d3e7) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4c8b2abbb45eb98ae7314dd7e0c766db) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1b0b29d74ee01514daed894f90b45f42) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b739db1986b43a3fe5b235f7c5e44526) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bef4c565d8c8269a1d3ee3dbedae8a1c) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e5257f91cbfd5607ceb241dc5b2b6584) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04e044c886dc4450fca84451d7605c3) switched from DEPLOYING to RUNNING.
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 16:59:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 16:59:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@49df2137}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 16:59:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 16:59:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 16:59:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 16:59:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 16:59:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 85, so the initial offset will be set to 84
2017-04-05 16:59:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 97, so the initial offset will be set to 96
2017-04-05 17:09:50 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:09:51 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:09:51 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:09:51 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:09:52 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:09:52 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-b3637273-1ea1-4416-a85f-e84908317d1a
2017-04-05 17:09:52 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65451 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:09:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:09:52 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:09:52 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:09:52 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:09:52 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:09:52 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:09:52 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:09:52 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#125829115] - leader session null
2017-04-05 17:09:52 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:09:52 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:09:52 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-69df1e56-4ae5-4624-8fcb-65db265cc071 for spill files.
2017-04-05 17:09:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:09:52 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-52d3e188-cd57-4273-9c2a-193f943f4bdc
2017-04-05 17:09:52 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1711511985.
2017-04-05 17:09:52 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='e30227376a4c352ca4df04703d1fccd0'} @ localhost (dataPort=-1)
2017-04-05 17:09:52 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:09:52 INFO  TaskManager:128 - Memory usage stats: [HEAP: 176/828/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 17:09:52 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:09:52 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='e30227376a4c352ca4df04703d1fccd0'} has started.
2017-04-05 17:09:52 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 20b3daa537469f3874426f529cc9ddeb. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:09:52 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:09:52 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65451. Starting BLOB cache.
2017-04-05 17:09:52 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-ccc137ec-a044-4a39-821b-ab052dd0aa66
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 9b4a51226fe166899574ab9259d8c728)) but there is no connection to a JobManager yet.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728).
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#125829115].
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#125829115]
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728) and wait for progress
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:09:52 INFO  JobManager:128 - Submitting job 9b4a51226fe166899574ab9259d8c728 (Flink Streaming Job).
2017-04-05 17:09:52 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 9b4a51226fe166899574ab9259d8c728.
2017-04-05 17:09:52 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728).
2017-04-05 17:09:52 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:111 - Job 9b4a51226fe166899574ab9259d8c728 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:09:52 INFO  JobManager:128 - Scheduling job 9b4a51226fe166899574ab9259d8c728 (Flink Streaming Job).
2017-04-05 17:09:52 INFO  ExecutionGraph:965 - Job Flink Streaming Job (9b4a51226fe166899574ab9259d8c728) switched from state CREATED to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:09:52	Job execution switched to status RUNNING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from CREATED to SCHEDULED.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:09:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@28d7e9e0 for Source: Custom Source -> Map (1/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) [DEPLOYING].
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@18058b10 for Source: Custom Source -> Map (3/4)
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@418ed92b for Source: Custom Source -> Map (4/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) [DEPLOYING].
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@142f6a01 for Source: Custom Source -> Map (2/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) [DEPLOYING].
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7747fd84 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) [DEPLOYING].
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@27550ee7 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) [DEPLOYING].
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@286c8f79 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:09:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from CREATED to DEPLOYING.
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) [DEPLOYING].
2017-04-05 17:09:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7d56c15b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:09:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) [DEPLOYING].
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (abe272bb9a304c96c47f18460839d6a4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e8b1b2f157e3bdfdbcab0459544cd5c7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0e4cda1833e1de688138d3919ce7f6ac) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (3ea1977ef502370acad15e4c39b1acf4) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (250cbd35cb498898b325c194de0865e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (976bd907da6f93869f13f2381adea54e) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2996808c5479743a264c8c660e674811) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 17:09:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:09:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:09:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (74aaf20f379c6fe193765466dbb42c73) switched from DEPLOYING to RUNNING.
2017-04-05 17:09:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:09:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@1e16e4c5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:09:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:09:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:09:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:09:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:09:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:09:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 100, so the initial offset will be set to 99
2017-04-05 17:09:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 93, so the initial offset will be set to 92
2017-04-05 17:14:01 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:14:07 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:14:08 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:14:08 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:14:08 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:14:08 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c358b0e4-01bb-4269-991e-9cff855f0fc2
2017-04-05 17:14:08 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65477 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:14:08 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:14:08 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:14:08 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:14:08 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:14:08 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:14:08 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:14:08 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:14:08 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:14:08 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-750048606] - leader session null
2017-04-05 17:14:08 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:14:08 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:14:08 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-30ddb3bc-70a1-4789-8d41-ab4763e9793b for spill files.
2017-04-05 17:14:08 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:14:09 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-8da80d2d-0a2e-4380-988d-e87217505ad2
2017-04-05 17:14:09 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#538401304.
2017-04-05 17:14:09 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='43bd2350995c7b98ca2c33bebe5c1b53'} @ localhost (dataPort=-1)
2017-04-05 17:14:09 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:14:09 INFO  TaskManager:128 - Memory usage stats: [HEAP: 178/879/910 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-05 17:14:09 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:14:09 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='43bd2350995c7b98ca2c33bebe5c1b53'} has started.
2017-04-05 17:14:09 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as cafce6f8351c2614190d4d083354e1a1. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:14:09 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:14:09 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65477. Starting BLOB cache.
2017-04-05 17:14:09 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-98cec4d0-c5aa-443d-b14d-bf355b465ef5
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 3e497f9d8e1b7d202ab67ee137787acd)) but there is no connection to a JobManager yet.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd).
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-750048606].
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-750048606]
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd) and wait for progress
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:14:09 INFO  JobManager:128 - Submitting job 3e497f9d8e1b7d202ab67ee137787acd (Flink Streaming Job).
2017-04-05 17:14:09 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 3e497f9d8e1b7d202ab67ee137787acd.
2017-04-05 17:14:09 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd).
2017-04-05 17:14:09 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:111 - Job 3e497f9d8e1b7d202ab67ee137787acd was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:14:09 INFO  JobManager:128 - Scheduling job 3e497f9d8e1b7d202ab67ee137787acd (Flink Streaming Job).
2017-04-05 17:14:09 INFO  ExecutionGraph:965 - Job Flink Streaming Job (3e497f9d8e1b7d202ab67ee137787acd) switched from state CREATED to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:14:09	Job execution switched to status RUNNING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from CREATED to SCHEDULED.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:14:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4c1b341f for Source: Custom Source -> Map (1/4)
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@e777874 for Source: Custom Source -> Map (2/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) [DEPLOYING].
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21464451 for Source: Custom Source -> Map (3/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@34c219c9 for Source: Custom Source -> Map (4/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4300ea74 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) [DEPLOYING].
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@40a2ac44 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@61ea7ba4 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  TaskManager:128 - Received task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from CREATED to DEPLOYING.
2017-04-05 17:14:09 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@674a2c68 for TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:14:09 INFO  Task:546 - Loading JAR files for task TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:575 - Registering task at network: TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) [DEPLOYING].
2017-04-05 17:14:09 INFO  Task:873 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:14:09 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d2336f07402a03de0c49d35f26a5a134) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (97bd52b5790bd0d739cc7e6fe8913676) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (5efbeff6b9472f8b5cfc756e0a1cc0ed) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (c2a56ec49b78e3f805c76ccef60eedcd) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (e97ba9d24ab6b8af8a85e7ce998927e7) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0a553edb17198bc984293b0cf666917d) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (c34ae1674198ec5a1ac226cf590fd011) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  ExecutionGraph:1025 - TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a0598d7267c439ebc7e7c1ee2e8cf905) switched from DEPLOYING to RUNNING.
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:14:09	TriggerWindow(ProcessingTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@404c194}, ProcessingTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:14:10 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:14:10 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:14:10 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 103, so the initial offset will be set to 102
2017-04-05 17:14:10 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 93, so the initial offset will be set to 92
2017-04-05 17:32:37 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:32:37 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:32:38 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:32:38 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:32:39 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:32:39 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-eaa07766-8911-4e7d-b448-060e04d4bf7a
2017-04-05 17:32:39 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49212 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:32:39 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:32:39 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:32:39 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:32:39 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:32:39 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:32:39 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:32:39 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:32:39 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1144756162] - leader session null
2017-04-05 17:32:40 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:32:40 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:32:40 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:32:40 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-4e0eb67e-0163-4d46-8c9c-b4958838aa9d for spill files.
2017-04-05 17:32:40 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:32:40 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-7148ea02-9b59-4bfb-9bbe-3c90dfedab2a
2017-04-05 17:32:40 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#582981956.
2017-04-05 17:32:40 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='23fe96635c7078d8f67c91f2315ea448'} @ localhost (dataPort=-1)
2017-04-05 17:32:40 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:32:40 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/841/910 MB, NON HEAP: 125/129/-1 MB (used/committed/max)]
2017-04-05 17:32:40 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:32:40 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='23fe96635c7078d8f67c91f2315ea448'} has started.
2017-04-05 17:32:40 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 466e62c38d91a32e6c20c6e639e09187. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:32:40 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:32:40 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49212. Starting BLOB cache.
2017-04-05 17:32:40 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6ca15e72-471a-4b2c-9ba3-da4915ccef59
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 7d52f0f4f523317ac118d6ec881dd269)) but there is no connection to a JobManager yet.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269).
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1144756162].
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1144756162]
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269) and wait for progress
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:32:40 INFO  JobManager:128 - Submitting job 7d52f0f4f523317ac118d6ec881dd269 (Flink Streaming Job).
2017-04-05 17:32:40 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 7d52f0f4f523317ac118d6ec881dd269.
2017-04-05 17:32:40 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269).
2017-04-05 17:32:40 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:111 - Job 7d52f0f4f523317ac118d6ec881dd269 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:32:40 INFO  JobManager:128 - Scheduling job 7d52f0f4f523317ac118d6ec881dd269 (Flink Streaming Job).
2017-04-05 17:32:40 INFO  ExecutionGraph:965 - Job Flink Streaming Job (7d52f0f4f523317ac118d6ec881dd269) switched from state CREATED to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:32:40	Job execution switched to status RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from CREATED to SCHEDULED.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:32:40 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4c1d0c93 for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) [DEPLOYING].
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4f34e8d3 for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5660560d for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@61edd45a for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@658cfaf9 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e417713 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3f40409d for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) [DEPLOYING].
2017-04-05 17:32:40 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from CREATED to DEPLOYING.
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) [DEPLOYING].
2017-04-05 17:32:40 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3fc60ecf for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) [DEPLOYING].
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (9ffbc347b31f0f46c8f93f79c697501c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f955037c47e6dae2a82a05866757706f) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (6003639dd04bc84656380643d8cc2a0d) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (1fd3954babe6165a33de8ea84d55974c) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0ff5d89f1625608925c40bdb84661ab8) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (21aceb2a3ddd2ad7e12a52a9fdc21779) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f153e47fb743e5c085a3ef3f17be99e1) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca9d0929f9e54ea8c2515839aae98621) switched from DEPLOYING to RUNNING.
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:32:40	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3949e767}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:32:41 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:32:41 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:32:41 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:32:41 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:32:42 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 104, so the initial offset will be set to 103
2017-04-05 17:32:42 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 95, so the initial offset will be set to 94
2017-04-05 17:54:18 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 17:54:19 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 17:54:19 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 17:54:19 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 17:54:20 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 17:54:20 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-a4f092d1-9c83-41da-a4ab-279a7afd2039
2017-04-05 17:54:20 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49307 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 17:54:20 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:54:20 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 17:54:20 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 17:54:20 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 17:54:20 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 17:54:20 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 17:54:20 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-537810066] - leader session null
2017-04-05 17:54:20 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 17:54:20 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 17:54:20 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 17:54:20 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1e55bd35-cb36-4287-a438-7a0b8991ceb3 for spill files.
2017-04-05 17:54:20 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 17:54:20 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-af374586-15ce-435a-a257-3f9087ceddfb
2017-04-05 17:54:20 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-853602967.
2017-04-05 17:54:20 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='229944996b8c35fca86228f3a6f75d58'} @ localhost (dataPort=-1)
2017-04-05 17:54:20 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 17:54:20 INFO  TaskManager:128 - Memory usage stats: [HEAP: 174/860/910 MB, NON HEAP: 125/129/-1 MB (used/committed/max)]
2017-04-05 17:54:20 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 17:54:20 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='229944996b8c35fca86228f3a6f75d58'} has started.
2017-04-05 17:54:20 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 6721e9dfac2db6e41e13af0048dafb73. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 17:54:20 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 17:54:20 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49307. Starting BLOB cache.
2017-04-05 17:54:20 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-9e93bdde-88ea-4e90-960f-c4d2971a2174
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 2bba1cec7b12ec92a1b967c7c86ad0d7)) but there is no connection to a JobManager yet.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7).
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-537810066].
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-537810066]
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) and wait for progress
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 17:54:20 INFO  JobManager:128 - Submitting job 2bba1cec7b12ec92a1b967c7c86ad0d7 (Flink Streaming Job).
2017-04-05 17:54:20 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 2bba1cec7b12ec92a1b967c7c86ad0d7.
2017-04-05 17:54:20 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7).
2017-04-05 17:54:20 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:111 - Job 2bba1cec7b12ec92a1b967c7c86ad0d7 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 17:54:20 INFO  JobManager:128 - Scheduling job 2bba1cec7b12ec92a1b967c7c86ad0d7 (Flink Streaming Job).
2017-04-05 17:54:20 INFO  ExecutionGraph:965 - Job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) switched from state CREATED to RUNNING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:54:20	Job execution switched to status RUNNING.
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CREATED to SCHEDULED.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 17:54:20 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from SCHEDULED to DEPLOYING.
2017-04-05 17:54:20 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:20	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 17:54:20 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  TaskManager:128 - Received task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CREATED to DEPLOYING.
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21464451 for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@12a6816c for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) [DEPLOYING].
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@12dc0b76 for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:54:20 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1594b3e2 for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) [DEPLOYING].
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:20 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:20 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:20 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7c3e52c5 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@28edad46 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) [DEPLOYING].
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@32ebc724 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CREATED to DEPLOYING.
2017-04-05 17:54:21 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2a96c10b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:54:21 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) [DEPLOYING].
2017-04-05 17:54:21 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 17:54:21 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from DEPLOYING to RUNNING.
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:21	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 17:54:21 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 17:54:21 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 17:54:21 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:54:21 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 17:54:21 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 106, so the initial offset will be set to 105
2017-04-05 17:54:21 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 97, so the initial offset will be set to 96
2017-04-05 17:54:30 INFO  Task:875 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from RUNNING to FAILED.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (2/4)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (d4df409c6a75bd48f0539d493afca953)
2017-04-05 17:54:30 INFO  ExecutionGraph:1027 - Source: Custom Source -> Map -> Timestamps/Watermarks (2/4) (d4df409c6a75bd48f0539d493afca953) switched from RUNNING to FAILED.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  ExecutionGraph:965 - Job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) switched from state RUNNING to FAILING.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(2/4) switched to FAILED 
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:280 - 04/05/2017 17:54:30	Job execution switched to status FAILING.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076).
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to CANCELING 
2017-04-05 17:54:30 INFO  TaskManager:128 - Discarding the results produced by task execution d4df409c6a75bd48f0539d493afca953
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (1/4)
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734).
2017-04-05 17:54:30 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from RUNNING to CANCELING.
2017-04-05 17:54:30 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2).
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (090a3afa2372967bd630884ffd158076)
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (1/4) (090a3afa2372967bd630884ffd158076) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(1/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904).
2017-04-05 17:54:30 INFO  Task:873 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca).
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (4/4)
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map -> Timestamps/Watermarks (3/4)
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2).
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734).
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (b4676fb77e2bb01b68357ad7fe862aca)
2017-04-05 17:54:30 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22).
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (b2763d111246a28b4f694751137856a7)
2017-04-05 17:54:30 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Timestamps/Watermarks (c22292e8b8bf8dc76611ae5ebb25c904)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (0891ebde647479dcb0c25158ebecc734)
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (6c6ddbb5ce9cd9ffdd1ab439a77565e2)
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (4/4) (b4676fb77e2bb01b68357ad7fe862aca) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (b33e2c0b47173fa65d7c6584307a3e22)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(4/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (b2763d111246a28b4f694751137856a7) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map -> Timestamps/Watermarks (3/4) (c22292e8b8bf8dc76611ae5ebb25c904) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0891ebde647479dcb0c25158ebecc734) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (6c6ddbb5ce9cd9ffdd1ab439a77565e2) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	Source: Custom Source -> Map -> Timestamps/Watermarks(3/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (b33e2c0b47173fa65d7c6584307a3e22) switched from CANCELING to CANCELED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) if no longer possible.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:265 - 04/05/2017 17:54:30	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@10b8d602}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-05 17:54:30 INFO  ExecutionGraph:965 - Job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) switched from state FAILING to FAILED.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:275 - 04/05/2017 17:54:30	Job execution switched to status FAILED.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-05 17:54:30 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#-537810066].
2017-04-05 17:54:30 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (2bba1cec7b12ec92a1b967c7c86ad0d7) because the restart strategy prevented it.
java.time.temporal.UnsupportedTemporalTypeException: Unsupported field: SecondOfMinute
	at java.time.Instant.get(Instant.java:566)
	at io.neons.common.log.Timestampable$class.isWatermark(Log.scala:13)
	at io.neons.common.log.Log.isWatermark(Log.scala:16)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:40)
	at io.neons.streamer.Application$$anon$13.checkAndGetNextWatermark(Application.scala:36)
	at org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartitionStateWithPunctuatedWatermarks.checkAndGetNewWatermark(KafkaTopicPartitionStateWithPunctuatedWatermarks.java:63)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestampAndPunctuatedWatermark(AbstractFetcher.java:315)
	at org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher.emitRecordWithTimestamp(AbstractFetcher.java:269)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka010Fetcher.emitRecord(Kafka010Fetcher.java:88)
	at org.apache.flink.streaming.connectors.kafka.internal.Kafka09Fetcher.runFetchLoop(Kafka09Fetcher.java:157)
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:255)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:78)
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:55)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.run(SourceStreamTask.java:56)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-05 17:54:30 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job 2bba1cec7b12ec92a1b967c7c86ad0d7
2017-04-05 17:54:30 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-05 17:54:30 INFO  JobClient:320 - Job execution failed
2017-04-05 17:54:30 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-05 17:54:30 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#-853602967.
2017-04-05 17:54:30 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-05 17:54:30 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-05 17:54:30 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-05 17:54:30 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:49307
2017-04-05 17:54:30 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1e55bd35-cb36-4287-a438-7a0b8991ceb3
2017-04-05 17:54:30 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-05 17:54:30 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-05 18:08:25 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:08:25 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:08:25 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:08:25 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:08:26 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:08:26 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-3c442964-dbba-4cbb-83c5-a78037326cdf
2017-04-05 18:08:26 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49334 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:08:26 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:08:26 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:08:26 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:08:26 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:08:26 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 18:08:26 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:08:26 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:08:26 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1226324929] - leader session null
2017-04-05 18:08:26 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:08:26 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 18:08:26 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-5b2b6251-44f6-4dbd-8a31-aaffabfbe0e8 for spill files.
2017-04-05 18:08:26 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:08:26 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-486ef175-df49-42da-bdd2-0562bdd67d2c
2017-04-05 18:08:26 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1214731962.
2017-04-05 18:08:26 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='932d8c3dd5dc7cfca926147fff22a38d'} @ localhost (dataPort=-1)
2017-04-05 18:08:26 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:08:26 INFO  TaskManager:128 - Memory usage stats: [HEAP: 172/853/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 18:08:26 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:08:26 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='932d8c3dd5dc7cfca926147fff22a38d'} has started.
2017-04-05 18:08:26 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as f02057d45753cee7b280d2958405f0ed. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:08:26 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:08:26 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49334. Starting BLOB cache.
2017-04-05 18:08:26 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-db0f6fb2-dcff-43bc-bd2f-8e86de2e5357
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 04e81d830f13ba257fb5651a504777c1)) but there is no connection to a JobManager yet.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1).
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1226324929].
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1226324929]
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1) and wait for progress
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:08:26 INFO  JobManager:128 - Submitting job 04e81d830f13ba257fb5651a504777c1 (Flink Streaming Job).
2017-04-05 18:08:26 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 04e81d830f13ba257fb5651a504777c1.
2017-04-05 18:08:26 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1).
2017-04-05 18:08:26 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:111 - Job 04e81d830f13ba257fb5651a504777c1 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:08:27 INFO  JobManager:128 - Scheduling job 04e81d830f13ba257fb5651a504777c1 (Flink Streaming Job).
2017-04-05 18:08:27 INFO  ExecutionGraph:965 - Job Flink Streaming Job (04e81d830f13ba257fb5651a504777c1) switched from state CREATED to RUNNING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:08:27	Job execution switched to status RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from CREATED to SCHEDULED.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:08:27 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21c3f8cd for Source: Custom Source -> Map (1/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) [DEPLOYING].
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@77da1602 for Source: Custom Source -> Map (2/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) [DEPLOYING].
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7f48430e for Source: Custom Source -> Map (4/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) [DEPLOYING].
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49dc85e2 for Source: Custom Source -> Map (3/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@72c95fb5 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:08:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from CREATED to DEPLOYING.
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@231bb157 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) [DEPLOYING].
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@588b630 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) [DEPLOYING].
2017-04-05 18:08:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@729453e1 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:08:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) [DEPLOYING].
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (02a1312bf101df7a8215d0a288ac75dc) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (ca50229384947a0b3c55a0b5ff9f7d31) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e9fa4d2a1234d226c79c3449d9ecd38e) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ce39de1fd8fb7ced0092580f7120c5bf) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c48dcf4ea597b874fd1d88d1f61b7a32) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2f4c0729aa0382289a5a59cada89a6e5) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (18b84ed1fb64f35becbd08d9627a938d) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af2c364b52a0b07a624a8d0d69e8457) switched from DEPLOYING to RUNNING.
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:08:27	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@8a7d35e8}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:28 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:08:28 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:08:28 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:08:28 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:08:28 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:08:28 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 97, so the initial offset will be set to 96
2017-04-05 18:08:28 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 107, so the initial offset will be set to 106
2017-04-05 18:13:46 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:13:47 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:13:47 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:13:47 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:13:48 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:13:48 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-feb2c1c9-bb38-4a3e-9fe7-d16104d05019
2017-04-05 18:13:48 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49361 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:13:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:13:48 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:13:48 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:13:48 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:13:48 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:13:48 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 18:13:48 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1227038263] - leader session null
2017-04-05 18:13:48 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:13:48 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:13:48 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 18:13:48 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-4bc9c59b-aaf3-4714-9473-b5e7963c47c4 for spill files.
2017-04-05 18:13:48 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:13:48 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-3a9c4e56-7797-40ba-8642-e7d33d14321f
2017-04-05 18:13:48 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1718370412.
2017-04-05 18:13:48 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='1b3bd274e8d2e1332fb73acc18bebb37'} @ localhost (dataPort=-1)
2017-04-05 18:13:48 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:13:48 INFO  TaskManager:128 - Memory usage stats: [HEAP: 178/848/910 MB, NON HEAP: 124/129/-1 MB (used/committed/max)]
2017-04-05 18:13:48 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:13:48 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='1b3bd274e8d2e1332fb73acc18bebb37'} has started.
2017-04-05 18:13:48 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 59d793d66689e2a80aef5c358fc5161f. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:13:48 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:13:48 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49361. Starting BLOB cache.
2017-04-05 18:13:48 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c544b3b4-45fc-4a50-99fd-302130da60b6
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 6722c410008234a62da538d901b0df00)) but there is no connection to a JobManager yet.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (6722c410008234a62da538d901b0df00).
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1227038263].
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1227038263]
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (6722c410008234a62da538d901b0df00) and wait for progress
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:13:48 INFO  JobManager:128 - Submitting job 6722c410008234a62da538d901b0df00 (Flink Streaming Job).
2017-04-05 18:13:48 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 6722c410008234a62da538d901b0df00.
2017-04-05 18:13:48 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (6722c410008234a62da538d901b0df00).
2017-04-05 18:13:48 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:111 - Job 6722c410008234a62da538d901b0df00 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:13:48 INFO  JobManager:128 - Scheduling job 6722c410008234a62da538d901b0df00 (Flink Streaming Job).
2017-04-05 18:13:48 INFO  ExecutionGraph:965 - Job Flink Streaming Job (6722c410008234a62da538d901b0df00) switched from state CREATED to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:13:48	Job execution switched to status RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from CREATED to SCHEDULED.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:13:48 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4f255bb2 for Source: Custom Source -> Map (3/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) [DEPLOYING].
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@9e18a33 for Source: Custom Source -> Map (4/4)
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4050f019 for Source: Custom Source -> Map (2/4)
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5bfd1c91 for Source: Custom Source -> Map (1/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3b5b100a for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6ead8c9f for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@751db6e4 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) [DEPLOYING].
2017-04-05 18:13:48 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from CREATED to DEPLOYING.
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) [DEPLOYING].
2017-04-05 18:13:48 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2098a8f8 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:13:48 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) [DEPLOYING].
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (8fbcb3b56858b170682d0a2328ff5970) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (eeb787d1b08c4453e19b66899bd8c28e) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81549478c87493a3c006046a5ce09ae7) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  Task:873 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (f38d833f29cc619e3838877f08363c29) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4a8922a1b846b5289429f4eb57618ac6) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:13:48 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b4bf8b5cfeadcbce96fbf1a6b792eb93) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (68047256bd291d10180a1c940752c978) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (fed2027c826050559d1b81f3b2562b8f) switched from DEPLOYING to RUNNING.
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:13:48	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@ebf352e5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:13:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:13:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:13:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:13:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:13:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 100, so the initial offset will be set to 99
2017-04-05 18:13:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 107, so the initial offset will be set to 106
2017-04-05 18:26:31 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:26:32 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:26:32 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:26:32 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:26:33 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:26:33 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c7e64288-f900-49d6-a283-2bef1aa9ab6a
2017-04-05 18:26:33 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49403 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:26:33 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:26:33 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:26:33 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:26:33 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:26:33 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:26:34 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#364019187] - leader session null
2017-04-05 18:26:34 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:26:34 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 12 GB (10,81% usable)
2017-04-05 18:26:34 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:26:34 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:26:34 INFO  TaskManager:128 - Limiting managed memory to 262 MB, memory will be allocated lazily.
2017-04-05 18:26:34 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-30774dd5-77c8-497e-bbaa-dd93b5e3caf0 for spill files.
2017-04-05 18:26:34 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:26:34 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-0f276644-8d25-4c34-8b46-04f10f86757a
2017-04-05 18:26:34 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1749889302.
2017-04-05 18:26:34 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='efda1b416438bae96aeb82373cec5e7a'} @ localhost (dataPort=-1)
2017-04-05 18:26:34 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:26:34 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/930/930 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-05 18:26:34 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:26:34 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='efda1b416438bae96aeb82373cec5e7a'} has started.
2017-04-05 18:26:34 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as aecf718c0e7de5b2e5843b526f44df73. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:26:34 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:26:34 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49403. Starting BLOB cache.
2017-04-05 18:26:34 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-e2bbdaff-f715-4a00-a6f5-ae6718d27222
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 049b9e884eef8930762f3520cbea6a29)) but there is no connection to a JobManager yet.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29).
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#364019187].
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#364019187]
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29) and wait for progress
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:26:34 INFO  JobManager:128 - Submitting job 049b9e884eef8930762f3520cbea6a29 (Flink Streaming Job).
2017-04-05 18:26:34 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 049b9e884eef8930762f3520cbea6a29.
2017-04-05 18:26:34 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29).
2017-04-05 18:26:34 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:111 - Job 049b9e884eef8930762f3520cbea6a29 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:26:34 INFO  JobManager:128 - Scheduling job 049b9e884eef8930762f3520cbea6a29 (Flink Streaming Job).
2017-04-05 18:26:34 INFO  ExecutionGraph:965 - Job Flink Streaming Job (049b9e884eef8930762f3520cbea6a29) switched from state CREATED to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:26:34	Job execution switched to status RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from CREATED to SCHEDULED.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:26:34 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@767f7ba3 for Source: Custom Source -> Map (1/4)
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@27c26170 for Source: Custom Source -> Map (2/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) [DEPLOYING].
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2d04a34b for Source: Custom Source -> Map (3/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@68ff89c8 for Source: Custom Source -> Map (4/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1c559c17 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3153451b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25d790c0 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from CREATED to DEPLOYING.
2017-04-05 18:26:34 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@45643206 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:26:34 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) [DEPLOYING].
2017-04-05 18:26:34 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:26:34 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c0fdd9042232bf852e9f4a5ca15caa9) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d57bf746590a5360bedea70c1c61d864) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7da953cc8c3822acd5dfcc0625260a06) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (1e5045d8513f10a1149266c8d3dcba98) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (4c16dc2e75c0cd3bada38bacd9b17fda) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (dac5cb614b44920d9d0c3ba1cadaec17) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (ee8eacdccf7575aeded21f5f1020b136) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (2c5653ffb243f9ef9439100da90badb1) switched from DEPLOYING to RUNNING.
2017-04-05 18:26:34 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:26:34	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@b8a97cad}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:26:35 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:26:35 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:26:35 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:26:35 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 109, so the initial offset will be set to 108
2017-04-05 18:26:35 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:26:35 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 100, so the initial offset will be set to 99
2017-04-05 18:29:49 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 18:29:49 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 18:29:50 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 18:29:50 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 18:29:50 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 18:29:50 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-8e78cb7a-8870-4e64-838f-2c6b0dff4610
2017-04-05 18:29:50 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49423 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 18:29:50 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:29:50 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 18:29:50 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 18:29:50 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 18:29:50 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 18:29:50 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 12 GB (10,81% usable)
2017-04-05 18:29:50 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 18:29:50 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#56451658] - leader session null
2017-04-05 18:29:50 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 18:29:50 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 18:29:50 INFO  TaskManager:128 - Limiting managed memory to 264 MB, memory will be allocated lazily.
2017-04-05 18:29:50 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-ba6602bd-5de3-4474-ad07-a4a16be14b4f for spill files.
2017-04-05 18:29:51 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 18:29:51 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-f5111c75-51ce-4d93-93f3-625ff7cb8d4a
2017-04-05 18:29:51 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#323181437.
2017-04-05 18:29:51 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='50b7dc738eda5e24f49e8d323f7b4ce7'} @ localhost (dataPort=-1)
2017-04-05 18:29:51 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 18:29:51 INFO  TaskManager:128 - Memory usage stats: [HEAP: 172/934/934 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 18:29:51 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 18:29:51 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='50b7dc738eda5e24f49e8d323f7b4ce7'} has started.
2017-04-05 18:29:51 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as cdcb20ddecfca0cf698caaed963b3596. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 18:29:51 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 18:29:51 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49423. Starting BLOB cache.
2017-04-05 18:29:51 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-24ea038f-fb75-4206-896c-c8cbf596143b
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: e141bf12e96eaf61fd6b196a90604eac)) but there is no connection to a JobManager yet.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac).
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#56451658].
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#56451658]
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac) and wait for progress
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 18:29:51 INFO  JobManager:128 - Submitting job e141bf12e96eaf61fd6b196a90604eac (Flink Streaming Job).
2017-04-05 18:29:51 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for e141bf12e96eaf61fd6b196a90604eac.
2017-04-05 18:29:51 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac).
2017-04-05 18:29:51 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:111 - Job e141bf12e96eaf61fd6b196a90604eac was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 18:29:51 INFO  JobManager:128 - Scheduling job e141bf12e96eaf61fd6b196a90604eac (Flink Streaming Job).
2017-04-05 18:29:51 INFO  ExecutionGraph:965 - Job Flink Streaming Job (e141bf12e96eaf61fd6b196a90604eac) switched from state CREATED to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:275 - 04/05/2017 18:29:51	Job execution switched to status RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from CREATED to SCHEDULED.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from SCHEDULED to DEPLOYING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 18:29:51 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@738e8b72 for Source: Custom Source -> Map (2/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) [DEPLOYING].
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@10cc93b for Source: Custom Source -> Map (1/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@776c8f06 for Source: Custom Source -> Map (3/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@464387dc for Source: Custom Source -> Map (4/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@679e31eb for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1eb8f25f for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@958277f for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from CREATED to DEPLOYING.
2017-04-05 18:29:51 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@12fa75fc for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 18:29:51 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) [DEPLOYING].
2017-04-05 18:29:51 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 18:29:51 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4a29dbd32e284f40e7c6a68c4e380f9e) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0c075d0dfa112adda394aa3210faa3f7) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9d52ee43107a685a748ac482dae4600c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (96af35a9117caeb187f815f4ec150183) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (6a037d97310ed64792423f5a37240b7c) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4e55f602f7a9596f743d708efe5e398a) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (0c73b90224f8164e9079adb49fb48f4f) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (4baf388463fb4ee2dede945731738b6d) switched from DEPLOYING to RUNNING.
2017-04-05 18:29:51 INFO  JobSubmissionClientActor:265 - 04/05/2017 18:29:51	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@13be953a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:51 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 18:29:52 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 18:29:52 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:29:52 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 18:29:52 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 109, so the initial offset will be set to 108
2017-04-05 18:29:52 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 101, so the initial offset will be set to 100
2017-04-05 20:16:58 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:16:58 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:16:59 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:16:59 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:16:59 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:16:59 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-fb530415-c2d8-4756-8bb0-a94c0b2d1f7d
2017-04-05 20:17:00 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49975 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:17:00 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:17:00 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:17:00 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:17:00 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:17:00 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:17:00 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:17:00 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#273657099] - leader session null
2017-04-05 20:17:00 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:17:00 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:17:00 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:17:00 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-3c5b9b74-70da-4fca-91ec-3ad2427ba7db for spill files.
2017-04-05 20:17:00 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:17:00 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-3b8efeea-d864-4411-aec7-0be607c087df
2017-04-05 20:17:00 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1155939688.
2017-04-05 20:17:00 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='41552bede422dad1c79365708a95c6a4'} @ localhost (dataPort=-1)
2017-04-05 20:17:00 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:17:00 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/870/910 MB, NON HEAP: 125/127/-1 MB (used/committed/max)]
2017-04-05 20:17:00 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:17:00 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='41552bede422dad1c79365708a95c6a4'} has started.
2017-04-05 20:17:00 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 50ce07c5490c7075fb22c900c3a349ad. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:17:00 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:17:00 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49975. Starting BLOB cache.
2017-04-05 20:17:00 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-21cf5ce2-ba00-4705-b916-728601aebd53
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 12ec278e028f3c7eaef30ea8796ed768)) but there is no connection to a JobManager yet.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768).
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#273657099].
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#273657099]
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768) and wait for progress
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:17:00 INFO  JobManager:128 - Submitting job 12ec278e028f3c7eaef30ea8796ed768 (Flink Streaming Job).
2017-04-05 20:17:00 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 12ec278e028f3c7eaef30ea8796ed768.
2017-04-05 20:17:00 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768).
2017-04-05 20:17:00 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:17:00 INFO  JobManager:128 - Scheduling job 12ec278e028f3c7eaef30ea8796ed768 (Flink Streaming Job).
2017-04-05 20:17:00 INFO  ExecutionGraph:965 - Job Flink Streaming Job (12ec278e028f3c7eaef30ea8796ed768) switched from state CREATED to RUNNING.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:111 - Job 12ec278e028f3c7eaef30ea8796ed768 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:17:00	Job execution switched to status RUNNING.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from CREATED to SCHEDULED.
2017-04-05 20:17:00 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:17:00 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:17:00 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:00	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@8235b82 for Source: Custom Source -> Map (1/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) [DEPLOYING].
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@132c6b3a for Source: Custom Source -> Map (2/4)
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3751cc96 for Source: Custom Source -> Map (3/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) [DEPLOYING].
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@20aba2 for Source: Custom Source -> Map (4/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) [DEPLOYING].
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  Task:873 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4e9926a2 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5286b4a6 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7a4079b1 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from CREATED to DEPLOYING.
2017-04-05 20:17:01 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@445df11e for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:17:01 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) [DEPLOYING].
2017-04-05 20:17:01 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:17:01 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (337fceb813268d9e51ccf4b95d88d1f5) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (caa4ad0e266ab9ef4808878ad9bd0275) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f9fea7fb7a87b8cfe4ea370dd308ee48) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (63424df117f849ad06e6348121bf1bee) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (1c3ae29574c8b6a74e83da387f118d15) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b4ebd4e95c4e54a2ba0c012492d40968) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (fcd686ecb455c54afb14aecacbd4f102) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (f2bee4a9bad39eb86be08b3da2f5a18c) switched from DEPLOYING to RUNNING.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:17:01	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a8733a1}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:01 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:01 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:17:02 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:17:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:02 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:17:02 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:17:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:17:02 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:17:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 111, so the initial offset will be set to 110
2017-04-05 20:17:02 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 105, so the initial offset will be set to 104
2017-04-05 20:18:41 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:18:42 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:18:42 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:18:42 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:18:43 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:18:43 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-f57abe2a-31af-4934-a8dd-4fbe698b17ae
2017-04-05 20:18:43 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50011 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:18:43 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:18:43 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:18:43 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:18:43 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:18:43 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:18:43 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:18:43 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:18:43 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-790443083] - leader session null
2017-04-05 20:18:43 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:18:43 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:18:43 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-b21c41d5-cd6d-4bca-bb4d-65e39b4f300b for spill files.
2017-04-05 20:18:43 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:18:43 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-13211b9a-7500-4ddc-91fe-2736e6ca5fc1
2017-04-05 20:18:43 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1773129487.
2017-04-05 20:18:43 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='523645c9c18aa3956a5c0c538a85665d'} @ localhost (dataPort=-1)
2017-04-05 20:18:43 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:18:43 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/869/910 MB, NON HEAP: 125/128/-1 MB (used/committed/max)]
2017-04-05 20:18:43 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:18:43 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='523645c9c18aa3956a5c0c538a85665d'} has started.
2017-04-05 20:18:43 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 1e2b2b3712266dda7304d6f7bd883b2c. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:18:43 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:18:43 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50011. Starting BLOB cache.
2017-04-05 20:18:43 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-83a5352a-eb55-4bc1-aca9-47bb8b9e2da3
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: dbce4e4719c7e73bb0c0a6f439704d4a)) but there is no connection to a JobManager yet.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a).
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-790443083].
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-790443083]
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a) and wait for progress
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:18:43 INFO  JobManager:128 - Submitting job dbce4e4719c7e73bb0c0a6f439704d4a (Flink Streaming Job).
2017-04-05 20:18:43 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for dbce4e4719c7e73bb0c0a6f439704d4a.
2017-04-05 20:18:43 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a).
2017-04-05 20:18:43 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:111 - Job dbce4e4719c7e73bb0c0a6f439704d4a was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:18:43 INFO  JobManager:128 - Scheduling job dbce4e4719c7e73bb0c0a6f439704d4a (Flink Streaming Job).
2017-04-05 20:18:43 INFO  ExecutionGraph:965 - Job Flink Streaming Job (dbce4e4719c7e73bb0c0a6f439704d4a) switched from state CREATED to RUNNING.
2017-04-05 20:18:43 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from CREATED to SCHEDULED.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:18:43	Job execution switched to status RUNNING.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:43	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:18:43 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:43 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:43	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:18:43 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from CREATED to SCHEDULED.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@500bea57 for Source: Custom Source -> Map (1/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d7f4423 for Source: Custom Source -> Map (2/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) [DEPLOYING].
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2098a8f8 for Source: Custom Source -> Map (3/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@39d0f011 for Source: Custom Source -> Map (4/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) [DEPLOYING].
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@21b91983 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) [DEPLOYING].
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) [DEPLOYING].
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e742846 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from CREATED to DEPLOYING.
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3c1a7d5e for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@303d4ad2 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) [DEPLOYING].
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2d81461d07a34aeb7a84dc87ef0ebddc) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2be4a0f2fc49b0087d5f0ef4e1ce0ea3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6dbf4a75d441f02341d170c3e80d4ff3) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (774dd77606165af181b76f9129232847) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (90db7b4a51c071324955d3c21ff122d8) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (f400d9122c3dd51fe6b81a19d860ebb2) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0577f0c65b3b918ab4f1f1a135c0b177) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (a10712c665e560ba77a4f62a902dcafb) switched from DEPLOYING to RUNNING.
2017-04-05 20:18:44 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:18:44	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@c30987a6}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:18:45 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:18:45 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:18:45 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 112, so the initial offset will be set to 111
2017-04-05 20:18:45 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 105, so the initial offset will be set to 104
2017-04-05 20:20:03 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:20:03 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:20:04 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:20:04 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:20:04 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:20:04 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0c708173-d69f-42e1-a70b-75dcd8880e01
2017-04-05 20:20:04 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50030 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:20:04 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:20:04 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:20:04 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:20:04 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:20:05 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:20:05 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:20:05 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:20:05 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1335381870] - leader session null
2017-04-05 20:20:05 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:20:05 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:20:05 INFO  TaskManager:128 - Limiting managed memory to 256 MB, memory will be allocated lazily.
2017-04-05 20:20:05 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1deea318-87f5-447b-b1a2-7cfb04387365 for spill files.
2017-04-05 20:20:05 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:20:05 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-ae930504-7718-4e4a-8182-afe63bfdb543
2017-04-05 20:20:05 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#708318888.
2017-04-05 20:20:05 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='76fbbea7e472e23b61242c1382af65af'} @ localhost (dataPort=-1)
2017-04-05 20:20:05 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:20:05 INFO  TaskManager:128 - Memory usage stats: [HEAP: 172/912/912 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:20:05 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:20:05 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='76fbbea7e472e23b61242c1382af65af'} has started.
2017-04-05 20:20:05 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 5240fdcaf60257a16d46c346c6d2d11e. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:20:05 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:20:05 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50030. Starting BLOB cache.
2017-04-05 20:20:05 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-e72ce0f6-f8ec-4f1c-a159-8e80338055c3
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 88af4eba71fff074d95630ef3675bf42)) but there is no connection to a JobManager yet.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42).
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1335381870].
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1335381870]
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42) and wait for progress
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:20:05 INFO  JobManager:128 - Submitting job 88af4eba71fff074d95630ef3675bf42 (Flink Streaming Job).
2017-04-05 20:20:05 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 88af4eba71fff074d95630ef3675bf42.
2017-04-05 20:20:05 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42).
2017-04-05 20:20:05 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:111 - Job 88af4eba71fff074d95630ef3675bf42 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:20:05 INFO  JobManager:128 - Scheduling job 88af4eba71fff074d95630ef3675bf42 (Flink Streaming Job).
2017-04-05 20:20:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (88af4eba71fff074d95630ef3675bf42) switched from state CREATED to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:20:05	Job execution switched to status RUNNING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from CREATED to SCHEDULED.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:20:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@586c4498 for Source: Custom Source -> Map (4/4)
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@72c95fb5 for Source: Custom Source -> Map (3/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) [DEPLOYING].
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@77dfe0d8 for Source: Custom Source -> Map (2/4)
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5460e2ca for Source: Custom Source -> Map (1/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@776c8f06 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e742846 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3924b24b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from CREATED to DEPLOYING.
2017-04-05 20:20:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3910a064 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:20:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) [DEPLOYING].
2017-04-05 20:20:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:20:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a124be67348c28245874c7b10396f700) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a293f6c4cf13da2cc0e8ba84f914c0a4) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (f297d1f33062c6d4ed0cf4e39d15d06a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (aab7f7aac5cfb69a37801a1393da4acf) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (4ce0e35d5c6ca98f1534d81a49d66e0a) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (8c1e975cd06d3d3bed8e268dc074fce9) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (c6d191afda6cad30c5390c87fb51e030) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (52d553512d088d4de934c6fe2d288e56) switched from DEPLOYING to RUNNING.
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:20:05	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@3d0da606}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:20:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:20:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:20:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:20:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:20:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 113, so the initial offset will be set to 112
2017-04-05 20:20:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 106, so the initial offset will be set to 105
2017-04-05 20:24:29 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:24:29 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:24:29 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:24:30 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:24:30 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:24:30 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0b91a19f-64fd-4e74-bad5-5f601ccf222b
2017-04-05 20:24:30 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50074 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:24:30 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:24:30 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:24:30 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:24:30 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:24:30 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:24:30 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:24:30 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#687904542] - leader session null
2017-04-05 20:24:30 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:24:30 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:24:30 INFO  TaskManager:128 - Limiting managed memory to 261 MB, memory will be allocated lazily.
2017-04-05 20:24:30 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-a5e048d4-fc73-4e5a-87ef-0bd60b7a985c for spill files.
2017-04-05 20:24:30 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:24:30 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-eccdfed0-81e5-4cb2-86c6-87d7f85cd11c
2017-04-05 20:24:30 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-451548543.
2017-04-05 20:24:30 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='28961281f49daf82317f7fd4cc9d46ae'} @ localhost (dataPort=-1)
2017-04-05 20:24:30 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:24:30 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/927/927 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:24:30 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:24:30 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='28961281f49daf82317f7fd4cc9d46ae'} has started.
2017-04-05 20:24:30 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 639082f5057c2c9d5b6b937de6a7aea3. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:24:30 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:24:30 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50074. Starting BLOB cache.
2017-04-05 20:24:30 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-3aa0ed42-8606-436d-98ca-f0f6b8f5d377
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 05f189d2f511af676fe53b34025908fd)) but there is no connection to a JobManager yet.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (05f189d2f511af676fe53b34025908fd).
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#687904542].
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#687904542]
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (05f189d2f511af676fe53b34025908fd) and wait for progress
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:24:30 INFO  JobManager:128 - Submitting job 05f189d2f511af676fe53b34025908fd (Flink Streaming Job).
2017-04-05 20:24:30 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 05f189d2f511af676fe53b34025908fd.
2017-04-05 20:24:31 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (05f189d2f511af676fe53b34025908fd).
2017-04-05 20:24:31 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:111 - Job 05f189d2f511af676fe53b34025908fd was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:24:31 INFO  JobManager:128 - Scheduling job 05f189d2f511af676fe53b34025908fd (Flink Streaming Job).
2017-04-05 20:24:31 INFO  ExecutionGraph:965 - Job Flink Streaming Job (05f189d2f511af676fe53b34025908fd) switched from state CREATED to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:24:31	Job execution switched to status RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from CREATED to SCHEDULED.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:24:31 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2295631b for Source: Custom Source -> Map (2/4)
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@476664eb for Source: Custom Source -> Map (1/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@699dcb4a for Source: Custom Source -> Map (3/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2099fc3 for Source: Custom Source -> Map (4/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2aba7436 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@30334796 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3b5cf8e8 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:24:31 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from CREATED to DEPLOYING.
2017-04-05 20:24:31 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1e574b0b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:24:31 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) [DEPLOYING].
2017-04-05 20:24:31 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:24:31 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b92c3bb8d0e7287ff6e152fe81d49e02) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (81d366214ba07f87ce1679e667a9daa9) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (70dffb4703c7e0e2785113f25a9dc07e) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d68336b65384f6a09d18ecee1bdfc2a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (606856de6a41170595eab9658851b626) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (30846c9519eeb1836b4227de4bf03d4f) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (aff3137580467feff163a4c995115113) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (77dac23d6be0b57e8deeaa84bde97fc8) switched from DEPLOYING to RUNNING.
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:24:31	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@501979d9}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:31 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:24:32 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:24:32 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:24:32 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:24:32 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:24:32 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 106, so the initial offset will be set to 105
2017-04-05 20:24:32 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 114, so the initial offset will be set to 113
2017-04-05 20:32:43 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:32:44 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:32:45 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:32:45 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:32:45 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:32:45 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-f63793bf-91ef-49a1-b96c-28b593b9a34d
2017-04-05 20:32:45 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50147 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:32:45 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:32:45 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:32:45 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:32:45 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:32:45 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:32:45 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:32:45 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:32:45 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1973105179] - leader session null
2017-04-05 20:32:45 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:32:45 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:32:45 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:32:45 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-1273f216-4848-4446-b1fe-ef4cb97233bb for spill files.
2017-04-05 20:32:45 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:32:45 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-76a884cd-9e17-43dc-8afb-0d3ea4a1dd97
2017-04-05 20:32:45 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#70152146.
2017-04-05 20:32:45 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='393047e8aa734e0ae0aa6a89237a12b8'} @ localhost (dataPort=-1)
2017-04-05 20:32:45 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:32:45 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/897/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:32:45 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:32:45 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='393047e8aa734e0ae0aa6a89237a12b8'} has started.
2017-04-05 20:32:45 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 6f31f765f85b02782c3d4cc34d7dff10. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:32:46 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:32:46 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50147. Starting BLOB cache.
2017-04-05 20:32:46 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-642fcfa3-aaa1-4dc1-9a68-b404c5f87bf6
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: ab7ea14f665a8ff53aab52ef7c7c663b)) but there is no connection to a JobManager yet.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b).
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1973105179].
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1973105179]
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b) and wait for progress
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:32:46 INFO  JobManager:128 - Submitting job ab7ea14f665a8ff53aab52ef7c7c663b (Flink Streaming Job).
2017-04-05 20:32:46 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for ab7ea14f665a8ff53aab52ef7c7c663b.
2017-04-05 20:32:46 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b).
2017-04-05 20:32:46 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:111 - Job ab7ea14f665a8ff53aab52ef7c7c663b was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:32:46 INFO  JobManager:128 - Scheduling job ab7ea14f665a8ff53aab52ef7c7c663b (Flink Streaming Job).
2017-04-05 20:32:46 INFO  ExecutionGraph:965 - Job Flink Streaming Job (ab7ea14f665a8ff53aab52ef7c7c663b) switched from state CREATED to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:32:46	Job execution switched to status RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from CREATED to SCHEDULED.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:32:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@377ac88d for Source: Custom Source -> Map (1/4)
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@65d1aebb for Source: Custom Source -> Map (2/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) [DEPLOYING].
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3a46462f for Source: Custom Source -> Map (3/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@630862bb for Source: Custom Source -> Map (4/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) [DEPLOYING].
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5ff37b3c for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) [DEPLOYING].
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@28846d1d for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) [DEPLOYING].
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1f1bfea8 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) [DEPLOYING].
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from CREATED to DEPLOYING.
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1869f67b for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) [DEPLOYING].
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) [DEPLOYING].
2017-04-05 20:32:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:32:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cbcb990e0d8493722c80e860ede245a2) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (705f758e90894e2260f19d15ea01fbd5) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4ccb525ee38551bedff36330b5583961) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ba34c446b9dd7c428bf784774b29fc5f) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5eae479ec2ab6682dbe3cb0db9cd488) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (975e0072681e5be973cd21c55207ae5a) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (b628333b20c8e78112d272db6c5ec9fe) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (60483343772b13fcfadb18bd619d1812) switched from DEPLOYING to RUNNING.
2017-04-05 20:32:46 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:32:46	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@6c1d8f4a}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:32:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:32:47 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:47 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:32:47 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:47 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:32:47 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:32:47 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:32:47 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 116, so the initial offset will be set to 115
2017-04-05 20:32:47 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 107, so the initial offset will be set to 106
2017-04-05 20:39:49 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 20:39:49 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 20:39:50 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 20:39:50 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 20:39:51 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 20:39:51 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6cadf92e-c0d9-4a09-93ca-c22022aa42ef
2017-04-05 20:39:52 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50314 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 20:39:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:39:52 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 20:39:52 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 20:39:52 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 20:39:52 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 20:39:52 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 20:39:52 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#644205278] - leader session null
2017-04-05 20:39:52 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 20:39:52 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 20:39:52 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 20:39:52 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-587fd470-e186-4afb-975d-fe8a23dbbff7 for spill files.
2017-04-05 20:39:52 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 20:39:52 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-138c4a6c-29e6-425a-aa40-105661b38d16
2017-04-05 20:39:52 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1461939588.
2017-04-05 20:39:52 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='609f84850b823c00d85b6edea6a3255b'} @ localhost (dataPort=-1)
2017-04-05 20:39:52 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 20:39:52 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/879/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-05 20:39:52 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 20:39:52 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='609f84850b823c00d85b6edea6a3255b'} has started.
2017-04-05 20:39:52 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 7316b0777d3e338f7c92cce217732641. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 20:39:52 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 20:39:52 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50314. Starting BLOB cache.
2017-04-05 20:39:52 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6ed05c96-d706-4557-b7ae-adb9d544bf81
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: c081b7d81df0f50fabc0151cac02f2dc)) but there is no connection to a JobManager yet.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc).
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#644205278].
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#644205278]
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc) and wait for progress
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 20:39:52 INFO  JobManager:128 - Submitting job c081b7d81df0f50fabc0151cac02f2dc (Flink Streaming Job).
2017-04-05 20:39:52 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for c081b7d81df0f50fabc0151cac02f2dc.
2017-04-05 20:39:52 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc).
2017-04-05 20:39:52 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:111 - Job c081b7d81df0f50fabc0151cac02f2dc was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 20:39:52 INFO  JobManager:128 - Scheduling job c081b7d81df0f50fabc0151cac02f2dc (Flink Streaming Job).
2017-04-05 20:39:52 INFO  ExecutionGraph:965 - Job Flink Streaming Job (c081b7d81df0f50fabc0151cac02f2dc) switched from state CREATED to RUNNING.
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:275 - 04/05/2017 20:39:52	Job execution switched to status RUNNING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from CREATED to SCHEDULED.
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 20:39:52 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from SCHEDULED to DEPLOYING.
2017-04-05 20:39:52 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 20:39:52 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:52	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@706f10ee for Source: Custom Source -> Map (1/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) [DEPLOYING].
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4aa9a182 for Source: Custom Source -> Map (3/4)
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@75c01b31 for Source: Custom Source -> Map (2/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@578bbec6 for Source: Custom Source -> Map (4/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 INFO  Task:873 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@22edffdb for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@102201d3 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@53fd5740 for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:52 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from CREATED to DEPLOYING.
2017-04-05 20:39:52 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6fbedb6c for TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 20:39:52 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) [DEPLOYING].
2017-04-05 20:39:52 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:52 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 20:39:52 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (f1c3c5f62e1643c751847fbaeef2e446) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (62a3d658312c0a5f83338d2381faa19a) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (4b24fc264c3329fc25066393a81e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (626d8814b028c74846cc5e72dcd83d5d) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9bf066d02ba2288f009a67d49632e40b) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (163d998014b302a86a76a06c62d0193c) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (5cef766a4589d335eebf30aaa59a4a2f) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (4a553b97887b09952dea5cba2f7e5971) switched from DEPLOYING to RUNNING.
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  JobSubmissionClientActor:265 - 04/05/2017 20:39:53	TriggerWindow(EventTimeSessionWindows(20000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@a942bbc5}, EventTimeTrigger(), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:53 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:53 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 20:39:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 20:39:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 20:39:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:39:54 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 20:39:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 117, so the initial offset will be set to 116
2017-04-05 20:39:54 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 129, so the initial offset will be set to 128
2017-04-05 21:23:01 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 21:23:02 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 21:23:02 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 21:23:02 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 21:23:03 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 21:23:03 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-31a2d85a-f037-4f3c-81c6-5ced7100f230
2017-04-05 21:23:03 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50664 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 21:23:03 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 21:23:03 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 21:23:03 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 21:23:03 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 21:23:03 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 21:23:03 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 21:23:03 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1097320115] - leader session null
2017-04-05 21:23:03 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 21:23:03 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 21:23:03 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 21:23:03 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-62badd41-737a-4499-8077-a34b0fa70f48 for spill files.
2017-04-05 21:23:03 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 21:23:03 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-c29f0469-1ca8-47c3-ae3c-573925660c6c
2017-04-05 21:23:03 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1144019418.
2017-04-05 21:23:03 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='2a43b32694e030c5138deb48fa37d510'} @ localhost (dataPort=-1)
2017-04-05 21:23:03 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 21:23:03 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/848/910 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-05 21:23:03 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 21:23:03 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='2a43b32694e030c5138deb48fa37d510'} has started.
2017-04-05 21:23:03 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 26b156eddafc5de36f42c72aee20cfff. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 21:23:03 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 21:23:03 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50664. Starting BLOB cache.
2017-04-05 21:23:03 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-7accbd28-6b6b-46ae-8de8-8ba95660d0aa
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 833b98f5c5adb3ab2a2b0bb9290f82ea)) but there is no connection to a JobManager yet.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea).
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1097320115].
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1097320115]
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea) and wait for progress
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 21:23:03 INFO  JobManager:128 - Submitting job 833b98f5c5adb3ab2a2b0bb9290f82ea (Flink Streaming Job).
2017-04-05 21:23:03 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 833b98f5c5adb3ab2a2b0bb9290f82ea.
2017-04-05 21:23:03 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea).
2017-04-05 21:23:03 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:111 - Job 833b98f5c5adb3ab2a2b0bb9290f82ea was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 21:23:04 INFO  JobManager:128 - Scheduling job 833b98f5c5adb3ab2a2b0bb9290f82ea (Flink Streaming Job).
2017-04-05 21:23:04 INFO  ExecutionGraph:965 - Job Flink Streaming Job (833b98f5c5adb3ab2a2b0bb9290f82ea) switched from state CREATED to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:275 - 04/05/2017 21:23:04	Job execution switched to status RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from CREATED to SCHEDULED.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from SCHEDULED to DEPLOYING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 21:23:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@71ff9151 for Source: Custom Source -> Map (2/4)
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2d029e99 for Source: Custom Source -> Map (1/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1ca5a964 for Source: Custom Source -> Map (3/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) [DEPLOYING].
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@19f9ec0c for Source: Custom Source -> Map (4/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  Task:873 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2099fc3 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6b0cb342 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@597e22a4 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) [DEPLOYING].
2017-04-05 21:23:04 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from CREATED to DEPLOYING.
2017-04-05 21:23:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6385882 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 21:23:04 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) [DEPLOYING].
2017-04-05 21:23:04 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 21:23:04 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (3aa49853bade72c69617ce9ce49ac34d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (be03aa341aee40aec02f433e38de948f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f4f8ffa53621943dbf44fe1362e41dad) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (15551c56a77c8f5f7c47dbcbb2a47f27) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (17540ff3b1f05e9e1d3e035099ddd45f) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (043803ca2220eafdac500015dc564c6d) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a04d9e4f5983b4afdd74f2a3d21171f8) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (e7b731c27332a8f439d05fa28b29f0ee) switched from DEPLOYING to RUNNING.
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  JobSubmissionClientActor:265 - 04/05/2017 21:23:04	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@4bd55298}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:04 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 21:23:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 21:23:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 21:23:05 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 21:23:05 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 21:23:05 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 131, so the initial offset will be set to 130
2017-04-05 21:23:05 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 120, so the initial offset will be set to 119
2017-04-05 22:01:53 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 22:01:53 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 22:01:54 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 22:01:54 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 22:01:54 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 22:01:54 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-1bdc134d-ebf1-4116-b0df-9af5476a3136
2017-04-05 22:01:55 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50761 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 22:01:55 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:01:55 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 22:01:55 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 22:01:55 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 22:01:55 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 22:01:55 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 22:01:55 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1051615375] - leader session null
2017-04-05 22:01:55 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 22:01:55 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 22:01:55 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 22:01:55 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-c97e0f28-9d64-459b-a09f-dc22fc9cfb2f for spill files.
2017-04-05 22:01:55 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:01:55 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-00f350d6-4168-48ef-ae37-d38c28e93f85
2017-04-05 22:01:55 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-238883264.
2017-04-05 22:01:55 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='158f03e527a93da72c6f15a39c70dd39'} @ localhost (dataPort=-1)
2017-04-05 22:01:55 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 22:01:55 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/861/910 MB, NON HEAP: 123/127/-1 MB (used/committed/max)]
2017-04-05 22:01:55 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 22:01:55 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='158f03e527a93da72c6f15a39c70dd39'} has started.
2017-04-05 22:01:55 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 538cb67627da10829a585f66fd1044e1. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 22:01:55 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 22:01:55 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50761. Starting BLOB cache.
2017-04-05 22:01:55 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0052ab92-3b5f-42a7-a0f9-ccf8508974d1
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 17b58dff67098ddb0fb21f0921c619ee)) but there is no connection to a JobManager yet.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee).
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1051615375].
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1051615375]
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee) and wait for progress
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 22:01:55 INFO  JobManager:128 - Submitting job 17b58dff67098ddb0fb21f0921c619ee (Flink Streaming Job).
2017-04-05 22:01:55 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 17b58dff67098ddb0fb21f0921c619ee.
2017-04-05 22:01:55 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee).
2017-04-05 22:01:55 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:111 - Job 17b58dff67098ddb0fb21f0921c619ee was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 22:01:55 INFO  JobManager:128 - Scheduling job 17b58dff67098ddb0fb21f0921c619ee (Flink Streaming Job).
2017-04-05 22:01:55 INFO  ExecutionGraph:965 - Job Flink Streaming Job (17b58dff67098ddb0fb21f0921c619ee) switched from state CREATED to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:275 - 04/05/2017 22:01:55	Job execution switched to status RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from CREATED to SCHEDULED.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 22:01:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2ecda439 for Source: Custom Source -> Map (1/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@e6178c for Source: Custom Source -> Map (2/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) [DEPLOYING].
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7eecea5a for Source: Custom Source -> Map (3/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) [DEPLOYING].
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@57793384 for Source: Custom Source -> Map (4/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@57b2a6b3 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3be67fad for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4d28250d for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from CREATED to DEPLOYING.
2017-04-05 22:01:55 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@37907ead for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:01:55 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) [DEPLOYING].
2017-04-05 22:01:55 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:01:55 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (2c1d61a673e93cc1da9ce2bc9b5326ee) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9722aa3a1818279b9941f741b47c0244) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2aa73b76cc6b3179225ee19926aa5f5f) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (5e509aa947d5a728d1d6b6000b4775ce) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (51218da47cd43763e5473e58f119bfd6) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (85eeabd0765ae0160c20688b2d3b4265) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (510be74dc1c0c4a5cad88cd20afa3d3b) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (0783064c6612ec9a49532d586617ad6c) switched from DEPLOYING to RUNNING.
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:01:55	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@5ad4affb}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:55 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:01:56 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:56 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:01:56 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:01:57 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:01:57 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:01:57 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 131, so the initial offset will be set to 130
2017-04-05 22:01:57 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 123, so the initial offset will be set to 122
2017-04-05 22:24:23 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-05 22:24:23 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-05 22:24:24 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-05 22:24:24 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-05 22:24:24 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-05 22:24:24 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c4934890-d7bb-467f-a136-bcd4399cb461
2017-04-05 22:24:24 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50874 - max concurrent requests: 50 - max backlog: 1000
2017-04-05 22:24:24 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:24:24 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-05 22:24:24 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-05 22:24:24 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-05 22:24:24 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-05 22:24:24 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-05 22:24:24 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-05 22:24:24 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-05 22:24:24 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-727700569] - leader session null
2017-04-05 22:24:24 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-05 22:24:24 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-05 22:24:25 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-e59c0823-8c35-4c8c-840c-ffc888a645ee for spill files.
2017-04-05 22:24:25 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-05 22:24:25 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-af6d95c5-1f69-4af1-82b6-d2ca83aab347
2017-04-05 22:24:25 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1329948128.
2017-04-05 22:24:25 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='f7e561919e14bc0649ff26d0803918c1'} @ localhost (dataPort=-1)
2017-04-05 22:24:25 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-05 22:24:25 INFO  TaskManager:128 - Memory usage stats: [HEAP: 171/831/910 MB, NON HEAP: 122/126/-1 MB (used/committed/max)]
2017-04-05 22:24:25 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-05 22:24:25 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='f7e561919e14bc0649ff26d0803918c1'} has started.
2017-04-05 22:24:25 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 2ff0fd7e798e1645a27197f50b327465. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-05 22:24:25 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-05 22:24:25 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50874. Starting BLOB cache.
2017-04-05 22:24:25 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-ed9e9f8b-827b-49cf-9aab-dd0d7c676a9a
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: e61e490082c7ea768359afa1c9a7e3cc)) but there is no connection to a JobManager yet.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc).
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-727700569].
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-727700569]
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc) and wait for progress
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-05 22:24:25 INFO  JobManager:128 - Submitting job e61e490082c7ea768359afa1c9a7e3cc (Flink Streaming Job).
2017-04-05 22:24:25 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for e61e490082c7ea768359afa1c9a7e3cc.
2017-04-05 22:24:25 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc).
2017-04-05 22:24:25 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:111 - Job e61e490082c7ea768359afa1c9a7e3cc was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-05 22:24:25 INFO  JobManager:128 - Scheduling job e61e490082c7ea768359afa1c9a7e3cc (Flink Streaming Job).
2017-04-05 22:24:25 INFO  ExecutionGraph:965 - Job Flink Streaming Job (e61e490082c7ea768359afa1c9a7e3cc) switched from state CREATED to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:275 - 04/05/2017 22:24:25	Job execution switched to status RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from CREATED to SCHEDULED.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from SCHEDULED to DEPLOYING.
2017-04-05 22:24:25 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2891a710 for Source: Custom Source -> Map (2/4)
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6affde57 for Source: Custom Source -> Map (3/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) [DEPLOYING].
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@453c965e for Source: Custom Source -> Map (1/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) [DEPLOYING].
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3751cc96 for Source: Custom Source -> Map (4/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) [DEPLOYING].
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@41726f29 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) [DEPLOYING].
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@270a258f for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d76e4d5 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from CREATED to DEPLOYING.
2017-04-05 22:24:25 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@31220e97 for TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-05 22:24:25 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) [DEPLOYING].
2017-04-05 22:24:25 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-05 22:24:25 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (1fa3373355a64d86ef0624a8fa471b89) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (cfc13d39ca1048c2655d9784a462f61f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (061c6cada236d4283c5c068d106cf76f) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6180b8a99dbbca1d9fa27f959e16a2f5) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (e5186bd275af49b81bd5d56a7952fd20) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (436b7f2bd38a27ad9c8995cefededcb6) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (dc03406c2e2b764a05cf5b334ff96225) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (301d7d0a86c9ae47538fceceb6039e24) switched from DEPLOYING to RUNNING.
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  JobSubmissionClientActor:265 - 04/05/2017 22:24:25	TriggerWindow(EventTimeSessionWindows(60000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@16a9cd72}, ContinuousEventTimeTrigger(20000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:25 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-05 22:24:26 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-05 22:24:26 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-05 22:24:26 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:24:26 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-05 22:24:26 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 123, so the initial offset will be set to 122
2017-04-05 22:24:26 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 134, so the initial offset will be set to 133
2017-04-07 09:28:41 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-07 09:28:41 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-07 09:28:43 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-07 09:28:43 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-07 09:28:44 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-07 09:28:44 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-1b75f3f5-bc5e-474f-bd45-4f5795400258
2017-04-07 09:28:44 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:61962 - max concurrent requests: 50 - max backlog: 1000
2017-04-07 09:28:44 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-07 09:28:44 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-07 09:28:44 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-07 09:28:44 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-07 09:28:44 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 8 GB (7,21% usable)
2017-04-07 09:28:44 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-07 09:28:44 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#639493118] - leader session null
2017-04-07 09:28:44 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-07 09:28:44 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-07 09:28:44 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-07 09:28:44 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-f4901cbc-66cb-4891-b442-01b0953cfbce for spill files.
2017-04-07 09:28:44 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-07 09:28:44 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-1f09bdb6-2708-438e-809d-3445fa8dd4ae
2017-04-07 09:28:44 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1848223155.
2017-04-07 09:28:44 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='26777db6d11cd5a2606300b55be39d20'} @ localhost (dataPort=-1)
2017-04-07 09:28:44 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-07 09:28:44 INFO  TaskManager:128 - Memory usage stats: [HEAP: 176/806/910 MB, NON HEAP: 131/134/-1 MB (used/committed/max)]
2017-04-07 09:28:44 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-07 09:28:44 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='26777db6d11cd5a2606300b55be39d20'} has started.
2017-04-07 09:28:44 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 3ad2d2029ac30a8f4dc3a0db06346d0c. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-07 09:28:44 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-07 09:28:44 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:61962. Starting BLOB cache.
2017-04-07 09:28:44 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-b3e191d5-3be8-4f33-8760-91017ea601a6
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 304c91fe338f6ff9a58d269ce1453a1e)) but there is no connection to a JobManager yet.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e).
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#639493118].
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#639493118]
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e) and wait for progress
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-07 09:28:44 INFO  JobManager:128 - Submitting job 304c91fe338f6ff9a58d269ce1453a1e (Flink Streaming Job).
2017-04-07 09:28:44 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 304c91fe338f6ff9a58d269ce1453a1e.
2017-04-07 09:28:44 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e).
2017-04-07 09:28:44 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:111 - Job 304c91fe338f6ff9a58d269ce1453a1e was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-07 09:28:44 INFO  JobManager:128 - Scheduling job 304c91fe338f6ff9a58d269ce1453a1e (Flink Streaming Job).
2017-04-07 09:28:44 INFO  ExecutionGraph:965 - Job Flink Streaming Job (304c91fe338f6ff9a58d269ce1453a1e) switched from state CREATED to RUNNING.
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:275 - 04/07/2017 09:28:44	Job execution switched to status RUNNING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from CREATED to SCHEDULED.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-07 09:28:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from SCHEDULED to DEPLOYING.
2017-04-07 09:28:44 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-07 09:28:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from CREATED to DEPLOYING.
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from CREATED to DEPLOYING.
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from CREATED to DEPLOYING.
2017-04-07 09:28:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-07 09:28:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49f8d852 for Source: Custom Source -> Map (3/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) [DEPLOYING].
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25632b7 for Source: Custom Source -> Map (4/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) [DEPLOYING].
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3472d14f for Source: Custom Source -> Map (1/4)
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@38a4dcc9 for Source: Custom Source -> Map (2/4)
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  Task:873 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@77f8f4a5 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4762109a for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@379157e9 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from CREATED to DEPLOYING.
2017-04-07 09:28:45 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@460271e2 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-07 09:28:45 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) [DEPLOYING].
2017-04-07 09:28:45 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-07 09:28:45 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5565583c8389b12ea86d23d067b5b4fc) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (04f9128372b01f9dc6416b410d553d4c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0475e86c304f8a7dce99e44042fe0d99) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (9b6fcbfea95e8d3006cb25a1a771d85c) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (554702de6a658366873d818b0a073ff6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (a1a736da87e77436fb4ef4d7aa809e98) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (c6efcd380f215282ca45cb33b71fa5b6) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (8f20ca8aa2e1899be67187b167b71c58) switched from DEPLOYING to RUNNING.
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  JobSubmissionClientActor:265 - 04/07/2017 09:28:45	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$11$$anon$4@d1b87f50}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-07 09:28:46 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-07 09:28:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-07 09:28:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-07 09:28:46 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-07 09:28:46 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-07 09:28:46 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 124, so the initial offset will be set to 123
2017-04-07 09:28:46 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 136, so the initial offset will be set to 135
2017-04-07 15:12:07 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-07 23:59:59 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 00:00:02 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 00:00:02 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 00:00:03 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 00:00:03 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 00:00:04 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-31bb4b5f-7878-4f2e-88c0-fad441f7b6b0
2017-04-08 00:00:04 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:50740 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 00:00:04 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 00:00:04 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 00:00:04 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 00:00:04 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 00:00:04 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 00:00:04 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 00:00:04 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 00:00:04 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#98455985] - leader session null
2017-04-08 00:00:04 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 00:00:04 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 00:00:04 INFO  TaskManager:128 - Limiting managed memory to 267 MB, memory will be allocated lazily.
2017-04-08 00:00:04 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-e56bba6f-0ec1-4f6c-a4f5-54e900037127 for spill files.
2017-04-08 00:00:04 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 00:00:04 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-5277a93c-8356-4044-a210-3f5423176771
2017-04-08 00:00:04 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1582472278.
2017-04-08 00:00:04 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='ef383c40008aba3b31bd4f3534a89fe0'} @ localhost (dataPort=-1)
2017-04-08 00:00:04 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 00:00:04 INFO  TaskManager:128 - Memory usage stats: [HEAP: 177/952/952 MB, NON HEAP: 145/147/-1 MB (used/committed/max)]
2017-04-08 00:00:04 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 00:00:04 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='ef383c40008aba3b31bd4f3534a89fe0'} has started.
2017-04-08 00:00:04 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as c003fc200a2a71e4973df85a2afbef5a. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 00:00:04 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 00:00:04 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:50740. Starting BLOB cache.
2017-04-08 00:00:04 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-42ab3623-f672-4362-acc2-09e503db9cf9
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: abc2cf5ae2f6e4792fe4606bbb210b52)) but there is no connection to a JobManager yet.
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (abc2cf5ae2f6e4792fe4606bbb210b52).
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#98455985].
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#98455985]
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (abc2cf5ae2f6e4792fe4606bbb210b52) and wait for progress
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 00:00:04 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 00:00:04 INFO  JobManager:128 - Submitting job abc2cf5ae2f6e4792fe4606bbb210b52 (Flink Streaming Job).
2017-04-08 00:00:04 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for abc2cf5ae2f6e4792fe4606bbb210b52.
2017-04-08 00:00:05 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (abc2cf5ae2f6e4792fe4606bbb210b52).
2017-04-08 00:00:05 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:111 - Job abc2cf5ae2f6e4792fe4606bbb210b52 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 00:00:05 INFO  JobManager:128 - Scheduling job abc2cf5ae2f6e4792fe4606bbb210b52 (Flink Streaming Job).
2017-04-08 00:00:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (abc2cf5ae2f6e4792fe4606bbb210b52) switched from state CREATED to RUNNING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:275 - 04/08/2017 00:00:05	Job execution switched to status RUNNING.
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (262cdee374ae4a84b76c79a01be1b34a) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (262cdee374ae4a84b76c79a01be1b34a) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (59a10418623425c6fccb0cc537e2bd45) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (59a10418623425c6fccb0cc537e2bd45) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (066418dbb55b4a3e336ae063eef0c419) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (066418dbb55b4a3e336ae063eef0c419) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5cafc3f37537a1526ac0ef5c52b08f86) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5cafc3f37537a1526ac0ef5c52b08f86) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (7dae87d834399783ddec7f20a0390af6) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (7dae87d834399783ddec7f20a0390af6) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (0e73b64101abbdbf1fd1c54f83a7a2c0) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (0e73b64101abbdbf1fd1c54f83a7a2c0) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (b82b6fb6e419c18431e4e358fc34e72e) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (b82b6fb6e419c18431e4e358fc34e72e) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (69974b522d8d3215c26153284584b6f1) switched from CREATED to SCHEDULED.
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (69974b522d8d3215c26153284584b6f1) switched from SCHEDULED to DEPLOYING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 00:00:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (262cdee374ae4a84b76c79a01be1b34a) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (59a10418623425c6fccb0cc537e2bd45) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (066418dbb55b4a3e336ae063eef0c419) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1a4d691 for Source: Custom Source -> Map (2/4)
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@33ec04cb for Source: Custom Source -> Map (3/4)
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@c8b3a88 for Source: Custom Source -> Map (1/4)
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (066418dbb55b4a3e336ae063eef0c419) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (59a10418623425c6fccb0cc537e2bd45) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5cafc3f37537a1526ac0ef5c52b08f86) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (262cdee374ae4a84b76c79a01be1b34a) [DEPLOYING].
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7ab7560c for Source: Custom Source -> Map (4/4)
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (5cafc3f37537a1526ac0ef5c52b08f86) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (262cdee374ae4a84b76c79a01be1b34a) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (59a10418623425c6fccb0cc537e2bd45) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (5cafc3f37537a1526ac0ef5c52b08f86) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (066418dbb55b4a3e336ae063eef0c419) [DEPLOYING].
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (7dae87d834399783ddec7f20a0390af6) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5cafc3f37537a1526ac0ef5c52b08f86) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@c49e52f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (59a10418623425c6fccb0cc537e2bd45) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (262cdee374ae4a84b76c79a01be1b34a) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (066418dbb55b4a3e336ae063eef0c419) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (7dae87d834399783ddec7f20a0390af6) [DEPLOYING].
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (7dae87d834399783ddec7f20a0390af6) [DEPLOYING].
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (7dae87d834399783ddec7f20a0390af6) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (0e73b64101abbdbf1fd1c54f83a7a2c0) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@ba320f3 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (0e73b64101abbdbf1fd1c54f83a7a2c0) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (0e73b64101abbdbf1fd1c54f83a7a2c0) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (0e73b64101abbdbf1fd1c54f83a7a2c0) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (b82b6fb6e419c18431e4e358fc34e72e) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4aa654ac for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (b82b6fb6e419c18431e4e358fc34e72e) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (b82b6fb6e419c18431e4e358fc34e72e) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (b82b6fb6e419c18431e4e358fc34e72e) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (69974b522d8d3215c26153284584b6f1) switched from CREATED to DEPLOYING.
2017-04-08 00:00:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@52d47148 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-08 00:00:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (69974b522d8d3215c26153284584b6f1) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (69974b522d8d3215c26153284584b6f1) [DEPLOYING].
2017-04-08 00:00:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (69974b522d8d3215c26153284584b6f1) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 00:00:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (262cdee374ae4a84b76c79a01be1b34a) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5cafc3f37537a1526ac0ef5c52b08f86) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (066418dbb55b4a3e336ae063eef0c419) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (59a10418623425c6fccb0cc537e2bd45) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (7dae87d834399783ddec7f20a0390af6) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (0e73b64101abbdbf1fd1c54f83a7a2c0) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (b82b6fb6e419c18431e4e358fc34e72e) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (69974b522d8d3215c26153284584b6f1) switched from DEPLOYING to RUNNING.
2017-04-08 00:00:05 INFO  JobSubmissionClientActor:265 - 04/08/2017 00:00:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@c98c4fff}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 00:00:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 00:00:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 00:00:06 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 00:00:06 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 00:00:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 00:00:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 00:00:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 00:00:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 00:00:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 00:00:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 00:00:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 00:00:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 00:00:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 00:00:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 00:00:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 00:00:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 00:00:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 00:00:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 00:00:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 00:00:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 00:00:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 00:00:07 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 00:00:07 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 00:00:07 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 126, so the initial offset will be set to 125
2017-04-08 00:00:07 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 139, so the initial offset will be set to 138
2017-04-08 15:02:19 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 15:02:20 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 15:02:20 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 15:02:21 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 15:02:21 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 15:02:21 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-90c88582-2cac-4fbc-beea-d12a0577bf72
2017-04-08 15:02:21 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:51734 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 15:02:21 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:02:21 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 15:02:21 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 15:02:21 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 15:02:21 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 15:02:21 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 15:02:21 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 15:02:21 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1326695123] - leader session null
2017-04-08 15:02:21 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 15:02:21 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 15:02:21 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-08 15:02:21 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-e57903a3-a389-4fe6-ab58-b524d2e7eb1d for spill files.
2017-04-08 15:02:21 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:02:21 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-c9123176-e5a9-4c33-8028-2df306415b22
2017-04-08 15:02:21 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1648837059.
2017-04-08 15:02:21 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='ccd5142c55a2501d8352e3122d020e0e'} @ localhost (dataPort=-1)
2017-04-08 15:02:21 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 15:02:21 INFO  TaskManager:128 - Memory usage stats: [HEAP: 174/867/910 MB, NON HEAP: 125/128/-1 MB (used/committed/max)]
2017-04-08 15:02:21 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 15:02:21 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='ccd5142c55a2501d8352e3122d020e0e'} has started.
2017-04-08 15:02:21 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 24ebc6b1f968031ad72dc7764d9cd0cb. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 15:02:21 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 15:02:21 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:51734. Starting BLOB cache.
2017-04-08 15:02:21 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-762ce06c-6dfb-4a4c-8f93-5d63ee740592
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 3cfb1a69aa19a9d374f56916cc364cde)) but there is no connection to a JobManager yet.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (3cfb1a69aa19a9d374f56916cc364cde).
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1326695123].
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1326695123]
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (3cfb1a69aa19a9d374f56916cc364cde) and wait for progress
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 15:02:22 INFO  JobManager:128 - Submitting job 3cfb1a69aa19a9d374f56916cc364cde (Flink Streaming Job).
2017-04-08 15:02:22 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 3cfb1a69aa19a9d374f56916cc364cde.
2017-04-08 15:02:22 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (3cfb1a69aa19a9d374f56916cc364cde).
2017-04-08 15:02:22 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:111 - Job 3cfb1a69aa19a9d374f56916cc364cde was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 15:02:22 INFO  JobManager:128 - Scheduling job 3cfb1a69aa19a9d374f56916cc364cde (Flink Streaming Job).
2017-04-08 15:02:22 INFO  ExecutionGraph:965 - Job Flink Streaming Job (3cfb1a69aa19a9d374f56916cc364cde) switched from state CREATED to RUNNING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:275 - 04/08/2017 15:02:22	Job execution switched to status RUNNING.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (a7cc47c9740be7bc670867128014a981) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (a7cc47c9740be7bc670867128014a981) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b03a728565bf82eda28feede1a5c564e) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b03a728565bf82eda28feede1a5c564e) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6b226685c75d35644835938fbcf8a98e) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6b226685c75d35644835938fbcf8a98e) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (010a7bc00674d39c7e5eec5536e09902) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (010a7bc00674d39c7e5eec5536e09902) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (5a56af3a2e726606c746792a53c51b2c) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (5a56af3a2e726606c746792a53c51b2c) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (227a78f8c634da54e1dc4d4f7130c64d) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (227a78f8c634da54e1dc4d4f7130c64d) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c72a51b693da1c262a14bc45013ef9fb) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c72a51b693da1c262a14bc45013ef9fb) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (9ca31a4dab95b31079dff2108d979778) switched from CREATED to SCHEDULED.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (9ca31a4dab95b31079dff2108d979778) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 15:02:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (1/4) (a7cc47c9740be7bc670867128014a981) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b03a728565bf82eda28feede1a5c564e) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6b226685c75d35644835938fbcf8a98e) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (4/4) (010a7bc00674d39c7e5eec5536e09902) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@358c9a95 for Source: Custom Source -> Map (1/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (a7cc47c9740be7bc670867128014a981) [DEPLOYING].
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6bfb77f4 for Source: Custom Source -> Map (3/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (6b226685c75d35644835938fbcf8a98e) [DEPLOYING].
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4be4eb3e for Source: Custom Source -> Map (2/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (b03a728565bf82eda28feede1a5c564e) [DEPLOYING].
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4e012c66 for Source: Custom Source -> Map (4/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (010a7bc00674d39c7e5eec5536e09902) [DEPLOYING].
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (5a56af3a2e726606c746792a53c51b2c) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@168b0649 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (5a56af3a2e726606c746792a53c51b2c) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (6b226685c75d35644835938fbcf8a98e) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (b03a728565bf82eda28feede1a5c564e) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (a7cc47c9740be7bc670867128014a981) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (5a56af3a2e726606c746792a53c51b2c) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (010a7bc00674d39c7e5eec5536e09902) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (2/4) (b03a728565bf82eda28feede1a5c564e) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (1/4) (a7cc47c9740be7bc670867128014a981) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (5a56af3a2e726606c746792a53c51b2c) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (4/4) (010a7bc00674d39c7e5eec5536e09902) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6b226685c75d35644835938fbcf8a98e) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (227a78f8c634da54e1dc4d4f7130c64d) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7e0590d7 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (227a78f8c634da54e1dc4d4f7130c64d) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (227a78f8c634da54e1dc4d4f7130c64d) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (227a78f8c634da54e1dc4d4f7130c64d) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c72a51b693da1c262a14bc45013ef9fb) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6b50443f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c72a51b693da1c262a14bc45013ef9fb) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c72a51b693da1c262a14bc45013ef9fb) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c72a51b693da1c262a14bc45013ef9fb) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (9ca31a4dab95b31079dff2108d979778) switched from CREATED to DEPLOYING.
2017-04-08 15:02:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7ba1d053 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:02:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (9ca31a4dab95b31079dff2108d979778) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (9ca31a4dab95b31079dff2108d979778) [DEPLOYING].
2017-04-08 15:02:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (9ca31a4dab95b31079dff2108d979778) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:02:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (5a56af3a2e726606c746792a53c51b2c) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (010a7bc00674d39c7e5eec5536e09902) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (b03a728565bf82eda28feede1a5c564e) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6b226685c75d35644835938fbcf8a98e) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (227a78f8c634da54e1dc4d4f7130c64d) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (a7cc47c9740be7bc670867128014a981) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c72a51b693da1c262a14bc45013ef9fb) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (9ca31a4dab95b31079dff2108d979778) switched from DEPLOYING to RUNNING.
2017-04-08 15:02:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:02:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f36eb882}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 15:02:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:02:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:02:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:02:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:22 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:02:22 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:02:22 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:02:22 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:02:22 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:02:22 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:02:22 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:02:22 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:02:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:02:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:02:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:02:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:02:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:02:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:02:23 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:02:23 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:02:23 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 139, so the initial offset will be set to 138
2017-04-08 15:02:23 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 127, so the initial offset will be set to 126
2017-04-08 15:20:21 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 15:20:21 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 15:20:21 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 15:20:21 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 15:20:22 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 15:20:22 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-39e9feff-efae-4a5e-9f7b-526d4f95507f
2017-04-08 15:20:22 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:51844 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 15:20:22 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:20:22 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 15:20:22 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 15:20:22 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 15:20:22 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 15:20:22 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 15:20:22 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 15:20:22 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 15:20:22 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1359957083] - leader session null
2017-04-08 15:20:22 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 15:20:22 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-08 15:20:22 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-725eb3a0-7e1d-4bfb-85e9-87fb1a85b496 for spill files.
2017-04-08 15:20:22 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:20:22 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-3128b404-447c-43fc-ac32-9bf8ed2256f8
2017-04-08 15:20:22 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#972119701.
2017-04-08 15:20:22 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='82c7aa3bda414f0e27ccb54e6454e2bd'} @ localhost (dataPort=-1)
2017-04-08 15:20:22 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 15:20:22 INFO  TaskManager:128 - Memory usage stats: [HEAP: 178/838/910 MB, NON HEAP: 121/123/-1 MB (used/committed/max)]
2017-04-08 15:20:22 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 15:20:22 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='82c7aa3bda414f0e27ccb54e6454e2bd'} has started.
2017-04-08 15:20:22 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as dfbd23c51b65d50a73b5d12f2543ce10. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 15:20:22 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 15:20:22 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:51844. Starting BLOB cache.
2017-04-08 15:20:22 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-9705ef1f-65da-4bc8-8655-f3ff1dff2cd7
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 5b3df27a827c3e068962fa1f6397c58f)) but there is no connection to a JobManager yet.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (5b3df27a827c3e068962fa1f6397c58f).
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1359957083].
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1359957083]
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (5b3df27a827c3e068962fa1f6397c58f) and wait for progress
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 15:20:22 INFO  JobManager:128 - Submitting job 5b3df27a827c3e068962fa1f6397c58f (Flink Streaming Job).
2017-04-08 15:20:22 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 5b3df27a827c3e068962fa1f6397c58f.
2017-04-08 15:20:22 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (5b3df27a827c3e068962fa1f6397c58f).
2017-04-08 15:20:22 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:111 - Job 5b3df27a827c3e068962fa1f6397c58f was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 15:20:22 INFO  JobManager:128 - Scheduling job 5b3df27a827c3e068962fa1f6397c58f (Flink Streaming Job).
2017-04-08 15:20:22 INFO  ExecutionGraph:965 - Job Flink Streaming Job (5b3df27a827c3e068962fa1f6397c58f) switched from state CREATED to RUNNING.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:275 - 04/08/2017 15:20:22	Job execution switched to status RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5b9bfde3901e084113c9e729478824a6) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5b9bfde3901e084113c9e729478824a6) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (de4bf7ca1b976615154b23aac5cef006) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (de4bf7ca1b976615154b23aac5cef006) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (e1ba64a42edf49e95f9c71ded600904d) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (e1ba64a42edf49e95f9c71ded600904d) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (2fb34344be377bf5fca98b356a46508c) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (2fb34344be377bf5fca98b356a46508c) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d477012bb87f1f9875ba77ee7d99280e) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d477012bb87f1f9875ba77ee7d99280e) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (d5058ea19ddf77c36df0fbdf8c595147) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (d5058ea19ddf77c36df0fbdf8c595147) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (2619fdc25c62391eb892015dac77f0bc) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (2619fdc25c62391eb892015dac77f0bc) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (29b11e562b5002b5021a37568ad442f7) switched from CREATED to SCHEDULED.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (29b11e562b5002b5021a37568ad442f7) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:20:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5b9bfde3901e084113c9e729478824a6) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (2/4) (de4bf7ca1b976615154b23aac5cef006) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (3/4) (e1ba64a42edf49e95f9c71ded600904d) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (4/4) (2fb34344be377bf5fca98b356a46508c) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@17d2cb01 for Source: Custom Source -> Map (1/4)
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (5b9bfde3901e084113c9e729478824a6) [DEPLOYING].
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2a7c0106 for Source: Custom Source -> Map (2/4)
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2cb6ab3c for Source: Custom Source -> Map (4/4)
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (2fb34344be377bf5fca98b356a46508c) [DEPLOYING].
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@31e85734 for Source: Custom Source -> Map (3/4)
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (e1ba64a42edf49e95f9c71ded600904d) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (de4bf7ca1b976615154b23aac5cef006) [DEPLOYING].
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (d5058ea19ddf77c36df0fbdf8c595147) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3b218ea8 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d477012bb87f1f9875ba77ee7d99280e) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (d5058ea19ddf77c36df0fbdf8c595147) [DEPLOYING].
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7327526c for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d477012bb87f1f9875ba77ee7d99280e) [DEPLOYING].
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (2619fdc25c62391eb892015dac77f0bc) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@236d612 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (2619fdc25c62391eb892015dac77f0bc) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (d5058ea19ddf77c36df0fbdf8c595147) [DEPLOYING].
2017-04-08 15:20:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (29b11e562b5002b5021a37568ad442f7) switched from CREATED to DEPLOYING.
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (5b9bfde3901e084113c9e729478824a6) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (2619fdc25c62391eb892015dac77f0bc) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (de4bf7ca1b976615154b23aac5cef006) [DEPLOYING].
2017-04-08 15:20:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@54f22ad6 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:20:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (29b11e562b5002b5021a37568ad442f7) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (29b11e562b5002b5021a37568ad442f7) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (2fb34344be377bf5fca98b356a46508c) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d477012bb87f1f9875ba77ee7d99280e) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (e1ba64a42edf49e95f9c71ded600904d) [DEPLOYING].
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (d5058ea19ddf77c36df0fbdf8c595147) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5b9bfde3901e084113c9e729478824a6) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d477012bb87f1f9875ba77ee7d99280e) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (2619fdc25c62391eb892015dac77f0bc) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (2/4) (de4bf7ca1b976615154b23aac5cef006) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (4/4) (2fb34344be377bf5fca98b356a46508c) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (29b11e562b5002b5021a37568ad442f7) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 INFO  Task:873 - Source: Custom Source -> Map (3/4) (e1ba64a42edf49e95f9c71ded600904d) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:20:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (d5058ea19ddf77c36df0fbdf8c595147) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (2619fdc25c62391eb892015dac77f0bc) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (de4bf7ca1b976615154b23aac5cef006) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d477012bb87f1f9875ba77ee7d99280e) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5b9bfde3901e084113c9e729478824a6) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (e1ba64a42edf49e95f9c71ded600904d) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (29b11e562b5002b5021a37568ad442f7) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (2fb34344be377bf5fca98b356a46508c) switched from DEPLOYING to RUNNING.
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 15:20:22 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:20:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aa6fec51}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 15:20:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:20:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:20:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:20:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:20:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:20:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:20:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:20:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:20:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:20:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:20:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:20:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:20:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:20:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:20:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:20:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:20:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:20:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:20:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:20:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:20:24 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:20:24 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:20:24 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 129, so the initial offset will be set to 128
2017-04-08 15:20:24 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 139, so the initial offset will be set to 138
2017-04-08 15:24:52 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 15:24:52 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 15:24:53 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 15:24:53 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 15:24:53 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 15:24:53 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6e35f16b-a9ea-4d44-bbe4-9fcb484356cc
2017-04-08 15:24:53 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:51892 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 15:24:53 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:24:53 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 15:24:53 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 15:24:53 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 15:24:53 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 15:24:53 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#662136345] - leader session null
2017-04-08 15:24:53 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 15:24:53 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 15:24:53 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 15:24:53 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 15:24:53 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-08 15:24:53 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-c161a373-1dd1-49fe-b3a8-c63c9a9e656a for spill files.
2017-04-08 15:24:53 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:24:53 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-e971a788-dcc8-4a40-a7e1-18d78fd08a6c
2017-04-08 15:24:53 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1736707761.
2017-04-08 15:24:53 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='b31bc4800e3db0b093e252d10ab76777'} @ localhost (dataPort=-1)
2017-04-08 15:24:53 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 15:24:53 INFO  TaskManager:128 - Memory usage stats: [HEAP: 170/908/910 MB, NON HEAP: 120/123/-1 MB (used/committed/max)]
2017-04-08 15:24:53 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 15:24:53 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='b31bc4800e3db0b093e252d10ab76777'} has started.
2017-04-08 15:24:53 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 7de8ac0a72075d47580776ecce1b56bc. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 15:24:53 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 15:24:53 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:51892. Starting BLOB cache.
2017-04-08 15:24:53 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-bf8238cb-96dc-4a60-b993-5a950b932767
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 4d275bb4479a8a60012204ff35161c5f)) but there is no connection to a JobManager yet.
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f).
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#662136345].
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#662136345]
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f) and wait for progress
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 15:24:53 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 15:24:54 INFO  JobManager:128 - Submitting job 4d275bb4479a8a60012204ff35161c5f (Flink Streaming Job).
2017-04-08 15:24:54 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 4d275bb4479a8a60012204ff35161c5f.
2017-04-08 15:24:54 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f).
2017-04-08 15:24:54 INFO  JobManager:141 - Successfully ran initialization on master in 1 ms.
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:111 - Job 4d275bb4479a8a60012204ff35161c5f was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 15:24:54 INFO  JobManager:128 - Scheduling job 4d275bb4479a8a60012204ff35161c5f (Flink Streaming Job).
2017-04-08 15:24:54 INFO  ExecutionGraph:965 - Job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f) switched from state CREATED to RUNNING.
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:275 - 04/08/2017 15:24:54	Job execution switched to status RUNNING.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from CREATED to SCHEDULED.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:24:54 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@650f3c8d for Source: Custom Source -> Map (3/4)
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3b64e2e2 for Source: Custom Source -> Map (1/4)
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) [DEPLOYING].
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7fb134da for Source: Custom Source -> Map (4/4)
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@417e0d02 for Source: Custom Source -> Map (2/4)
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) [DEPLOYING].
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7caac62c for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  Task:873 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4ee0245e for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) [DEPLOYING].
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) [DEPLOYING].
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@586e7294 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from CREATED to DEPLOYING.
2017-04-08 15:24:54 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@471b4cde for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:24:54 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) [DEPLOYING].
2017-04-08 15:24:54 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) [DEPLOYING].
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from DEPLOYING to RUNNING.
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:24:54	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 15:24:54 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:24:54 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:24:54 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:24:54 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:24:54 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:24:54 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:24:54 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:24:54 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:24:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:24:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:24:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:24:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:24:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:24:54 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:24:54 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:24:55 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:24:55 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:55 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:55 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:55 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:24:55 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:24:55 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:24:55 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:24:55 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:24:55 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:24:55 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:24:55 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 139, so the initial offset will be set to 138
2017-04-08 15:24:55 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 130, so the initial offset will be set to 129
2017-04-08 15:25:35 INFO  Task:875 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) switched from RUNNING to FAILED.
java.lang.RuntimeException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:425)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:407)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:797)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:775)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:22)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:10)
	at org.apache.flink.streaming.api.scala.function.util.ScalaWindowFunctionWrapper.apply(ScalaWindowFunctionWrapper.scala:44)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:43)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:31)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:518)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:427)
	at org.apache.flink.streaming.api.operators.HeapInternalTimerService.advanceWatermark(HeapInternalTimerService.java:276)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:858)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:168)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date
	at java.text.DateFormat.format(DateFormat.java:310)
	at java.text.Format.format(Format.java:157)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:44)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:37)
	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:521)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:422)
	... 18 more
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724).
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (04f4fd7e8c7a30fa96481ea76e17f724)
2017-04-08 15:25:35 INFO  ExecutionGraph:1027 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (04f4fd7e8c7a30fa96481ea76e17f724) switched from RUNNING to FAILED.
java.lang.RuntimeException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:425)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:407)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:797)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:775)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:22)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:10)
	at org.apache.flink.streaming.api.scala.function.util.ScalaWindowFunctionWrapper.apply(ScalaWindowFunctionWrapper.scala:44)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:43)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:31)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:518)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:427)
	at org.apache.flink.streaming.api.operators.HeapInternalTimerService.advanceWatermark(HeapInternalTimerService.java:276)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:858)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:168)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date
	at java.text.DateFormat.format(DateFormat.java:310)
	at java.text.Format.format(Format.java:157)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:44)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:37)
	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:521)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:422)
	... 18 more
2017-04-08 15:25:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f) switched from state RUNNING to FAILING.
java.lang.RuntimeException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:425)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:407)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:797)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:775)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:22)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:10)
	at org.apache.flink.streaming.api.scala.function.util.ScalaWindowFunctionWrapper.apply(ScalaWindowFunctionWrapper.scala:44)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:43)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:31)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:518)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:427)
	at org.apache.flink.streaming.api.operators.HeapInternalTimerService.advanceWatermark(HeapInternalTimerService.java:276)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:858)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:168)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date
	at java.text.DateFormat.format(DateFormat.java:310)
	at java.text.Format.format(Format.java:157)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:44)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:37)
	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:521)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:422)
	... 18 more
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to FAILED 
java.lang.RuntimeException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:425)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:407)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:797)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:775)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:22)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:10)
	at org.apache.flink.streaming.api.scala.function.util.ScalaWindowFunctionWrapper.apply(ScalaWindowFunctionWrapper.scala:44)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:43)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:31)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:518)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:427)
	at org.apache.flink.streaming.api.operators.HeapInternalTimerService.advanceWatermark(HeapInternalTimerService.java:276)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:858)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:168)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date
	at java.text.DateFormat.format(DateFormat.java:310)
	at java.text.Format.format(Format.java:157)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:44)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:37)
	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:521)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:422)
	... 18 more

2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:280 - 04/08/2017 15:25:35	Job execution switched to status FAILING.
java.lang.RuntimeException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:425)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:407)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:797)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:775)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:22)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:10)
	at org.apache.flink.streaming.api.scala.function.util.ScalaWindowFunctionWrapper.apply(ScalaWindowFunctionWrapper.scala:44)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:43)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:31)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:518)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:427)
	at org.apache.flink.streaming.api.operators.HeapInternalTimerService.advanceWatermark(HeapInternalTimerService.java:276)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:858)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:168)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date
	at java.text.DateFormat.format(DateFormat.java:310)
	at java.text.Format.format(Format.java:157)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:44)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:37)
	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:521)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:422)
	... 18 more
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-08 15:25:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522).
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522).
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea).
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea).
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a).
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522).
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea).
2017-04-08 15:25:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a).
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to CANCELING 
2017-04-08 15:25:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e).
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e).
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a).
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-08 15:25:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175).
2017-04-08 15:25:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-08 15:25:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175).
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-08 15:25:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e).
2017-04-08 15:25:35 INFO  TaskManager:128 - Discarding the results produced by task execution 04f4fd7e8c7a30fa96481ea76e17f724
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-08 15:25:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3).
2017-04-08 15:25:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3).
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175).
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:25:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0).
2017-04-08 15:25:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from RUNNING to CANCELING.
2017-04-08 15:25:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0).
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (b7a0bec86daf71fcd39dbe4943e7e522)
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (bb4a8a0b1fc1c70e04a9be443d9da89a)
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (90191a7294aa0485278219d5dcf1c2ea)
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (6e887dc32fb67ae5382baa97bdeaec7e)
2017-04-08 15:25:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (d9c8feceae8498c46416540121bd4175)
2017-04-08 15:25:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0).
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6e887dc32fb67ae5382baa97bdeaec7e) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3).
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (d9c8feceae8498c46416540121bd4175) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (90191a7294aa0485278219d5dcf1c2ea) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (c2906b5d29a61a658978619f2ab0c7e0)
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-08 15:25:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (c1e8feed3d9630cb28b225b915f48fb3)
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (bb4a8a0b1fc1c70e04a9be443d9da89a) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (b7a0bec86daf71fcd39dbe4943e7e522) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (c2906b5d29a61a658978619f2ab0c7e0) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to CANCELED 
2017-04-08 15:25:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (c1e8feed3d9630cb28b225b915f48fb3) switched from CANCELING to CANCELED.
2017-04-08 15:25:35 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f) if no longer possible.
2017-04-08 15:25:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f) switched from state FAILING to FAILED.
java.lang.RuntimeException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:425)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:407)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:797)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:775)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:22)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:10)
	at org.apache.flink.streaming.api.scala.function.util.ScalaWindowFunctionWrapper.apply(ScalaWindowFunctionWrapper.scala:44)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:43)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:31)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:518)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:427)
	at org.apache.flink.streaming.api.operators.HeapInternalTimerService.advanceWatermark(HeapInternalTimerService.java:276)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:858)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:168)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date
	at java.text.DateFormat.format(DateFormat.java:310)
	at java.text.Format.format(Format.java:157)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:44)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:37)
	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:521)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:422)
	... 18 more
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:25:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@448456fe}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:275 - 04/08/2017 15:25:35	Job execution switched to status FAILED.
2017-04-08 15:25:35 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (4d275bb4479a8a60012204ff35161c5f) because the restart strategy prevented it.
java.lang.RuntimeException: Could not forward element to next operator
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:425)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:407)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:797)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator$CountingOutput.collect(AbstractStreamOperator.java:775)
	at org.apache.flink.streaming.api.operators.TimestampedCollector.collect(TimestampedCollector.java:51)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:22)
	at io.neons.streamer.collector.SessionCollector.apply(SessionCollector.scala:10)
	at org.apache.flink.streaming.api.scala.function.util.ScalaWindowFunctionWrapper.apply(ScalaWindowFunctionWrapper.scala:44)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:43)
	at org.apache.flink.streaming.runtime.operators.windowing.functions.InternalIterableWindowFunction.apply(InternalIterableWindowFunction.java:31)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.emitWindowContents(WindowOperator.java:518)
	at org.apache.flink.streaming.runtime.operators.windowing.WindowOperator.onEventTime(WindowOperator.java:427)
	at org.apache.flink.streaming.api.operators.HeapInternalTimerService.advanceWatermark(HeapInternalTimerService.java:276)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.processWatermark(AbstractStreamOperator.java:858)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:168)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalArgumentException: Cannot format given Object as a Date
	at java.text.DateFormat.format(DateFormat.java:310)
	at java.text.Format.format(Format.java:157)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:44)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:37)
	at org.apache.flink.streaming.api.scala.DataStream$$anon$4.map(DataStream.scala:521)
	at org.apache.flink.streaming.api.operators.StreamMap.processElement(StreamMap.java:38)
	at org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:422)
	... 18 more
2017-04-08 15:25:35 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job 4d275bb4479a8a60012204ff35161c5f
2017-04-08 15:25:35 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-08 15:25:35 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#662136345].
2017-04-08 15:25:35 INFO  JobClient:320 - Job execution failed
2017-04-08 15:25:35 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-08 15:25:35 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#1736707761.
2017-04-08 15:25:35 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-08 15:25:35 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-08 15:25:35 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-08 15:25:35 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:51892
2017-04-08 15:25:35 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-c161a373-1dd1-49fe-b3a8-c63c9a9e656a
2017-04-08 15:25:35 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-08 15:25:35 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-08 15:28:14 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 15:28:15 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 15:28:15 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 15:28:16 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 15:28:16 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 15:28:16 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-1d23c2b5-7bdc-49f6-a405-44813d6cc60c
2017-04-08 15:28:16 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:52075 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 15:28:16 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:28:16 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 15:28:16 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 15:28:16 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 15:28:16 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 15:28:16 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 15:28:16 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 15:28:16 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1460087524] - leader session null
2017-04-08 15:28:17 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 15:28:17 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 15:28:17 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-08 15:28:17 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-cd311990-6a48-4819-b38d-8a446e65e3c9 for spill files.
2017-04-08 15:28:17 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 15:28:17 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-c0ce2f8d-71ef-4897-9a18-824e85197fb6
2017-04-08 15:28:17 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-338516718.
2017-04-08 15:28:17 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='bf51c79608a40c5d3c153ee00e15e59c'} @ localhost (dataPort=-1)
2017-04-08 15:28:17 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 15:28:17 INFO  TaskManager:128 - Memory usage stats: [HEAP: 176/813/910 MB, NON HEAP: 122/126/-1 MB (used/committed/max)]
2017-04-08 15:28:17 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 15:28:17 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='bf51c79608a40c5d3c153ee00e15e59c'} has started.
2017-04-08 15:28:17 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as ea3b02536da0e8ba9ab673eecf35562e. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 15:28:17 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 15:28:17 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:52075. Starting BLOB cache.
2017-04-08 15:28:17 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-484efade-de4c-480f-bb2c-fdc55f626b71
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 12bfb6d03b3cee810fec665727333679)) but there is no connection to a JobManager yet.
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (12bfb6d03b3cee810fec665727333679).
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1460087524].
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1460087524]
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (12bfb6d03b3cee810fec665727333679) and wait for progress
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 15:28:17 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 15:28:17 INFO  JobManager:128 - Submitting job 12bfb6d03b3cee810fec665727333679 (Flink Streaming Job).
2017-04-08 15:28:17 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 12bfb6d03b3cee810fec665727333679.
2017-04-08 15:28:18 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (12bfb6d03b3cee810fec665727333679).
2017-04-08 15:28:18 INFO  JobManager:141 - Successfully ran initialization on master in 1 ms.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:111 - Job 12bfb6d03b3cee810fec665727333679 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 15:28:18 INFO  JobManager:128 - Scheduling job 12bfb6d03b3cee810fec665727333679 (Flink Streaming Job).
2017-04-08 15:28:18 INFO  ExecutionGraph:965 - Job Flink Streaming Job (12bfb6d03b3cee810fec665727333679) switched from state CREATED to RUNNING.
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (e1a9cb800418df9b8256ca8e7e52cb68) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:275 - 04/08/2017 15:28:18	Job execution switched to status RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (e1a9cb800418df9b8256ca8e7e52cb68) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f8b155206e72df8aa1f56902ba89db47) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f8b155206e72df8aa1f56902ba89db47) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (161fda2519df7d9465f1f714066635d8) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (161fda2519df7d9465f1f714066635d8) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (4798c5359720566cef79b55752bc156a) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (4798c5359720566cef79b55752bc156a) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (578cb77b759e27cfce2ef5f9d01c5922) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (578cb77b759e27cfce2ef5f9d01c5922) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (b5df732c171bdee722ca43b80d6dc310) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (b5df732c171bdee722ca43b80d6dc310) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (69569046319af26a6c8251a44e429981) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (69569046319af26a6c8251a44e429981) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (2dc7c597eaeac4802796b7f75cad2b20) switched from CREATED to SCHEDULED.
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (2dc7c597eaeac4802796b7f75cad2b20) switched from SCHEDULED to DEPLOYING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 15:28:18 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (1/4) (e1a9cb800418df9b8256ca8e7e52cb68) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f8b155206e72df8aa1f56902ba89db47) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (3/4) (161fda2519df7d9465f1f714066635d8) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (4/4) (4798c5359720566cef79b55752bc156a) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@577c4c40 for Source: Custom Source -> Map (3/4)
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (161fda2519df7d9465f1f714066635d8) [DEPLOYING].
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@696ae0c6 for Source: Custom Source -> Map (1/4)
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3454b374 for Source: Custom Source -> Map (2/4)
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7afdb696 for Source: Custom Source -> Map (4/4)
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (f8b155206e72df8aa1f56902ba89db47) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (e1a9cb800418df9b8256ca8e7e52cb68) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (4798c5359720566cef79b55752bc156a) [DEPLOYING].
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (578cb77b759e27cfce2ef5f9d01c5922) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7505f025 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (578cb77b759e27cfce2ef5f9d01c5922) [DEPLOYING].
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (b5df732c171bdee722ca43b80d6dc310) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@390c14 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (b5df732c171bdee722ca43b80d6dc310) [DEPLOYING].
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (69569046319af26a6c8251a44e429981) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@58dacc7e for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 15:28:18 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (69569046319af26a6c8251a44e429981) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (2dc7c597eaeac4802796b7f75cad2b20) switched from CREATED to DEPLOYING.
2017-04-08 15:28:18 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3eb650f4 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 15:28:18 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (2dc7c597eaeac4802796b7f75cad2b20) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (161fda2519df7d9465f1f714066635d8) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (e1a9cb800418df9b8256ca8e7e52cb68) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (4798c5359720566cef79b55752bc156a) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (578cb77b759e27cfce2ef5f9d01c5922) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (f8b155206e72df8aa1f56902ba89db47) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (69569046319af26a6c8251a44e429981) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (b5df732c171bdee722ca43b80d6dc310) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (2dc7c597eaeac4802796b7f75cad2b20) [DEPLOYING].
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (3/4) (161fda2519df7d9465f1f714066635d8) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f8b155206e72df8aa1f56902ba89db47) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (b5df732c171bdee722ca43b80d6dc310) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (69569046319af26a6c8251a44e429981) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (578cb77b759e27cfce2ef5f9d01c5922) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (4/4) (4798c5359720566cef79b55752bc156a) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 INFO  Task:873 - Source: Custom Source -> Map (1/4) (e1a9cb800418df9b8256ca8e7e52cb68) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (2dc7c597eaeac4802796b7f75cad2b20) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 15:28:18 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (161fda2519df7d9465f1f714066635d8) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f8b155206e72df8aa1f56902ba89db47) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (b5df732c171bdee722ca43b80d6dc310) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (69569046319af26a6c8251a44e429981) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (578cb77b759e27cfce2ef5f9d01c5922) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (4798c5359720566cef79b55752bc156a) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (e1a9cb800418df9b8256ca8e7e52cb68) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (2dc7c597eaeac4802796b7f75cad2b20) switched from DEPLOYING to RUNNING.
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  JobSubmissionClientActor:265 - 04/08/2017 15:28:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b66d863c}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 15:28:18 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:28:18 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:28:18 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:28:18 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 15:28:18 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:28:18 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:28:18 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:28:18 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:18 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:28:18 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:28:18 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:28:18 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:28:18 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:28:18 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:28:18 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:28:18 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 15:28:19 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 15:28:19 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:19 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:19 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:19 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 15:28:19 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:28:19 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:28:19 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 15:28:19 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 15:28:19 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:28:19 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 15:28:19 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 130, so the initial offset will be set to 129
2017-04-08 15:28:19 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 140, so the initial offset will be set to 139
2017-04-08 16:08:36 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 16:08:36 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 16:08:37 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 16:08:37 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 16:08:38 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 16:08:38 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-d528c1bc-7a71-4761-9590-74c87e8f007a
2017-04-08 16:08:38 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:52493 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 16:08:38 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 16:08:38 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 16:08:38 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 16:08:38 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 16:08:38 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 16:08:38 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 16:08:38 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 16:08:38 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#263450722] - leader session null
2017-04-08 16:08:38 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 16:08:38 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 16:08:38 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-08 16:08:38 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-a330193c-68cc-4c29-8cdb-a7b691afc5a2 for spill files.
2017-04-08 16:08:38 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 16:08:38 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-a930c63e-d8b8-44b4-8127-dde6650cff51
2017-04-08 16:08:38 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1697336962.
2017-04-08 16:08:38 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='1cc2b2d39732a92573ccd24d89e98a9d'} @ localhost (dataPort=-1)
2017-04-08 16:08:38 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 16:08:38 INFO  TaskManager:128 - Memory usage stats: [HEAP: 177/812/910 MB, NON HEAP: 121/126/-1 MB (used/committed/max)]
2017-04-08 16:08:38 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 16:08:38 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='1cc2b2d39732a92573ccd24d89e98a9d'} has started.
2017-04-08 16:08:38 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 9c43abd4022669a24ddc2d60b30648e5. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 16:08:38 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 16:08:38 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:52493. Starting BLOB cache.
2017-04-08 16:08:38 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-8a750cf8-5102-4e5b-bc43-2f97e2815b5b
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 13a13c4e7dd3ac853a4cb923159fde85)) but there is no connection to a JobManager yet.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (13a13c4e7dd3ac853a4cb923159fde85).
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#263450722].
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#263450722]
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (13a13c4e7dd3ac853a4cb923159fde85) and wait for progress
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 16:08:38 INFO  JobManager:128 - Submitting job 13a13c4e7dd3ac853a4cb923159fde85 (Flink Streaming Job).
2017-04-08 16:08:38 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 13a13c4e7dd3ac853a4cb923159fde85.
2017-04-08 16:08:38 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (13a13c4e7dd3ac853a4cb923159fde85).
2017-04-08 16:08:38 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:111 - Job 13a13c4e7dd3ac853a4cb923159fde85 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 16:08:38 INFO  JobManager:128 - Scheduling job 13a13c4e7dd3ac853a4cb923159fde85 (Flink Streaming Job).
2017-04-08 16:08:38 INFO  ExecutionGraph:965 - Job Flink Streaming Job (13a13c4e7dd3ac853a4cb923159fde85) switched from state CREATED to RUNNING.
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4a2b90588ffbc75b2f37205aa530587c) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:275 - 04/08/2017 16:08:38	Job execution switched to status RUNNING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4a2b90588ffbc75b2f37205aa530587c) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d6647c3664d0e87cb78a75ec630d000c) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d6647c3664d0e87cb78a75ec630d000c) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2b3200403c73327407b0ceb6719d2700) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2b3200403c73327407b0ceb6719d2700) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (320db8fced26be54fda4a0318115cb08) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (320db8fced26be54fda4a0318115cb08) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (80e8ffd4908f1a4bff33cb0ebfab31d8) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (80e8ffd4908f1a4bff33cb0ebfab31d8) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (c8b1912642c3a9530c4e7b2aa10b0497) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (c8b1912642c3a9530c4e7b2aa10b0497) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (6d96300a0218650cea7d2a14543c745e) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (6d96300a0218650cea7d2a14543c745e) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (d337d42b94fcf54adb65a23fd8471b64) switched from CREATED to SCHEDULED.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (d337d42b94fcf54adb65a23fd8471b64) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 16:08:38 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4a2b90588ffbc75b2f37205aa530587c) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (2/4) (d6647c3664d0e87cb78a75ec630d000c) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49673ddf for Source: Custom Source -> Map (1/4)
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@b50644 for Source: Custom Source -> Map (2/4)
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (4a2b90588ffbc75b2f37205aa530587c) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (d6647c3664d0e87cb78a75ec630d000c) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (d6647c3664d0e87cb78a75ec630d000c) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (4a2b90588ffbc75b2f37205aa530587c) [DEPLOYING].
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2b3200403c73327407b0ceb6719d2700) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4075294c for Source: Custom Source -> Map (3/4)
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (2b3200403c73327407b0ceb6719d2700) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (2/4) (d6647c3664d0e87cb78a75ec630d000c) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (1/4) (4a2b90588ffbc75b2f37205aa530587c) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (2b3200403c73327407b0ceb6719d2700) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (3/4) (2b3200403c73327407b0ceb6719d2700) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (4/4) (320db8fced26be54fda4a0318115cb08) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5c55f4b for Source: Custom Source -> Map (4/4)
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (320db8fced26be54fda4a0318115cb08) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (320db8fced26be54fda4a0318115cb08) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:873 - Source: Custom Source -> Map (4/4) (320db8fced26be54fda4a0318115cb08) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:08:38 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:08:38 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:08:38 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (80e8ffd4908f1a4bff33cb0ebfab31d8) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4a35f385 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4)
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (80e8ffd4908f1a4bff33cb0ebfab31d8) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (80e8ffd4908f1a4bff33cb0ebfab31d8) [DEPLOYING].
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (80e8ffd4908f1a4bff33cb0ebfab31d8) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (c8b1912642c3a9530c4e7b2aa10b0497) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@43017bde for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4)
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (c8b1912642c3a9530c4e7b2aa10b0497) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (c8b1912642c3a9530c4e7b2aa10b0497) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (c8b1912642c3a9530c4e7b2aa10b0497) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (6d96300a0218650cea7d2a14543c745e) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@405018ef for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4)
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (6d96300a0218650cea7d2a14543c745e) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (6d96300a0218650cea7d2a14543c745e) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (6d96300a0218650cea7d2a14543c745e) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (d337d42b94fcf54adb65a23fd8471b64) switched from CREATED to DEPLOYING.
2017-04-08 16:08:38 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5c9fed25 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4)
2017-04-08 16:08:38 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (d337d42b94fcf54adb65a23fd8471b64) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (d337d42b94fcf54adb65a23fd8471b64) [DEPLOYING].
2017-04-08 16:08:38 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (d337d42b94fcf54adb65a23fd8471b64) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:08:38 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (d6647c3664d0e87cb78a75ec630d000c) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (2b3200403c73327407b0ceb6719d2700) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (4a2b90588ffbc75b2f37205aa530587c) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (2/4) (c8b1912642c3a9530c4e7b2aa10b0497) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (1/4) (80e8ffd4908f1a4bff33cb0ebfab31d8) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (320db8fced26be54fda4a0318115cb08) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (3/4) (6d96300a0218650cea7d2a14543c745e) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed (4/4) (d337d42b94fcf54adb65a23fd8471b64) switched from DEPLOYING to RUNNING.
2017-04-08 16:08:38 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:08:38	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@d70e7037}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 16:08:38 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:08:38 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:08:38 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:08:38 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:08:38 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:38 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:38 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:38 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:39 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:39 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:39 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:39 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:39 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:08:39 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:08:39 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:08:39 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:08:39 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:08:39 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:08:39 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:08:39 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:08:40 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:08:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:40 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:08:40 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:08:40 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:08:40 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:08:40 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:08:40 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 16:08:40 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 16:08:40 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 131, so the initial offset will be set to 130
2017-04-08 16:08:40 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 140, so the initial offset will be set to 139
2017-04-08 16:10:45 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 16:10:45 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 16:10:45 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 16:10:45 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 16:10:45 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 16:10:45 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-1a2036ee-8d00-41d7-b8a2-faa6ca580fd9
2017-04-08 16:10:45 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:52516 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 16:10:45 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 16:10:46 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 16:10:46 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 16:10:46 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 16:10:46 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 16:10:46 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 16:10:46 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 16:10:46 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 16:10:46 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 16:10:46 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1006891619] - leader session null
2017-04-08 16:10:46 INFO  TaskManager:128 - Limiting managed memory to 268 MB, memory will be allocated lazily.
2017-04-08 16:10:46 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-7c5e7e03-b4db-43c9-9c56-72d8fb9f3195 for spill files.
2017-04-08 16:10:46 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 16:10:46 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-9c2b7969-f82a-4702-bf1b-a5afcd924078
2017-04-08 16:10:46 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1413032342.
2017-04-08 16:10:46 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='570e7082f392d22cb1b6deff4817583d'} @ localhost (dataPort=-1)
2017-04-08 16:10:46 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 16:10:46 INFO  TaskManager:128 - Memory usage stats: [HEAP: 176/948/948 MB, NON HEAP: 121/125/-1 MB (used/committed/max)]
2017-04-08 16:10:46 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 16:10:46 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='570e7082f392d22cb1b6deff4817583d'} has started.
2017-04-08 16:10:46 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 52f05d304b1b4c9f9751129c41c62b9e. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 16:10:46 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 16:10:46 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:52516. Starting BLOB cache.
2017-04-08 16:10:46 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-f1a247ed-f223-4320-b763-84cf6cfa5300
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 415846f317e582e5dc5dbc2cd5ff09f5)) but there is no connection to a JobManager yet.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (415846f317e582e5dc5dbc2cd5ff09f5).
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1006891619].
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1006891619]
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (415846f317e582e5dc5dbc2cd5ff09f5) and wait for progress
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 16:10:46 INFO  JobManager:128 - Submitting job 415846f317e582e5dc5dbc2cd5ff09f5 (Flink Streaming Job).
2017-04-08 16:10:46 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 415846f317e582e5dc5dbc2cd5ff09f5.
2017-04-08 16:10:46 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (415846f317e582e5dc5dbc2cd5ff09f5).
2017-04-08 16:10:46 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:111 - Job 415846f317e582e5dc5dbc2cd5ff09f5 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 16:10:46 INFO  JobManager:128 - Scheduling job 415846f317e582e5dc5dbc2cd5ff09f5 (Flink Streaming Job).
2017-04-08 16:10:46 INFO  ExecutionGraph:965 - Job Flink Streaming Job (415846f317e582e5dc5dbc2cd5ff09f5) switched from state CREATED to RUNNING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:275 - 04/08/2017 16:10:46	Job execution switched to status RUNNING.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d97eaede1ab9e01ea5d1d1efaa79fa87) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d97eaede1ab9e01ea5d1d1efaa79fa87) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (480df1cd3637659de796795f93dfefdf) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (480df1cd3637659de796795f93dfefdf) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (59bd71dd778321ddab97deaff286c4e8) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (59bd71dd778321ddab97deaff286c4e8) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (29d52bb2255fb51261e7000a7ac03d76) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (29d52bb2255fb51261e7000a7ac03d76) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (c6f9a132175f9566b23c2c782ff86674) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(1/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (c6f9a132175f9566b23c2c782ff86674) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(1/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (9455be085e065975a912bc6a9746245f) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (9455be085e065975a912bc6a9746245f) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(2/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(2/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (5b6ccc23e0d8d2d0ea535a371d0f11c9) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(3/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (5b6ccc23e0d8d2d0ea535a371d0f11c9) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(3/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (d58678391365f87af6ceda939ed8add7) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(4/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (d58678391365f87af6ceda939ed8add7) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(4/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (1/4) (3e792b723f3dedbeede5864e6c22c296) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (1/4) (3e792b723f3dedbeede5864e6c22c296) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (2/4) (9fe6e63e3992a16e380ba51f53a0dac4) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (2/4) (9fe6e63e3992a16e380ba51f53a0dac4) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (3/4) (feed1a3c6c9b8e9fa506823455c6d084) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (3/4) (feed1a3c6c9b8e9fa506823455c6d084) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (4/4) (0244d5edb2b20f16b427acd77e57ac5c) switched from CREATED to SCHEDULED.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (4/4) (0244d5edb2b20f16b427acd77e57ac5c) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 16:10:46 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d97eaede1ab9e01ea5d1d1efaa79fa87) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (480df1cd3637659de796795f93dfefdf) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@fdd90c7 for Source: Custom Source -> Map (1/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (d97eaede1ab9e01ea5d1d1efaa79fa87) [DEPLOYING].
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@64f2b2f9 for Source: Custom Source -> Map (2/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (480df1cd3637659de796795f93dfefdf) [DEPLOYING].
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (59bd71dd778321ddab97deaff286c4e8) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@72fc0d0b for Source: Custom Source -> Map (3/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (59bd71dd778321ddab97deaff286c4e8) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (480df1cd3637659de796795f93dfefdf) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (59bd71dd778321ddab97deaff286c4e8) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (d97eaede1ab9e01ea5d1d1efaa79fa87) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (59bd71dd778321ddab97deaff286c4e8) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d97eaede1ab9e01ea5d1d1efaa79fa87) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (480df1cd3637659de796795f93dfefdf) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (29d52bb2255fb51261e7000a7ac03d76) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@255a4347 for Source: Custom Source -> Map (4/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (29d52bb2255fb51261e7000a7ac03d76) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (29d52bb2255fb51261e7000a7ac03d76) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (29d52bb2255fb51261e7000a7ac03d76) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:10:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:10:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:10:46 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4)
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (c6f9a132175f9566b23c2c782ff86674) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d5253a5 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (c6f9a132175f9566b23c2c782ff86674) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (c6f9a132175f9566b23c2c782ff86674) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (c6f9a132175f9566b23c2c782ff86674) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4)
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (9455be085e065975a912bc6a9746245f) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4d626786 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (9455be085e065975a912bc6a9746245f) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (9455be085e065975a912bc6a9746245f) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (9455be085e065975a912bc6a9746245f) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4)
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (5b6ccc23e0d8d2d0ea535a371d0f11c9) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7d46b3a1 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (5b6ccc23e0d8d2d0ea535a371d0f11c9) [DEPLOYING].
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4)
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (5b6ccc23e0d8d2d0ea535a371d0f11c9) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (d58678391365f87af6ceda939ed8add7) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (5b6ccc23e0d8d2d0ea535a371d0f11c9) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@20464c56 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (d58678391365f87af6ceda939ed8add7) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (d58678391365f87af6ceda939ed8add7) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (d58678391365f87af6ceda939ed8add7) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (1/4)
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (1/4) (3e792b723f3dedbeede5864e6c22c296) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1300e3fd for aggregation -> Sink: Unnamed (1/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (1/4) (3e792b723f3dedbeede5864e6c22c296) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (1/4) (3e792b723f3dedbeede5864e6c22c296) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (1/4) (3e792b723f3dedbeede5864e6c22c296) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (2/4)
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (2/4) (9fe6e63e3992a16e380ba51f53a0dac4) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@11961fc2 for aggregation -> Sink: Unnamed (2/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (2/4) (9fe6e63e3992a16e380ba51f53a0dac4) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (2/4) (9fe6e63e3992a16e380ba51f53a0dac4) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (2/4) (9fe6e63e3992a16e380ba51f53a0dac4) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (3/4)
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (3/4) (feed1a3c6c9b8e9fa506823455c6d084) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2e1809cf for aggregation -> Sink: Unnamed (3/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (3/4) (feed1a3c6c9b8e9fa506823455c6d084) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (3/4) (feed1a3c6c9b8e9fa506823455c6d084) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (3/4) (feed1a3c6c9b8e9fa506823455c6d084) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (4/4)
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (4/4) (0244d5edb2b20f16b427acd77e57ac5c) switched from CREATED to DEPLOYING.
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@62e11e94 for aggregation -> Sink: Unnamed (4/4)
2017-04-08 16:10:46 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (4/4) (0244d5edb2b20f16b427acd77e57ac5c) [DEPLOYING].
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (4/4) (0244d5edb2b20f16b427acd77e57ac5c) [DEPLOYING].
2017-04-08 16:10:46 INFO  Task:873 - aggregation -> Sink: Unnamed (4/4) (0244d5edb2b20f16b427acd77e57ac5c) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:10:46 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:10:46 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (480df1cd3637659de796795f93dfefdf) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d97eaede1ab9e01ea5d1d1efaa79fa87) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (59bd71dd778321ddab97deaff286c4e8) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (29d52bb2255fb51261e7000a7ac03d76) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (c6f9a132175f9566b23c2c782ff86674) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(1/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (5b6ccc23e0d8d2d0ea535a371d0f11c9) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(3/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (1/4) (3e792b723f3dedbeede5864e6c22c296) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (d58678391365f87af6ceda939ed8add7) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (9455be085e065975a912bc6a9746245f) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (3/4) (feed1a3c6c9b8e9fa506823455c6d084) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (2/4) (9fe6e63e3992a16e380ba51f53a0dac4) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(4/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@1cec56b6}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(2/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (4/4) (0244d5edb2b20f16b427acd77e57ac5c) switched from DEPLOYING to RUNNING.
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:10:46	aggregation -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:10:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:10:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:10:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:10:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:10:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:10:46 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:10:46 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:10:47 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:10:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:10:47 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:10:47 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:10:47 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:10:47 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:10:47 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 16:10:47 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 16:10:47 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 131, so the initial offset will be set to 130
2017-04-08 16:10:47 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 141, so the initial offset will be set to 140
2017-04-08 16:14:34 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 16:14:34 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 16:14:35 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 16:14:35 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 16:14:35 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 16:14:35 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-e1e6a74f-cb46-4aae-a861-69901edb27a2
2017-04-08 16:14:35 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:52537 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 16:14:35 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 16:14:35 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 16:14:35 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 16:14:35 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 16:14:35 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 16:14:35 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-08 16:14:35 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 16:14:35 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 16:14:35 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1081929268] - leader session null
2017-04-08 16:14:35 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 16:14:35 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-08 16:14:35 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-c62a4a8b-e017-4c07-867e-ef0bb764fa21 for spill files.
2017-04-08 16:14:35 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 16:14:35 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-d6cb4a1f-8e0b-412b-9fd0-8fab2d3152e4
2017-04-08 16:14:35 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#327373925.
2017-04-08 16:14:35 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='591f0808d30dd01edc67832f176b4012'} @ localhost (dataPort=-1)
2017-04-08 16:14:35 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 16:14:35 INFO  TaskManager:128 - Memory usage stats: [HEAP: 179/874/910 MB, NON HEAP: 123/126/-1 MB (used/committed/max)]
2017-04-08 16:14:35 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 16:14:35 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='591f0808d30dd01edc67832f176b4012'} has started.
2017-04-08 16:14:35 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 20ca59a87294c28828f3cdab2f655294. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 16:14:35 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 16:14:35 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:52537. Starting BLOB cache.
2017-04-08 16:14:35 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-af94034c-7d5f-44f1-9967-100dc7fd543d
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: ce4131cc59d29a2d406e4e13554dc522)) but there is no connection to a JobManager yet.
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (ce4131cc59d29a2d406e4e13554dc522).
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1081929268].
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1081929268]
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (ce4131cc59d29a2d406e4e13554dc522) and wait for progress
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 16:14:35 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 16:14:35 INFO  JobManager:128 - Submitting job ce4131cc59d29a2d406e4e13554dc522 (Flink Streaming Job).
2017-04-08 16:14:35 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for ce4131cc59d29a2d406e4e13554dc522.
2017-04-08 16:14:35 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (ce4131cc59d29a2d406e4e13554dc522).
2017-04-08 16:14:35 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:111 - Job ce4131cc59d29a2d406e4e13554dc522 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 16:14:36 INFO  JobManager:128 - Scheduling job ce4131cc59d29a2d406e4e13554dc522 (Flink Streaming Job).
2017-04-08 16:14:36 INFO  ExecutionGraph:965 - Job Flink Streaming Job (ce4131cc59d29a2d406e4e13554dc522) switched from state CREATED to RUNNING.
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (928a92a298cef1993b719313dcff92b2) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:275 - 04/08/2017 16:14:36	Job execution switched to status RUNNING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (928a92a298cef1993b719313dcff92b2) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f88f2ed78298780c7c382aed762ce29a) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f88f2ed78298780c7c382aed762ce29a) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (57e2e204368bbb5f234cb63bc1a3c5df) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (57e2e204368bbb5f234cb63bc1a3c5df) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (bd51bdf8d58e27927c30b43d7ea19437) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (bd51bdf8d58e27927c30b43d7ea19437) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (53e7611c6a50fbab7d7414de38bb59fb) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(1/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (53e7611c6a50fbab7d7414de38bb59fb) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(1/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (e29474e6b66f263438871b4243ba48aa) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(2/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (e29474e6b66f263438871b4243ba48aa) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(2/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (90957c678dba31b8dbf6103edf65b766) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(3/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (90957c678dba31b8dbf6103edf65b766) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(3/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (6974f2c1108841495d78c4dedd5cb375) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(4/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (6974f2c1108841495d78c4dedd5cb375) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(4/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (1/4) (2cc7485afc57ac80613af8a80ed4687b) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (1/4) (2cc7485afc57ac80613af8a80ed4687b) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (2/4) (9ac2b9a59e151cfd647fe4e2856120c1) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (2/4) (9ac2b9a59e151cfd647fe4e2856120c1) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (3/4) (136a789feccb3eb9552a7f5a8c0497c4) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (3/4) (136a789feccb3eb9552a7f5a8c0497c4) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (4/4) (cedad7e1a8484e6cb92a193adeb66a59) switched from CREATED to SCHEDULED.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (4/4) (cedad7e1a8484e6cb92a193adeb66a59) switched from SCHEDULED to DEPLOYING.
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (1/4) (928a92a298cef1993b719313dcff92b2) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f88f2ed78298780c7c382aed762ce29a) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  ExecutionGraph:354 - Deploying aggregation -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6fb0a98a for Source: Custom Source -> Map (1/4)
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7d46ce69 for Source: Custom Source -> Map (2/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (928a92a298cef1993b719313dcff92b2) [DEPLOYING].
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (f88f2ed78298780c7c382aed762ce29a) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (3/4) (57e2e204368bbb5f234cb63bc1a3c5df) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5aedf9bc for Source: Custom Source -> Map (3/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (57e2e204368bbb5f234cb63bc1a3c5df) [DEPLOYING].
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (4/4) (bd51bdf8d58e27927c30b43d7ea19437) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@207ef78b for Source: Custom Source -> Map (4/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (bd51bdf8d58e27927c30b43d7ea19437) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (f88f2ed78298780c7c382aed762ce29a) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (57e2e204368bbb5f234cb63bc1a3c5df) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (bd51bdf8d58e27927c30b43d7ea19437) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (928a92a298cef1993b719313dcff92b2) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (2/4) (f88f2ed78298780c7c382aed762ce29a) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (3/4) (57e2e204368bbb5f234cb63bc1a3c5df) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (1/4) (928a92a298cef1993b719313dcff92b2) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  Task:873 - Source: Custom Source -> Map (4/4) (bd51bdf8d58e27927c30b43d7ea19437) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (53e7611c6a50fbab7d7414de38bb59fb) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4ce644a4 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (53e7611c6a50fbab7d7414de38bb59fb) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (53e7611c6a50fbab7d7414de38bb59fb) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (53e7611c6a50fbab7d7414de38bb59fb) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4)
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (e29474e6b66f263438871b4243ba48aa) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@a12f0bd for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (e29474e6b66f263438871b4243ba48aa) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (e29474e6b66f263438871b4243ba48aa) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (e29474e6b66f263438871b4243ba48aa) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4)
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (90957c678dba31b8dbf6103edf65b766) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@477a9ee4 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (90957c678dba31b8dbf6103edf65b766) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (90957c678dba31b8dbf6103edf65b766) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (90957c678dba31b8dbf6103edf65b766) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4)
2017-04-08 16:14:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (6974f2c1108841495d78c4dedd5cb375) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:14:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1cc3cc for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (6974f2c1108841495d78c4dedd5cb375) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (6974f2c1108841495d78c4dedd5cb375) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (6974f2c1108841495d78c4dedd5cb375) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (1/4)
2017-04-08 16:14:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (1/4) (2cc7485afc57ac80613af8a80ed4687b) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6bbe235b for aggregation -> Sink: Unnamed (1/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (1/4) (2cc7485afc57ac80613af8a80ed4687b) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (1/4) (2cc7485afc57ac80613af8a80ed4687b) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (1/4) (2cc7485afc57ac80613af8a80ed4687b) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (2/4)
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (2/4) (9ac2b9a59e151cfd647fe4e2856120c1) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@23429132 for aggregation -> Sink: Unnamed (2/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (2/4) (9ac2b9a59e151cfd647fe4e2856120c1) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (2/4) (9ac2b9a59e151cfd647fe4e2856120c1) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (2/4) (9ac2b9a59e151cfd647fe4e2856120c1) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (3/4)
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (3/4) (136a789feccb3eb9552a7f5a8c0497c4) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5a9bcedc for aggregation -> Sink: Unnamed (3/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (3/4) (136a789feccb3eb9552a7f5a8c0497c4) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (3/4) (136a789feccb3eb9552a7f5a8c0497c4) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (3/4) (136a789feccb3eb9552a7f5a8c0497c4) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  TaskManager:128 - Received task aggregation -> Sink: Unnamed (4/4)
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (4/4) (cedad7e1a8484e6cb92a193adeb66a59) switched from CREATED to DEPLOYING.
2017-04-08 16:14:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@261016ba for aggregation -> Sink: Unnamed (4/4)
2017-04-08 16:14:36 INFO  Task:546 - Loading JAR files for task aggregation -> Sink: Unnamed (4/4) (cedad7e1a8484e6cb92a193adeb66a59) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:575 - Registering task at network: aggregation -> Sink: Unnamed (4/4) (cedad7e1a8484e6cb92a193adeb66a59) [DEPLOYING].
2017-04-08 16:14:36 INFO  Task:873 - aggregation -> Sink: Unnamed (4/4) (cedad7e1a8484e6cb92a193adeb66a59) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 16:14:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (f88f2ed78298780c7c382aed762ce29a) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (928a92a298cef1993b719313dcff92b2) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (57e2e204368bbb5f234cb63bc1a3c5df) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (bd51bdf8d58e27927c30b43d7ea19437) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (1/4) (53e7611c6a50fbab7d7414de38bb59fb) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(1/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (3/4) (90957c678dba31b8dbf6103edf65b766) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (2/4) (e29474e6b66f263438871b4243ba48aa) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(3/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map (4/4) (6974f2c1108841495d78c4dedd5cb375) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (1/4) (2cc7485afc57ac80613af8a80ed4687b) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(4/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@677fd088}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Map(2/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (2/4) (9ac2b9a59e151cfd647fe4e2856120c1) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (4/4) (cedad7e1a8484e6cb92a193adeb66a59) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ExecutionGraph:1025 - aggregation -> Sink: Unnamed (3/4) (136a789feccb3eb9552a7f5a8c0497c4) switched from DEPLOYING to RUNNING.
2017-04-08 16:14:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 16:14:36	aggregation -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:14:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:14:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:14:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:14:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:14:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:14:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:14:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 16:14:36 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 16:14:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 16:14:37 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:14:37 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:14:37 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 16:14:37 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 16:14:37 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 16:14:37 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 16:14:37 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 131, so the initial offset will be set to 130
2017-04-08 16:14:37 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 143, so the initial offset will be set to 142
2017-04-08 18:25:28 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 18:25:28 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 18:25:28 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 18:25:29 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 18:25:31 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 18:25:31 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-12fa5a7b-0621-4ad7-bd6a-29dd62d0e586
2017-04-08 18:25:31 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:53475 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 18:25:31 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 18:25:31 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 18:25:31 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 18:25:31 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 18:25:31 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 18:25:31 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-08 18:25:31 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 18:25:31 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1787370477] - leader session null
2017-04-08 18:25:31 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 18:25:31 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 18:25:31 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-08 18:25:31 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-e04561e8-21de-443b-981a-19a84493539b for spill files.
2017-04-08 18:25:31 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 18:25:31 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-464720d3-b85f-4bc8-a412-da3ac213ca8a
2017-04-08 18:25:31 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#997857749.
2017-04-08 18:25:31 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='e734991918a43007024581363b6c51a4'} @ localhost (dataPort=-1)
2017-04-08 18:25:31 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 18:25:31 INFO  TaskManager:128 - Memory usage stats: [HEAP: 181/799/910 MB, NON HEAP: 121/126/-1 MB (used/committed/max)]
2017-04-08 18:25:31 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 18:25:31 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='e734991918a43007024581363b6c51a4'} has started.
2017-04-08 18:25:31 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 49e266ebc2083967b3e090b7e235b929. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 18:25:31 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 18:25:31 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:53475. Starting BLOB cache.
2017-04-08 18:25:31 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-e644622b-d5bd-4075-8d43-d609f50c374c
2017-04-08 18:25:31 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 11595008c5351111296638602f6dcaa5)) but there is no connection to a JobManager yet.
2017-04-08 18:25:31 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (11595008c5351111296638602f6dcaa5).
2017-04-08 18:25:31 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1787370477].
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1787370477]
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (11595008c5351111296638602f6dcaa5) and wait for progress
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 18:25:32 INFO  JobManager:128 - Submitting job 11595008c5351111296638602f6dcaa5 (Flink Streaming Job).
2017-04-08 18:25:32 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 11595008c5351111296638602f6dcaa5.
2017-04-08 18:25:32 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (11595008c5351111296638602f6dcaa5).
2017-04-08 18:25:32 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:111 - Job 11595008c5351111296638602f6dcaa5 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 18:25:32 INFO  JobManager:128 - Scheduling job 11595008c5351111296638602f6dcaa5 (Flink Streaming Job).
2017-04-08 18:25:32 INFO  ExecutionGraph:965 - Job Flink Streaming Job (11595008c5351111296638602f6dcaa5) switched from state CREATED to RUNNING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:275 - 04/08/2017 18:25:32	Job execution switched to status RUNNING.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3d44b632ac8dbf1f4c81174b551244fd) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3d44b632ac8dbf1f4c81174b551244fd) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (389f57728ef6b12e67745fd20a3b8a9a) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (389f57728ef6b12e67745fd20a3b8a9a) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (84ca14aefe577b3c926c5a6d2ea23e03) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (84ca14aefe577b3c926c5a6d2ea23e03) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (103bea0c8cc93a449edbeffd749116ac) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (103bea0c8cc93a449edbeffd749116ac) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (761a26d70a6931986f5b2fe61531d1df) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (761a26d70a6931986f5b2fe61531d1df) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (9e49a65821471317a4ebd6ac32d649fc) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (9e49a65821471317a4ebd6ac32d649fc) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (d5f28bc91e5c446777aa052219591817) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (d5f28bc91e5c446777aa052219591817) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (76681b7cc46fd8d8ab85766260b1d5d2) switched from CREATED to SCHEDULED.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (76681b7cc46fd8d8ab85766260b1d5d2) switched from SCHEDULED to DEPLOYING.
2017-04-08 18:25:32 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3d44b632ac8dbf1f4c81174b551244fd) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (2/4) (389f57728ef6b12e67745fd20a3b8a9a) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6610e77a for Source: Custom Source -> Map (2/4)
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (3/4) (84ca14aefe577b3c926c5a6d2ea23e03) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@521630c7 for Source: Custom Source -> Map (1/4)
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (3d44b632ac8dbf1f4c81174b551244fd) [DEPLOYING].
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@796ca350 for Source: Custom Source -> Map (3/4)
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (84ca14aefe577b3c926c5a6d2ea23e03) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (389f57728ef6b12e67745fd20a3b8a9a) [DEPLOYING].
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (4/4) (103bea0c8cc93a449edbeffd749116ac) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@521d9e3d for Source: Custom Source -> Map (4/4)
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (103bea0c8cc93a449edbeffd749116ac) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (389f57728ef6b12e67745fd20a3b8a9a) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (103bea0c8cc93a449edbeffd749116ac) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (3d44b632ac8dbf1f4c81174b551244fd) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (84ca14aefe577b3c926c5a6d2ea23e03) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (4/4) (103bea0c8cc93a449edbeffd749116ac) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (3/4) (84ca14aefe577b3c926c5a6d2ea23e03) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (2/4) (389f57728ef6b12e67745fd20a3b8a9a) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3d44b632ac8dbf1f4c81174b551244fd) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (761a26d70a6931986f5b2fe61531d1df) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2700f974 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (761a26d70a6931986f5b2fe61531d1df) [DEPLOYING].
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (761a26d70a6931986f5b2fe61531d1df) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (761a26d70a6931986f5b2fe61531d1df) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (9e49a65821471317a4ebd6ac32d649fc) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@ffb5bb4 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (9e49a65821471317a4ebd6ac32d649fc) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (9e49a65821471317a4ebd6ac32d649fc) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (9e49a65821471317a4ebd6ac32d649fc) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (d5f28bc91e5c446777aa052219591817) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25830300 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (d5f28bc91e5c446777aa052219591817) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (d5f28bc91e5c446777aa052219591817) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (d5f28bc91e5c446777aa052219591817) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (76681b7cc46fd8d8ab85766260b1d5d2) switched from CREATED to DEPLOYING.
2017-04-08 18:25:32 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5323c7d5 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-08 18:25:32 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (76681b7cc46fd8d8ab85766260b1d5d2) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (76681b7cc46fd8d8ab85766260b1d5d2) [DEPLOYING].
2017-04-08 18:25:32 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (76681b7cc46fd8d8ab85766260b1d5d2) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 18:25:32 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (84ca14aefe577b3c926c5a6d2ea23e03) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (389f57728ef6b12e67745fd20a3b8a9a) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3d44b632ac8dbf1f4c81174b551244fd) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (103bea0c8cc93a449edbeffd749116ac) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (761a26d70a6931986f5b2fe61531d1df) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (9e49a65821471317a4ebd6ac32d649fc) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (d5f28bc91e5c446777aa052219591817) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 18:25:32 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (76681b7cc46fd8d8ab85766260b1d5d2) switched from DEPLOYING to RUNNING.
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  JobSubmissionClientActor:265 - 04/08/2017 18:25:32	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@17033f11}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 18:25:32 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 18:25:32 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 18:25:32 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 18:25:32 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 18:25:32 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 18:25:32 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:33 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 18:25:33 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 18:25:33 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 18:25:33 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 18:25:33 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 18:25:33 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 18:25:33 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 18:25:33 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 18:25:34 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 18:25:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:34 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 18:25:34 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 18:25:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:34 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 18:25:34 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 18:25:34 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 18:25:34 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 18:25:34 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 18:25:34 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 144, so the initial offset will be set to 143
2017-04-08 18:25:34 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 132, so the initial offset will be set to 131
2017-04-08 20:40:34 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-08 20:40:34 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-08 20:40:34 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-08 20:40:35 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-08 20:40:35 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-08 20:40:35 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-58f7dddd-7468-4559-9e70-80a1cd2347d3
2017-04-08 20:40:35 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:54447 - max concurrent requests: 50 - max backlog: 1000
2017-04-08 20:40:35 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 20:40:35 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-08 20:40:35 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-08 20:40:35 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-08 20:40:35 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-08 20:40:35 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-08 20:40:35 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 15 GB (13,51% usable)
2017-04-08 20:40:35 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1312067986] - leader session null
2017-04-08 20:40:35 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-08 20:40:35 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-08 20:40:35 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-08 20:40:35 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-3f988ce7-16a2-43f7-a548-a07d94b21749 for spill files.
2017-04-08 20:40:35 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-08 20:40:35 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-ca32ee60-cb0b-4ab7-817b-488a7252bb8e
2017-04-08 20:40:35 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-263501744.
2017-04-08 20:40:35 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='dd63fb6435b81a2fb1e3f177c22631ad'} @ localhost (dataPort=-1)
2017-04-08 20:40:35 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-08 20:40:35 INFO  TaskManager:128 - Memory usage stats: [HEAP: 175/820/910 MB, NON HEAP: 121/124/-1 MB (used/committed/max)]
2017-04-08 20:40:35 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-08 20:40:35 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='dd63fb6435b81a2fb1e3f177c22631ad'} has started.
2017-04-08 20:40:35 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 585b05ce64ede7b2d23c729ed7a4ec92. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-08 20:40:35 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-08 20:40:35 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:54447. Starting BLOB cache.
2017-04-08 20:40:35 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-c1ae29cd-3104-4c94-ab7a-19a74402d2a8
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 06cbaeedf2f22acda0d01700dfd75782)) but there is no connection to a JobManager yet.
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (06cbaeedf2f22acda0d01700dfd75782).
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1312067986].
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1312067986]
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (06cbaeedf2f22acda0d01700dfd75782) and wait for progress
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-08 20:40:35 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-08 20:40:35 INFO  JobManager:128 - Submitting job 06cbaeedf2f22acda0d01700dfd75782 (Flink Streaming Job).
2017-04-08 20:40:35 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 06cbaeedf2f22acda0d01700dfd75782.
2017-04-08 20:40:35 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (06cbaeedf2f22acda0d01700dfd75782).
2017-04-08 20:40:35 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:111 - Job 06cbaeedf2f22acda0d01700dfd75782 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-08 20:40:36 INFO  JobManager:128 - Scheduling job 06cbaeedf2f22acda0d01700dfd75782 (Flink Streaming Job).
2017-04-08 20:40:36 INFO  ExecutionGraph:965 - Job Flink Streaming Job (06cbaeedf2f22acda0d01700dfd75782) switched from state CREATED to RUNNING.
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (e5fe97713b19d501658a57dd5d4e7c1d) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:275 - 04/08/2017 20:40:36	Job execution switched to status RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (e5fe97713b19d501658a57dd5d4e7c1d) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (1d1c6402183f93c5d8b29c69125ee127) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (1d1c6402183f93c5d8b29c69125ee127) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (0b7a61bca9ad26b31c01888e2abc55a4) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (0b7a61bca9ad26b31c01888e2abc55a4) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6b64d7903c52a526f581866ab615f2cb) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6b64d7903c52a526f581866ab615f2cb) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (169c3f9d338aab9c5f6608755c7ed597) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (169c3f9d338aab9c5f6608755c7ed597) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (d32cf9bb99505c37e97cbff2d0995347) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (d32cf9bb99505c37e97cbff2d0995347) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ff9acdf5d204ef3cfa1f238173443ddf) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ff9acdf5d204ef3cfa1f238173443ddf) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (270a3f0ae026d397205e458e70fc38a5) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (270a3f0ae026d397205e458e70fc38a5) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (1/4) (b58c1309f8c68fdab5087777a34a337f) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (1/4) (b58c1309f8c68fdab5087777a34a337f) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (2/4) (3151aced0e9c5f566662fadcb5631ca4) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (2/4) (3151aced0e9c5f566662fadcb5631ca4) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (3/4) (97af758b960167feb680baa46d489138) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (3/4) (97af758b960167feb680baa46d489138) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (4/4) (b61c47434a74102ab83c51086d9f6d2c) switched from CREATED to SCHEDULED.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (4/4) (b61c47434a74102ab83c51086d9f6d2c) switched from SCHEDULED to DEPLOYING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-08 20:40:36 INFO  ExecutionGraph:354 - Deploying Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (1/4) (e5fe97713b19d501658a57dd5d4e7c1d) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (2/4) (1d1c6402183f93c5d8b29c69125ee127) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (3/4) (0b7a61bca9ad26b31c01888e2abc55a4) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6130b473 for Source: Custom Source -> Map (2/4)
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@324ee0ce for Source: Custom Source -> Map (3/4)
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49485260 for Source: Custom Source -> Map (1/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (1d1c6402183f93c5d8b29c69125ee127) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (0b7a61bca9ad26b31c01888e2abc55a4) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (e5fe97713b19d501658a57dd5d4e7c1d) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (1d1c6402183f93c5d8b29c69125ee127) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (e5fe97713b19d501658a57dd5d4e7c1d) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (0b7a61bca9ad26b31c01888e2abc55a4) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (3/4) (0b7a61bca9ad26b31c01888e2abc55a4) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (1/4) (e5fe97713b19d501658a57dd5d4e7c1d) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (2/4) (1d1c6402183f93c5d8b29c69125ee127) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6b64d7903c52a526f581866ab615f2cb) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@66cc8b7c for Source: Custom Source -> Map (4/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (6b64d7903c52a526f581866ab615f2cb) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (6b64d7903c52a526f581866ab615f2cb) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - Source: Custom Source -> Map (4/4) (6b64d7903c52a526f581866ab615f2cb) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 20:40:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 20:40:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 20:40:36 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (169c3f9d338aab9c5f6608755c7ed597) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4e2ff10 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (169c3f9d338aab9c5f6608755c7ed597) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (169c3f9d338aab9c5f6608755c7ed597) [DEPLOYING].
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (169c3f9d338aab9c5f6608755c7ed597) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (d32cf9bb99505c37e97cbff2d0995347) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1b2bd46c for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (d32cf9bb99505c37e97cbff2d0995347) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (d32cf9bb99505c37e97cbff2d0995347) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (d32cf9bb99505c37e97cbff2d0995347) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ff9acdf5d204ef3cfa1f238173443ddf) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6f023999 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ff9acdf5d204ef3cfa1f238173443ddf) [DEPLOYING].
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (270a3f0ae026d397205e458e70fc38a5) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ff9acdf5d204ef3cfa1f238173443ddf) [DEPLOYING].
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1342433b for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (270a3f0ae026d397205e458e70fc38a5) [DEPLOYING].
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Map -> Sink: Unnamed (1/4)
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ff9acdf5d204ef3cfa1f238173443ddf) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (270a3f0ae026d397205e458e70fc38a5) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (1/4) (b58c1309f8c68fdab5087777a34a337f) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1a102a46 for Map -> Sink: Unnamed (1/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Map -> Sink: Unnamed (1/4) (b58c1309f8c68fdab5087777a34a337f) [DEPLOYING].
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Map -> Sink: Unnamed (2/4)
2017-04-08 20:40:36 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (270a3f0ae026d397205e458e70fc38a5) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Map -> Sink: Unnamed (1/4) (b58c1309f8c68fdab5087777a34a337f) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (1/4) (b58c1309f8c68fdab5087777a34a337f) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (2/4) (3151aced0e9c5f566662fadcb5631ca4) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@434074ca for Map -> Sink: Unnamed (2/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Map -> Sink: Unnamed (2/4) (3151aced0e9c5f566662fadcb5631ca4) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Map -> Sink: Unnamed (2/4) (3151aced0e9c5f566662fadcb5631ca4) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (2/4) (3151aced0e9c5f566662fadcb5631ca4) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Map -> Sink: Unnamed (3/4)
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (3/4) (97af758b960167feb680baa46d489138) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1401cbb9 for Map -> Sink: Unnamed (3/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Map -> Sink: Unnamed (3/4) (97af758b960167feb680baa46d489138) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Map -> Sink: Unnamed (3/4) (97af758b960167feb680baa46d489138) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (3/4) (97af758b960167feb680baa46d489138) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  TaskManager:128 - Received task Map -> Sink: Unnamed (4/4)
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (4/4) (b61c47434a74102ab83c51086d9f6d2c) switched from CREATED to DEPLOYING.
2017-04-08 20:40:36 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@717d1f8c for Map -> Sink: Unnamed (4/4)
2017-04-08 20:40:36 INFO  Task:546 - Loading JAR files for task Map -> Sink: Unnamed (4/4) (b61c47434a74102ab83c51086d9f6d2c) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:575 - Registering task at network: Map -> Sink: Unnamed (4/4) (b61c47434a74102ab83c51086d9f6d2c) [DEPLOYING].
2017-04-08 20:40:36 INFO  Task:873 - Map -> Sink: Unnamed (4/4) (b61c47434a74102ab83c51086d9f6d2c) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-08 20:40:36 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (0b7a61bca9ad26b31c01888e2abc55a4) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (1d1c6402183f93c5d8b29c69125ee127) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (e5fe97713b19d501658a57dd5d4e7c1d) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (169c3f9d338aab9c5f6608755c7ed597) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (6b64d7903c52a526f581866ab615f2cb) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (d32cf9bb99505c37e97cbff2d0995347) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (1/4) (b58c1309f8c68fdab5087777a34a337f) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (2/4) (3151aced0e9c5f566662fadcb5631ca4) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (3/4) (97af758b960167feb680baa46d489138) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ff9acdf5d204ef3cfa1f238173443ddf) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - Map -> Sink: Unnamed (4/4) (b61c47434a74102ab83c51086d9f6d2c) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (270a3f0ae026d397205e458e70fc38a5) switched from DEPLOYING to RUNNING.
2017-04-08 20:40:36 INFO  JobSubmissionClientActor:265 - 04/08/2017 20:40:36	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@f46b7fed}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 20:40:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 20:40:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 20:40:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 20:40:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 20:40:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 20:40:36 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 20:40:36 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-08 20:40:37 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-08 20:40:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:37 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-08 20:40:37 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 20:40:37 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-08 20:40:37 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 20:40:37 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-08 20:40:37 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 20:40:37 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-08 20:40:37 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 146, so the initial offset will be set to 145
2017-04-08 20:40:37 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 132, so the initial offset will be set to 131
2017-04-09 11:32:02 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-09 11:32:02 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-09 11:32:03 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-09 11:32:03 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-09 11:32:04 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-09 11:32:04 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-bbc9b5eb-c850-4e46-aeb3-9f3d1aff4cc4
2017-04-09 11:32:04 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:56447 - max concurrent requests: 50 - max backlog: 1000
2017-04-09 11:32:04 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-09 11:32:04 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-09 11:32:04 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-09 11:32:04 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-09 11:32:04 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-09 11:32:04 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 16 GB (14,41% usable)
2017-04-09 11:32:04 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-09 11:32:04 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#204206503] - leader session null
2017-04-09 11:32:04 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-09 11:32:05 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-09 11:32:05 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-09 11:32:05 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-2f949617-19e0-4407-b271-da35c610559f for spill files.
2017-04-09 11:32:05 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-09 11:32:05 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-aefe5027-4ec3-4c45-b8c4-e7cf2b2ea66a
2017-04-09 11:32:05 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#286629541.
2017-04-09 11:32:05 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='60293b3d0b2d231aa0460f1111689017'} @ localhost (dataPort=-1)
2017-04-09 11:32:05 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-09 11:32:05 INFO  TaskManager:128 - Memory usage stats: [HEAP: 181/809/910 MB, NON HEAP: 121/124/-1 MB (used/committed/max)]
2017-04-09 11:32:05 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-09 11:32:05 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='60293b3d0b2d231aa0460f1111689017'} has started.
2017-04-09 11:32:05 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 7dbfe503fa9b59856665b21733e1fd38. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-09 11:32:05 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-09 11:32:05 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:56447. Starting BLOB cache.
2017-04-09 11:32:05 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-f9014629-09b6-469b-a15f-b3ddffd7b616
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 71ac8ec1b529b3f9934b46f77474dfd5)) but there is no connection to a JobManager yet.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (71ac8ec1b529b3f9934b46f77474dfd5).
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#204206503].
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#204206503]
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (71ac8ec1b529b3f9934b46f77474dfd5) and wait for progress
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-09 11:32:05 INFO  JobManager:128 - Submitting job 71ac8ec1b529b3f9934b46f77474dfd5 (Flink Streaming Job).
2017-04-09 11:32:05 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 71ac8ec1b529b3f9934b46f77474dfd5.
2017-04-09 11:32:05 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (71ac8ec1b529b3f9934b46f77474dfd5).
2017-04-09 11:32:05 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:111 - Job 71ac8ec1b529b3f9934b46f77474dfd5 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-09 11:32:05 INFO  JobManager:128 - Scheduling job 71ac8ec1b529b3f9934b46f77474dfd5 (Flink Streaming Job).
2017-04-09 11:32:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (71ac8ec1b529b3f9934b46f77474dfd5) switched from state CREATED to RUNNING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:275 - 04/09/2017 11:32:05	Job execution switched to status RUNNING.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af35257d6bd32fec029ddd2e09e51cf) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af35257d6bd32fec029ddd2e09e51cf) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (da519b6718c6499a644a5c577e7f6faa) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (da519b6718c6499a644a5c577e7f6faa) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c6bbb453befc006b788e287431b5d73) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c6bbb453befc006b788e287431b5d73) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (baf3c0b6c82bd4948b7d421a8488e01a) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (baf3c0b6c82bd4948b7d421a8488e01a) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (128c372190d15e8d1973b3cb50792e59) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (128c372190d15e8d1973b3cb50792e59) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bd2010b7bc2831bc8be4b01e7b777f51) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bd2010b7bc2831bc8be4b01e7b777f51) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (c4bf1b18be2bf3ab0f0f526a9a079645) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (c4bf1b18be2bf3ab0f0f526a9a079645) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (1b4478f7ca19ce9543235b7059939a11) switched from CREATED to SCHEDULED.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (1b4478f7ca19ce9543235b7059939a11) switched from SCHEDULED to DEPLOYING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-09 11:32:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3af35257d6bd32fec029ddd2e09e51cf) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (da519b6718c6499a644a5c577e7f6faa) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9c6bbb453befc006b788e287431b5d73) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (baf3c0b6c82bd4948b7d421a8488e01a) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5f8f707c for Source: Custom Source -> Map (1/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (3af35257d6bd32fec029ddd2e09e51cf) [DEPLOYING].
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1425a3c7 for Source: Custom Source -> Map (4/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (baf3c0b6c82bd4948b7d421a8488e01a) [DEPLOYING].
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7a855eca for Source: Custom Source -> Map (3/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (9c6bbb453befc006b788e287431b5d73) [DEPLOYING].
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2cf6cfc5 for Source: Custom Source -> Map (2/4)
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (da519b6718c6499a644a5c577e7f6faa) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (128c372190d15e8d1973b3cb50792e59) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@71dbfcf3 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (128c372190d15e8d1973b3cb50792e59) [DEPLOYING].
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bd2010b7bc2831bc8be4b01e7b777f51) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7fdb7331 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bd2010b7bc2831bc8be4b01e7b777f51) [DEPLOYING].
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (c4bf1b18be2bf3ab0f0f526a9a079645) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5bef4f1f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (c4bf1b18be2bf3ab0f0f526a9a079645) [DEPLOYING].
2017-04-09 11:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (9c6bbb453befc006b788e287431b5d73) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (3af35257d6bd32fec029ddd2e09e51cf) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (1b4478f7ca19ce9543235b7059939a11) switched from CREATED to DEPLOYING.
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (c4bf1b18be2bf3ab0f0f526a9a079645) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (128c372190d15e8d1973b3cb50792e59) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (da519b6718c6499a644a5c577e7f6faa) [DEPLOYING].
2017-04-09 11:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@54acb5b7 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4)
2017-04-09 11:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (1b4478f7ca19ce9543235b7059939a11) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (1b4478f7ca19ce9543235b7059939a11) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bd2010b7bc2831bc8be4b01e7b777f51) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (baf3c0b6c82bd4948b7d421a8488e01a) [DEPLOYING].
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (9c6bbb453befc006b788e287431b5d73) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (128c372190d15e8d1973b3cb50792e59) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (1b4478f7ca19ce9543235b7059939a11) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (da519b6718c6499a644a5c577e7f6faa) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bd2010b7bc2831bc8be4b01e7b777f51) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (baf3c0b6c82bd4948b7d421a8488e01a) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3af35257d6bd32fec029ddd2e09e51cf) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (c4bf1b18be2bf3ab0f0f526a9a079645) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (9c6bbb453befc006b788e287431b5d73) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (1/4) (128c372190d15e8d1973b3cb50792e59) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (4/4) (1b4478f7ca19ce9543235b7059939a11) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (da519b6718c6499a644a5c577e7f6faa) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (2/4) (bd2010b7bc2831bc8be4b01e7b777f51) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (baf3c0b6c82bd4948b7d421a8488e01a) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed (3/4) (c4bf1b18be2bf3ab0f0f526a9a079645) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3af35257d6bd32fec029ddd2e09e51cf) switched from DEPLOYING to RUNNING.
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$12$$anon$4@bdf6561d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 11:32:05	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-09 11:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 11:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 11:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 11:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 11:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 11:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 11:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 11:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 11:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 11:32:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 11:32:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 11:32:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 11:32:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 11:32:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 11:32:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 11:32:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 11:32:06 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 11:32:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 11:32:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 11:32:06 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 11:32:06 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 11:32:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-09 11:32:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-09 11:32:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 135, so the initial offset will be set to 134
2017-04-09 11:32:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 146, so the initial offset will be set to 145
2017-04-09 13:18:40 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-09 13:18:43 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-09 13:18:44 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-09 13:18:44 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-09 13:18:44 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-09 13:18:44 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-964f8083-6dcc-433a-97cd-0a1d8a2f9fb6
2017-04-09 13:18:44 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:59477 - max concurrent requests: 50 - max backlog: 1000
2017-04-09 13:18:44 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-09 13:18:44 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-09 13:18:44 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-09 13:18:44 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-09 13:18:44 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-09 13:18:44 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-09 13:18:44 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-09 13:18:44 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-09 13:18:44 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#683399349] - leader session null
2017-04-09 13:18:44 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-09 13:18:44 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-09 13:18:44 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-5645fd74-9de6-4288-a856-b1a8a11c743c for spill files.
2017-04-09 13:18:44 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-09 13:18:44 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-76a3e3f3-36bf-4c20-9e8a-770a34283537
2017-04-09 13:18:44 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1794964924.
2017-04-09 13:18:44 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='dbc685f2f0d740986ef0aab1b7fa2110'} @ localhost (dataPort=-1)
2017-04-09 13:18:44 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-09 13:18:44 INFO  TaskManager:128 - Memory usage stats: [HEAP: 177/863/910 MB, NON HEAP: 141/144/-1 MB (used/committed/max)]
2017-04-09 13:18:44 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-09 13:18:44 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='dbc685f2f0d740986ef0aab1b7fa2110'} has started.
2017-04-09 13:18:44 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as e0bf35564ae48b107d031a81aa58fba8. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-09 13:18:44 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-09 13:18:44 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:59477. Starting BLOB cache.
2017-04-09 13:18:44 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-3c97c6c6-e3c8-4d0b-b78a-0f16b4cff2c9
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 432c25f6fd5efe9f4edc5152d8e52585)) but there is no connection to a JobManager yet.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (432c25f6fd5efe9f4edc5152d8e52585).
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#683399349].
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#683399349]
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (432c25f6fd5efe9f4edc5152d8e52585) and wait for progress
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-09 13:18:44 INFO  JobManager:128 - Submitting job 432c25f6fd5efe9f4edc5152d8e52585 (Flink Streaming Job).
2017-04-09 13:18:44 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 432c25f6fd5efe9f4edc5152d8e52585.
2017-04-09 13:18:44 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (432c25f6fd5efe9f4edc5152d8e52585).
2017-04-09 13:18:44 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:111 - Job 432c25f6fd5efe9f4edc5152d8e52585 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-09 13:18:44 INFO  JobManager:128 - Scheduling job 432c25f6fd5efe9f4edc5152d8e52585 (Flink Streaming Job).
2017-04-09 13:18:44 INFO  ExecutionGraph:965 - Job Flink Streaming Job (432c25f6fd5efe9f4edc5152d8e52585) switched from state CREATED to RUNNING.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:275 - 04/09/2017 13:18:44	Job execution switched to status RUNNING.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3f72f98cf4ae05b55d31ae0f370e7b87) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3f72f98cf4ae05b55d31ae0f370e7b87) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c0b5b270470c2543b0202aecc1421c95) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c0b5b270470c2543b0202aecc1421c95) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (4c1a6d647301522c5ea11272e4512ae3) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (4c1a6d647301522c5ea11272e4512ae3) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (be1dc205431a850848369d4cfc8f7942) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (be1dc205431a850848369d4cfc8f7942) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (a49331ea7c4f709444838f766f3f47ab) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (a49331ea7c4f709444838f766f3f47ab) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(1/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(1/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d7b1649f8d7ba70ee70ad1fa9a1ff5c9) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d7b1649f8d7ba70ee70ad1fa9a1ff5c9) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(2/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (0cfb21d7cf964d2d2368a126ca842d20) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (0cfb21d7cf964d2d2368a126ca842d20) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(2/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(3/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(3/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (7bb788ba09e7829f4963eb50c99b4e55) switched from CREATED to SCHEDULED.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (7bb788ba09e7829f4963eb50c99b4e55) switched from SCHEDULED to DEPLOYING.
2017-04-09 13:18:44 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (attempt #0) to localhost
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(4/4) switched to SCHEDULED 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(4/4) switched to DEPLOYING 
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3f72f98cf4ae05b55d31ae0f370e7b87) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c0b5b270470c2543b0202aecc1421c95) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (4c1a6d647301522c5ea11272e4512ae3) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@73dbebd9 for Source: Custom Source -> Map (3/4)
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3ad4d00 for Source: Custom Source -> Map (1/4)
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (4c1a6d647301522c5ea11272e4512ae3) [DEPLOYING].
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@373bbefa for Source: Custom Source -> Map (2/4)
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (3f72f98cf4ae05b55d31ae0f370e7b87) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (c0b5b270470c2543b0202aecc1421c95) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (be1dc205431a850848369d4cfc8f7942) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3399007 for Source: Custom Source -> Map (4/4)
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (be1dc205431a850848369d4cfc8f7942) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (3f72f98cf4ae05b55d31ae0f370e7b87) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (c0b5b270470c2543b0202aecc1421c95) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (4c1a6d647301522c5ea11272e4512ae3) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (be1dc205431a850848369d4cfc8f7942) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (1/4) (3f72f98cf4ae05b55d31ae0f370e7b87) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c0b5b270470c2543b0202aecc1421c95) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (3/4) (4c1a6d647301522c5ea11272e4512ae3) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  Task:873 - Source: Custom Source -> Map (4/4) (be1dc205431a850848369d4cfc8f7942) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4)
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (a49331ea7c4f709444838f766f3f47ab) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4bd332b9 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4)
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (a49331ea7c4f709444838f766f3f47ab) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (a49331ea7c4f709444838f766f3f47ab) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (a49331ea7c4f709444838f766f3f47ab) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4)
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d7b1649f8d7ba70ee70ad1fa9a1ff5c9) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d023f2b for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4)
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d7b1649f8d7ba70ee70ad1fa9a1ff5c9) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d7b1649f8d7ba70ee70ad1fa9a1ff5c9) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d7b1649f8d7ba70ee70ad1fa9a1ff5c9) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4)
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (0cfb21d7cf964d2d2368a126ca842d20) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7910e2f5 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4)
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (0cfb21d7cf964d2d2368a126ca842d20) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (0cfb21d7cf964d2d2368a126ca842d20) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (0cfb21d7cf964d2d2368a126ca842d20) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4)
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (7bb788ba09e7829f4963eb50c99b4e55) switched from CREATED to DEPLOYING.
2017-04-09 13:18:44 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2b720a3d for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4)
2017-04-09 13:18:44 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (7bb788ba09e7829f4963eb50c99b4e55) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (7bb788ba09e7829f4963eb50c99b4e55) [DEPLOYING].
2017-04-09 13:18:44 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (7bb788ba09e7829f4963eb50c99b4e55) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 13:18:44 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 13:18:44 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, e0bf35564ae48b107d031a81aa58fba8, Flink Streaming Job, Sink: Unnamed, 2]
2017-04-09 13:18:44 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, e0bf35564ae48b107d031a81aa58fba8, Flink Streaming Job, Sink: Unnamed, 0]
2017-04-09 13:18:44 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, e0bf35564ae48b107d031a81aa58fba8, Flink Streaming Job, Sink: Unnamed, 3]
2017-04-09 13:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 13:18:44 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, e0bf35564ae48b107d031a81aa58fba8, Flink Streaming Job, Sink: Unnamed, 1]
2017-04-09 13:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 13:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 13:18:44 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c0b5b270470c2543b0202aecc1421c95) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (4c1a6d647301522c5ea11272e4512ae3) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (a49331ea7c4f709444838f766f3f47ab) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d7b1649f8d7ba70ee70ad1fa9a1ff5c9) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (3f72f98cf4ae05b55d31ae0f370e7b87) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (0cfb21d7cf964d2d2368a126ca842d20) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(1/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(2/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (be1dc205431a850848369d4cfc8f7942) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (7bb788ba09e7829f4963eb50c99b4e55) switched from DEPLOYING to RUNNING.
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(3/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  JobSubmissionClientActor:265 - 04/09/2017 13:18:44	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@cf2decb0}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(4/4) switched to RUNNING 
2017-04-09 13:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 13:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 13:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 13:18:44 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 13:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:44 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 13:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 13:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 13:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 13:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 13:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 13:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 13:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 13:18:45 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 13:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 13:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 13:18:45 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 13:18:45 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 13:18:45 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-09 13:18:45 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-09 13:18:45 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 148, so the initial offset will be set to 147
2017-04-09 13:18:45 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 135, so the initial offset will be set to 134
2017-04-09 13:36:12 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-09 13:37:18 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-09 18:32:03 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-09 18:32:03 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-09 18:32:03 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-09 18:32:03 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-09 18:32:04 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-09 18:32:04 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-8fee47b4-c033-46c4-8eab-2a0b11fb0fc6
2017-04-09 18:32:04 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:55267 - max concurrent requests: 50 - max backlog: 1000
2017-04-09 18:32:04 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-09 18:32:04 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-09 18:32:04 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-09 18:32:04 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-09 18:32:04 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-09 18:32:04 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-09 18:32:04 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-09 18:32:04 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-09 18:32:04 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-902326057] - leader session null
2017-04-09 18:32:04 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-09 18:32:04 INFO  TaskManager:128 - Limiting managed memory to 255 MB, memory will be allocated lazily.
2017-04-09 18:32:04 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-131a3de9-2066-4460-9413-43b87ed632f8 for spill files.
2017-04-09 18:32:04 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-09 18:32:04 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-97714827-1f4b-4462-9475-a8355989fd6f
2017-04-09 18:32:04 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#2096470034.
2017-04-09 18:32:04 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='9a9f2682b96f22a58db30fca7720bcea'} @ localhost (dataPort=-1)
2017-04-09 18:32:04 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-09 18:32:04 INFO  TaskManager:128 - Memory usage stats: [HEAP: 172/902/910 MB, NON HEAP: 120/125/-1 MB (used/committed/max)]
2017-04-09 18:32:04 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-09 18:32:04 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='9a9f2682b96f22a58db30fca7720bcea'} has started.
2017-04-09 18:32:04 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 975161f548503971afb6cd5b2894a21f. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-09 18:32:04 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-09 18:32:04 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:55267. Starting BLOB cache.
2017-04-09 18:32:04 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-8c51763b-102c-4be9-a25d-7143b1e27f95
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: a012ef27bd68cf744fa8df30d636964a)) but there is no connection to a JobManager yet.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (a012ef27bd68cf744fa8df30d636964a).
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-902326057].
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-902326057]
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (a012ef27bd68cf744fa8df30d636964a) and wait for progress
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-09 18:32:04 INFO  JobManager:128 - Submitting job a012ef27bd68cf744fa8df30d636964a (Flink Streaming Job).
2017-04-09 18:32:04 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for a012ef27bd68cf744fa8df30d636964a.
2017-04-09 18:32:04 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (a012ef27bd68cf744fa8df30d636964a).
2017-04-09 18:32:04 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:111 - Job a012ef27bd68cf744fa8df30d636964a was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-09 18:32:04 INFO  JobManager:128 - Scheduling job a012ef27bd68cf744fa8df30d636964a (Flink Streaming Job).
2017-04-09 18:32:04 INFO  ExecutionGraph:965 - Job Flink Streaming Job (a012ef27bd68cf744fa8df30d636964a) switched from state CREATED to RUNNING.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0ee73f94109d7237d9811988585c0f99) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:275 - 04/09/2017 18:32:04	Job execution switched to status RUNNING.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0ee73f94109d7237d9811988585c0f99) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (447e3a025de914dcfd503bc73782080a) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (447e3a025de914dcfd503bc73782080a) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (33eb4cfaebea952ba170b37ac4b6e430) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (33eb4cfaebea952ba170b37ac4b6e430) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (482f55cb85236aef437e4dba452eca6d) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (482f55cb85236aef437e4dba452eca6d) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (087231d665320e7b8a94a7ce86883f47) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (087231d665320e7b8a94a7ce86883f47) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (44d32d0f6ed805233d1d81b7f3c445e8) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (44d32d0f6ed805233d1d81b7f3c445e8) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ca68c0803304fdc18226e0a797f2109e) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ca68c0803304fdc18226e0a797f2109e) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7709a0c85e78fd31496b01871b70415c) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7709a0c85e78fd31496b01871b70415c) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (1/4) (07c9cc9507174411f58c5e0bf93ac3fc) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (1/4) (07c9cc9507174411f58c5e0bf93ac3fc) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Keyed Reduce -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (2/4) (3eb91c9683cf9ad530741b6cc2e5ba38) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (2/4) (3eb91c9683cf9ad530741b6cc2e5ba38) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Keyed Reduce -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (3/4) (4625fbd7928e4c584b6a082f1a4202ad) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (3/4) (4625fbd7928e4c584b6a082f1a4202ad) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Keyed Reduce -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (4/4) (55d0cb3460064d11de85f22a7953fdeb) switched from CREATED to SCHEDULED.
2017-04-09 18:32:04 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (4/4) (55d0cb3460064d11de85f22a7953fdeb) switched from SCHEDULED to DEPLOYING.
2017-04-09 18:32:04 INFO  ExecutionGraph:354 - Deploying Keyed Reduce -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-09 18:32:04 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:04	Keyed Reduce -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-09 18:32:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-09 18:32:04 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0ee73f94109d7237d9811988585c0f99) switched from CREATED to DEPLOYING.
2017-04-09 18:32:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@20ae62de for Source: Custom Source -> Map (1/4)
2017-04-09 18:32:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-09 18:32:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (0ee73f94109d7237d9811988585c0f99) [DEPLOYING].
2017-04-09 18:32:04 INFO  Task:873 - Source: Custom Source -> Map (2/4) (447e3a025de914dcfd503bc73782080a) switched from CREATED to DEPLOYING.
2017-04-09 18:32:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4572af25 for Source: Custom Source -> Map (2/4)
2017-04-09 18:32:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (447e3a025de914dcfd503bc73782080a) [DEPLOYING].
2017-04-09 18:32:04 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-09 18:32:04 INFO  Task:873 - Source: Custom Source -> Map (3/4) (33eb4cfaebea952ba170b37ac4b6e430) switched from CREATED to DEPLOYING.
2017-04-09 18:32:04 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@194b40fc for Source: Custom Source -> Map (3/4)
2017-04-09 18:32:04 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (33eb4cfaebea952ba170b37ac4b6e430) [DEPLOYING].
2017-04-09 18:32:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (447e3a025de914dcfd503bc73782080a) [DEPLOYING].
2017-04-09 18:32:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (33eb4cfaebea952ba170b37ac4b6e430) [DEPLOYING].
2017-04-09 18:32:04 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (0ee73f94109d7237d9811988585c0f99) [DEPLOYING].
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-09 18:32:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (482f55cb85236aef437e4dba452eca6d) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (447e3a025de914dcfd503bc73782080a) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1a746aed for Source: Custom Source -> Map (4/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (482f55cb85236aef437e4dba452eca6d) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (482f55cb85236aef437e4dba452eca6d) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (0ee73f94109d7237d9811988585c0f99) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (33eb4cfaebea952ba170b37ac4b6e430) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (482f55cb85236aef437e4dba452eca6d) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (087231d665320e7b8a94a7ce86883f47) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5ce67dbf for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (087231d665320e7b8a94a7ce86883f47) [DEPLOYING].
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (087231d665320e7b8a94a7ce86883f47) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (087231d665320e7b8a94a7ce86883f47) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (44d32d0f6ed805233d1d81b7f3c445e8) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3746c84e for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (44d32d0f6ed805233d1d81b7f3c445e8) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (44d32d0f6ed805233d1d81b7f3c445e8) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (44d32d0f6ed805233d1d81b7f3c445e8) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ca68c0803304fdc18226e0a797f2109e) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@38e99fa4 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ca68c0803304fdc18226e0a797f2109e) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ca68c0803304fdc18226e0a797f2109e) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ca68c0803304fdc18226e0a797f2109e) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 18:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 18:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 18:32:05 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7709a0c85e78fd31496b01871b70415c) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49cafe5d for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7709a0c85e78fd31496b01871b70415c) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7709a0c85e78fd31496b01871b70415c) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7709a0c85e78fd31496b01871b70415c) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task Keyed Reduce -> Sink: Unnamed (1/4)
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (1/4) (07c9cc9507174411f58c5e0bf93ac3fc) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1ee964b4 for Keyed Reduce -> Sink: Unnamed (1/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task Keyed Reduce -> Sink: Unnamed (1/4) (07c9cc9507174411f58c5e0bf93ac3fc) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: Keyed Reduce -> Sink: Unnamed (1/4) (07c9cc9507174411f58c5e0bf93ac3fc) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (1/4) (07c9cc9507174411f58c5e0bf93ac3fc) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task Keyed Reduce -> Sink: Unnamed (2/4)
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (2/4) (3eb91c9683cf9ad530741b6cc2e5ba38) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2c3f4f4a for Keyed Reduce -> Sink: Unnamed (2/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task Keyed Reduce -> Sink: Unnamed (2/4) (3eb91c9683cf9ad530741b6cc2e5ba38) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: Keyed Reduce -> Sink: Unnamed (2/4) (3eb91c9683cf9ad530741b6cc2e5ba38) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (2/4) (3eb91c9683cf9ad530741b6cc2e5ba38) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task Keyed Reduce -> Sink: Unnamed (3/4)
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (3/4) (4625fbd7928e4c584b6a082f1a4202ad) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1220ab84 for Keyed Reduce -> Sink: Unnamed (3/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task Keyed Reduce -> Sink: Unnamed (3/4) (4625fbd7928e4c584b6a082f1a4202ad) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: Keyed Reduce -> Sink: Unnamed (3/4) (4625fbd7928e4c584b6a082f1a4202ad) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (3/4) (4625fbd7928e4c584b6a082f1a4202ad) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  TaskManager:128 - Received task Keyed Reduce -> Sink: Unnamed (4/4)
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (4/4) (55d0cb3460064d11de85f22a7953fdeb) switched from CREATED to DEPLOYING.
2017-04-09 18:32:05 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2736422e for Keyed Reduce -> Sink: Unnamed (4/4)
2017-04-09 18:32:05 INFO  Task:546 - Loading JAR files for task Keyed Reduce -> Sink: Unnamed (4/4) (55d0cb3460064d11de85f22a7953fdeb) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:575 - Registering task at network: Keyed Reduce -> Sink: Unnamed (4/4) (55d0cb3460064d11de85f22a7953fdeb) [DEPLOYING].
2017-04-09 18:32:05 INFO  Task:873 - Keyed Reduce -> Sink: Unnamed (4/4) (55d0cb3460064d11de85f22a7953fdeb) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-09 18:32:05 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (447e3a025de914dcfd503bc73782080a) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (0ee73f94109d7237d9811988585c0f99) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (33eb4cfaebea952ba170b37ac4b6e430) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (2/4) (3eb91c9683cf9ad530741b6cc2e5ba38) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (087231d665320e7b8a94a7ce86883f47) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (482f55cb85236aef437e4dba452eca6d) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (3/4) (4625fbd7928e4c584b6a082f1a4202ad) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (44d32d0f6ed805233d1d81b7f3c445e8) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (ca68c0803304fdc18226e0a797f2109e) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7709a0c85e78fd31496b01871b70415c) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (4/4) (55d0cb3460064d11de85f22a7953fdeb) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Keyed Reduce -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  ExecutionGraph:1025 - Keyed Reduce -> Sink: Unnamed (1/4) (07c9cc9507174411f58c5e0bf93ac3fc) switched from DEPLOYING to RUNNING.
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Keyed Reduce -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@b6125adf}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Keyed Reduce -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  JobSubmissionClientActor:265 - 04/09/2017 18:32:05	Keyed Reduce -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 18:32:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 18:32:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 18:32:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 18:32:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 18:32:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 18:32:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 18:32:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-09 18:32:05 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-09 18:32:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 18:32:05 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-09 18:32:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 18:32:05 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-09 18:32:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-09 18:32:06 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-09 18:32:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 136, so the initial offset will be set to 135
2017-04-09 18:32:06 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 149, so the initial offset will be set to 148
2017-04-09 22:24:59 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-10 21:42:15 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-10 21:42:15 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-10 21:42:15 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-10 21:42:16 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-10 21:42:16 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-10 21:42:16 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-9c01f435-4313-4100-8cfe-2a4dfd272272
2017-04-10 21:42:16 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:64748 - max concurrent requests: 50 - max backlog: 1000
2017-04-10 21:42:16 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 21:42:16 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-10 21:42:16 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-10 21:42:16 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-10 21:42:16 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-10 21:42:16 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-10 21:42:16 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-10 21:42:16 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-10 21:42:16 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1659496150] - leader session null
2017-04-10 21:42:16 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-10 21:42:16 INFO  TaskManager:128 - Limiting managed memory to 266 MB, memory will be allocated lazily.
2017-04-10 21:42:16 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-70add805-bdf0-4515-8aca-19c10fb58a0e for spill files.
2017-04-10 21:42:16 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 21:42:16 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-5c08a323-9fb4-4e4d-b8bb-3077a8c0b113
2017-04-10 21:42:16 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1195779895.
2017-04-10 21:42:16 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='e149e6e81c4d83a25ace6d09ee5380a9'} @ localhost (dataPort=-1)
2017-04-10 21:42:16 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-10 21:42:16 INFO  TaskManager:128 - Memory usage stats: [HEAP: 171/942/942 MB, NON HEAP: 120/123/-1 MB (used/committed/max)]
2017-04-10 21:42:16 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-10 21:42:16 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='e149e6e81c4d83a25ace6d09ee5380a9'} has started.
2017-04-10 21:42:16 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 79ed11be5d9a99cf18177aed31800bad. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-10 21:42:16 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-10 21:42:16 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:64748. Starting BLOB cache.
2017-04-10 21:42:16 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0f382334-f360-42a5-8056-453cf9232e90
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 94480fe2e6f94f6329537a9d65b1bb87)) but there is no connection to a JobManager yet.
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (94480fe2e6f94f6329537a9d65b1bb87).
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1659496150].
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1659496150]
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (94480fe2e6f94f6329537a9d65b1bb87) and wait for progress
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-10 21:42:16 INFO  JobManager:128 - Submitting job 94480fe2e6f94f6329537a9d65b1bb87 (Flink Streaming Job).
2017-04-10 21:42:16 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 94480fe2e6f94f6329537a9d65b1bb87.
2017-04-10 21:42:16 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (94480fe2e6f94f6329537a9d65b1bb87).
2017-04-10 21:42:16 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:111 - Job 94480fe2e6f94f6329537a9d65b1bb87 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-10 21:42:16 INFO  JobManager:128 - Scheduling job 94480fe2e6f94f6329537a9d65b1bb87 (Flink Streaming Job).
2017-04-10 21:42:16 INFO  ExecutionGraph:965 - Job Flink Streaming Job (94480fe2e6f94f6329537a9d65b1bb87) switched from state CREATED to RUNNING.
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:275 - 04/10/2017 21:42:16	Job execution switched to status RUNNING.
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (557611e55e9c397cf278728ccd7fc37e) switched from CREATED to SCHEDULED.
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (557611e55e9c397cf278728ccd7fc37e) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:16 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (174c2865198e4abe7323e8b423093d48) switched from CREATED to SCHEDULED.
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (174c2865198e4abe7323e8b423093d48) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:16 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (386dccfe42b45a5883e281a3755cdebd) switched from CREATED to SCHEDULED.
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (386dccfe42b45a5883e281a3755cdebd) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:16 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (504032e43369fd7465724c30246a6691) switched from CREATED to SCHEDULED.
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (504032e43369fd7465724c30246a6691) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:16 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (feb4793797ee4bfd3ef880158fab45fe) switched from CREATED to SCHEDULED.
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (feb4793797ee4bfd3ef880158fab45fe) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:16 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (attempt #0) to localhost
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(1/4) switched to SCHEDULED 
2017-04-10 21:42:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(1/4) switched to DEPLOYING 
2017-04-10 21:42:16 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d397c340cccdfa1b4eca0043849988fd) switched from CREATED to SCHEDULED.
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d397c340cccdfa1b4eca0043849988fd) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:17 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (attempt #0) to localhost
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (c4389b4b6c1250fa34a800041efd5740) switched from CREATED to SCHEDULED.
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (c4389b4b6c1250fa34a800041efd5740) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:17 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (attempt #0) to localhost
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (2d6567b15879ffc041158d5e67599c3f) switched from CREATED to SCHEDULED.
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (2d6567b15879ffc041158d5e67599c3f) switched from SCHEDULED to DEPLOYING.
2017-04-10 21:42:17 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (attempt #0) to localhost
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:16	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(2/4) switched to SCHEDULED 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(2/4) switched to DEPLOYING 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(3/4) switched to SCHEDULED 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(3/4) switched to DEPLOYING 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(4/4) switched to SCHEDULED 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(4/4) switched to DEPLOYING 
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (1/4) (557611e55e9c397cf278728ccd7fc37e) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (2/4) (174c2865198e4abe7323e8b423093d48) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@641e0f06 for Source: Custom Source -> Map (1/4)
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6b75190c for Source: Custom Source -> Map (2/4)
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (557611e55e9c397cf278728ccd7fc37e) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (174c2865198e4abe7323e8b423093d48) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (557611e55e9c397cf278728ccd7fc37e) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (174c2865198e4abe7323e8b423093d48) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (1/4) (557611e55e9c397cf278728ccd7fc37e) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (2/4) (174c2865198e4abe7323e8b423093d48) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (3/4) (386dccfe42b45a5883e281a3755cdebd) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7dcbcab1 for Source: Custom Source -> Map (3/4)
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (386dccfe42b45a5883e281a3755cdebd) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (386dccfe42b45a5883e281a3755cdebd) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (3/4) (386dccfe42b45a5883e281a3755cdebd) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (4/4) (504032e43369fd7465724c30246a6691) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@407df321 for Source: Custom Source -> Map (4/4)
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (504032e43369fd7465724c30246a6691) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (504032e43369fd7465724c30246a6691) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:873 - Source: Custom Source -> Map (4/4) (504032e43369fd7465724c30246a6691) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4)
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (feb4793797ee4bfd3ef880158fab45fe) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@61433e7f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4)
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (feb4793797ee4bfd3ef880158fab45fe) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (feb4793797ee4bfd3ef880158fab45fe) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (feb4793797ee4bfd3ef880158fab45fe) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4)
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d397c340cccdfa1b4eca0043849988fd) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e2c391 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4)
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d397c340cccdfa1b4eca0043849988fd) [DEPLOYING].
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4)
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d397c340cccdfa1b4eca0043849988fd) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d397c340cccdfa1b4eca0043849988fd) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (c4389b4b6c1250fa34a800041efd5740) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@9901932 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4)
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (c4389b4b6c1250fa34a800041efd5740) [DEPLOYING].
2017-04-10 21:42:17 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4)
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (c4389b4b6c1250fa34a800041efd5740) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (2d6567b15879ffc041158d5e67599c3f) switched from CREATED to DEPLOYING.
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (c4389b4b6c1250fa34a800041efd5740) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@49738709 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4)
2017-04-10 21:42:17 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (2d6567b15879ffc041158d5e67599c3f) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (2d6567b15879ffc041158d5e67599c3f) [DEPLOYING].
2017-04-10 21:42:17 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (2d6567b15879ffc041158d5e67599c3f) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 21:42:17 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 21:42:17 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, 79ed11be5d9a99cf18177aed31800bad, Flink Streaming Job, Sink: Unnamed, 0]
2017-04-10 21:42:17 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, 79ed11be5d9a99cf18177aed31800bad, Flink Streaming Job, Sink: Unnamed, 1]
2017-04-10 21:42:17 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, 79ed11be5d9a99cf18177aed31800bad, Flink Streaming Job, Sink: Unnamed, 2]
2017-04-10 21:42:17 WARN  MetricGroup:378 - Name collision: Group already contains a Metric with the name 'latency'. Metric will not be reported.[localhost, taskmanager, 79ed11be5d9a99cf18177aed31800bad, Flink Streaming Job, Sink: Unnamed, 3]
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (174c2865198e4abe7323e8b423093d48) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 21:42:17 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 21:42:17 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (557611e55e9c397cf278728ccd7fc37e) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (386dccfe42b45a5883e281a3755cdebd) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (504032e43369fd7465724c30246a6691) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (1/4) (feb4793797ee4bfd3ef880158fab45fe) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(1/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (2/4) (d397c340cccdfa1b4eca0043849988fd) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (4/4) (2d6567b15879ffc041158d5e67599c3f) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed) (3/4) (c4389b4b6c1250fa34a800041efd5740) switched from DEPLOYING to RUNNING.
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(2/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(4/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  JobSubmissionClientActor:265 - 04/10/2017 21:42:17	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@a4bfe04d}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map -> Sink: Unnamed)(3/4) switched to RUNNING 
2017-04-10 21:42:17 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 21:42:17 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 21:42:17 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 21:42:17 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 21:42:17 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:17 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 21:42:17 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 21:42:17 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 21:42:17 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 21:42:17 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 21:42:17 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 21:42:17 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 21:42:17 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 21:42:18 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 21:42:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:18 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 21:42:18 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 21:42:18 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 21:42:18 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 21:42:18 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 21:42:18 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 21:42:18 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 21:42:18 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 137, so the initial offset will be set to 136
2017-04-10 21:42:18 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 149, so the initial offset will be set to 148
2017-04-10 22:53:55 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-10 22:53:56 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-10 22:53:56 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-10 22:53:56 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-10 22:53:57 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-10 22:53:57 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-1be781de-38e2-41c2-8e0a-1d6f987122a9
2017-04-10 22:53:57 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65216 - max concurrent requests: 50 - max backlog: 1000
2017-04-10 22:53:57 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 22:53:57 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-10 22:53:57 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-10 22:53:57 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-10 22:53:57 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-10 22:53:57 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 13 GB (11,71% usable)
2017-04-10 22:53:57 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-10 22:53:57 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-10 22:53:57 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1967223963] - leader session null
2017-04-10 22:53:57 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-10 22:53:57 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-10 22:53:57 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-8f6c3455-6a05-4490-961f-faf29a986af9 for spill files.
2017-04-10 22:53:57 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 22:53:57 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-1633f39d-95e7-48e3-ba24-2b16928d7cc0
2017-04-10 22:53:57 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1987454574.
2017-04-10 22:53:57 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='fde5edfe9d3bc2b787a0e6fda28c3f35'} @ localhost (dataPort=-1)
2017-04-10 22:53:57 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-10 22:53:57 INFO  TaskManager:128 - Memory usage stats: [HEAP: 175/898/910 MB, NON HEAP: 125/129/-1 MB (used/committed/max)]
2017-04-10 22:53:57 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-10 22:53:57 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='fde5edfe9d3bc2b787a0e6fda28c3f35'} has started.
2017-04-10 22:53:57 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as f1707e2728d065f9c9f259d32a4777fa. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-10 22:53:57 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-10 22:53:57 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65216. Starting BLOB cache.
2017-04-10 22:53:57 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-a5230cb4-275f-486b-8c48-ab37e9c3e233
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 54dfa2ffb4c271aac3a50b314aa639a5)) but there is no connection to a JobManager yet.
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5).
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1967223963].
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1967223963]
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5) and wait for progress
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-10 22:53:57 INFO  JobManager:128 - Submitting job 54dfa2ffb4c271aac3a50b314aa639a5 (Flink Streaming Job).
2017-04-10 22:53:57 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 54dfa2ffb4c271aac3a50b314aa639a5.
2017-04-10 22:53:57 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5).
2017-04-10 22:53:57 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:111 - Job 54dfa2ffb4c271aac3a50b314aa639a5 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-10 22:53:57 INFO  JobManager:128 - Scheduling job 54dfa2ffb4c271aac3a50b314aa639a5 (Flink Streaming Job).
2017-04-10 22:53:57 INFO  ExecutionGraph:965 - Job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5) switched from state CREATED to RUNNING.
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:275 - 04/10/2017 22:53:57	Job execution switched to status RUNNING.
2017-04-10 22:53:57 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from CREATED to SCHEDULED.
2017-04-10 22:53:57 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:57	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from CREATED to SCHEDULED.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from SCHEDULED to DEPLOYING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-10 22:53:58 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1d4cbda9 for Source: Custom Source -> Map (2/4)
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@35c24207 for Source: Custom Source -> Map (1/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@38513975 for Source: Custom Source -> Map (3/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) [DEPLOYING].
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@74038185 for Source: Custom Source -> Map (4/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 22:53:58 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 22:53:58 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 22:53:58 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@65750cf0 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@702ea962 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5099f952 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7fef3f22 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@384b3944 for Flat Map -> Sink: Unnamed (1/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@307922d3 for Flat Map -> Sink: Unnamed (2/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@76f10397 for Flat Map -> Sink: Unnamed (3/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from CREATED to DEPLOYING.
2017-04-10 22:53:58 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@53b2e0e7 for Flat Map -> Sink: Unnamed (4/4)
2017-04-10 22:53:58 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) [DEPLOYING].
2017-04-10 22:53:58 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 22:53:58 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from DEPLOYING to RUNNING.
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  JobSubmissionClientActor:265 - 04/10/2017 22:53:58	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:58 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:59 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 22:53:59 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 22:53:59 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 22:53:59 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 22:53:59 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 22:53:59 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 22:53:59 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 22:53:59 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 22:53:59 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 22:53:59 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:59 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:59 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:59 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 22:53:59 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 22:53:59 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 22:53:59 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 22:53:59 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 22:53:59 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 22:53:59 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 22:53:59 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 150, so the initial offset will be set to 149
2017-04-10 22:53:59 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 137, so the initial offset will be set to 136
2017-04-10 23:01:02 INFO  Task:875 - Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) switched from RUNNING to FAILED.
scala.MatchError: Some(1491857674182.f44e028c-4277-4703-b580-cc92aecbe7e6) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:59)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:01:07 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11).
2017-04-10 23:01:14 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:01:15 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (0fea89fdc84344d584b7300b6f706f11)
2017-04-10 23:01:16 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (2/4) (0fea89fdc84344d584b7300b6f706f11) switched from RUNNING to FAILED.
scala.MatchError: Some(1491857674182.f44e028c-4277-4703-b580-cc92aecbe7e6) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:59)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:01:16 INFO  ExecutionGraph:965 - Job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5) switched from state RUNNING to FAILING.
scala.MatchError: Some(1491857674182.f44e028c-4277-4703-b580-cc92aecbe7e6) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:59)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:01:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:16	Flat Map -> Sink: Unnamed(2/4) switched to FAILED 
scala.MatchError: Some(1491857674182.f44e028c-4277-4703-b580-cc92aecbe7e6) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:59)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-10 23:01:16 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from RUNNING to CANCELING.
2017-04-10 23:01:16 INFO  JobSubmissionClientActor:280 - 04/10/2017 23:01:16	Job execution switched to status FAILING.
scala.MatchError: Some(1491857674182.f44e028c-4277-4703-b580-cc92aecbe7e6) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:59)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:01:16 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:16	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-10 23:01:17 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a).
2017-04-10 23:01:17 INFO  Task:873 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a).
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  Task:873 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7).
2017-04-10 23:01:18 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a).
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7).
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b).
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Flat Map -> Sink: Unnamed(4/4) switched to CANCELING 
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b).
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-10 23:01:18 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7).
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-10 23:01:18 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b).
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22).
2017-04-10 23:01:18 INFO  Task:873 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22).
2017-04-10 23:01:18 INFO  Task:873 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22).
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c).
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c).
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e).
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c).
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e).
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61).
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e).
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61).
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61).
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792).
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792).
2017-04-10 23:01:18 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792).
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502).
2017-04-10 23:01:18 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502).
2017-04-10 23:01:18 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502).
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:01:18 INFO  TaskManager:128 - Discarding the results produced by task execution 0fea89fdc84344d584b7300b6f706f11
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8).
2017-04-10 23:01:18 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8).
2017-04-10 23:01:18 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8).
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:01:18 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2).
2017-04-10 23:01:18 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from RUNNING to CANCELING.
2017-04-10 23:01:18 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2).
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (c85c643a56a01f91c2c9da1df52ef1a7)
2017-04-10 23:01:18 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2).
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (50103aa5590eafe9a711920987d06d3a)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (6ba73271fa81f381604b5ef4c90f4a6b)
2017-04-10 23:01:18 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (56df37f9c656909e1ef7173a68d9bd22)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (caea232441fc789eb31cb7dd013eaa5c)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (00670e66ef9d908d87d2b88fa93b781e)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (463a60dceef0b74aed1a684c57e24c61)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (c4853ec405a7ac0ae9c211ca146e9792)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (b53a1637a9a1b948d403923baa751502)
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (c3b24026f6a92d93321645de6c246fa8)
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c85c643a56a01f91c2c9da1df52ef1a7) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (50103aa5590eafe9a711920987d06d3a) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6ba73271fa81f381604b5ef4c90f4a6b) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (934372900bc7f5045dbab2d0a318b7b2)
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (56df37f9c656909e1ef7173a68d9bd22) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (caea232441fc789eb31cb7dd013eaa5c) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (00670e66ef9d908d87d2b88fa93b781e) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (463a60dceef0b74aed1a684c57e24c61) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (b53a1637a9a1b948d403923baa751502) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c4853ec405a7ac0ae9c211ca146e9792) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c3b24026f6a92d93321645de6c246fa8) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@aae482a8}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (934372900bc7f5045dbab2d0a318b7b2) switched from CANCELING to CANCELED.
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5) if no longer possible.
2017-04-10 23:01:18 INFO  ExecutionGraph:965 - Job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5) switched from state FAILING to FAILED.
scala.MatchError: Some(1491857674182.f44e028c-4277-4703-b580-cc92aecbe7e6) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:59)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:18	Flat Map -> Sink: Unnamed(4/4) switched to CANCELED 
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:275 - 04/10/2017 23:01:18	Job execution switched to status FAILED.
2017-04-10 23:01:18 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (54dfa2ffb4c271aac3a50b314aa639a5) because the restart strategy prevented it.
scala.MatchError: Some(1491857674182.f44e028c-4277-4703-b580-cc92aecbe7e6) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:59)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:01:18 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job 54dfa2ffb4c271aac3a50b314aa639a5
2017-04-10 23:01:18 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-10 23:01:18 INFO  JobClient:320 - Job execution failed
2017-04-10 23:01:18 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#-1967223963].
2017-04-10 23:01:18 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-10 23:01:18 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#-1987454574.
2017-04-10 23:01:18 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-10 23:01:18 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-10 23:01:18 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-10 23:01:18 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:65216
2017-04-10 23:01:18 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-8f6c3455-6a05-4490-961f-faf29a986af9
2017-04-10 23:01:18 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-10 23:01:18 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-10 23:01:44 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-10 23:01:45 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-10 23:01:45 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-10 23:01:45 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-10 23:01:46 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-10 23:01:46 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-463881f5-6ed9-4c7c-938d-31e21e655185
2017-04-10 23:01:46 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65257 - max concurrent requests: 50 - max backlog: 1000
2017-04-10 23:01:46 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 23:01:46 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-10 23:01:46 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-10 23:01:46 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-10 23:01:46 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-10 23:01:46 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-10 23:01:46 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-10 23:01:46 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#891744547] - leader session null
2017-04-10 23:01:46 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-10 23:01:46 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-10 23:01:46 INFO  TaskManager:128 - Limiting managed memory to 256 MB, memory will be allocated lazily.
2017-04-10 23:01:46 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-35d79f05-b1a0-440a-b9a0-b6a73e7e1607 for spill files.
2017-04-10 23:01:46 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 23:01:46 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-4ebe0de3-d3ce-4737-b7bb-5f5ccbca9c22
2017-04-10 23:01:46 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#2123275416.
2017-04-10 23:01:46 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='9461125414f149e594e80f72410a0fb5'} @ localhost (dataPort=-1)
2017-04-10 23:01:46 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-10 23:01:46 INFO  TaskManager:128 - Memory usage stats: [HEAP: 169/572/910 MB, NON HEAP: 79/82/-1 MB (used/committed/max)]
2017-04-10 23:01:46 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-10 23:01:46 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='9461125414f149e594e80f72410a0fb5'} has started.
2017-04-10 23:01:46 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 047bee477cf0644837b127b3736c1a3e. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-10 23:01:46 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-10 23:01:46 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65257. Starting BLOB cache.
2017-04-10 23:01:46 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-bfbb4ec6-64e8-46e3-ae98-9e96e0f3c6f3
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 18fc02ceddc50fa90ea6a88486a9d2a9)) but there is no connection to a JobManager yet.
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (18fc02ceddc50fa90ea6a88486a9d2a9).
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#891744547].
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#891744547]
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (18fc02ceddc50fa90ea6a88486a9d2a9) and wait for progress
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-10 23:01:46 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-10 23:01:47 INFO  JobManager:128 - Submitting job 18fc02ceddc50fa90ea6a88486a9d2a9 (Flink Streaming Job).
2017-04-10 23:01:47 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 18fc02ceddc50fa90ea6a88486a9d2a9.
2017-04-10 23:01:47 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (18fc02ceddc50fa90ea6a88486a9d2a9).
2017-04-10 23:01:47 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:111 - Job 18fc02ceddc50fa90ea6a88486a9d2a9 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-10 23:01:47 INFO  JobManager:128 - Scheduling job 18fc02ceddc50fa90ea6a88486a9d2a9 (Flink Streaming Job).
2017-04-10 23:01:47 INFO  ExecutionGraph:965 - Job Flink Streaming Job (18fc02ceddc50fa90ea6a88486a9d2a9) switched from state CREATED to RUNNING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:275 - 04/10/2017 23:01:47	Job execution switched to status RUNNING.
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (9c9a2a6083ebb9c49d87419e7e204aeb) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (9c9a2a6083ebb9c49d87419e7e204aeb) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (dca9cf561e80bfd0b038d1bc8e48e512) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (dca9cf561e80bfd0b038d1bc8e48e512) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6939101e19203d2f01126179ed370392) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6939101e19203d2f01126179ed370392) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5548cbe325b502c50ca3238ee52f520e) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5548cbe325b502c50ca3238ee52f520e) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (591a60832a658c1eaf614a8bcf19e16e) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (591a60832a658c1eaf614a8bcf19e16e) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (a4f54d125db92fe74112af5541a80c5c) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (a4f54d125db92fe74112af5541a80c5c) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (c90ea4548302e073ad33c7a234a26bc8) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (c90ea4548302e073ad33c7a234a26bc8) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (66fc4f4754337c37abd6ec7dcf50db65) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (66fc4f4754337c37abd6ec7dcf50db65) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (7f189ecbcc5279b06ec657c4254fc726) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (7f189ecbcc5279b06ec657c4254fc726) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (c45e1f96e875ae4e73b5f0c8c52e8e29) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (c45e1f96e875ae4e73b5f0c8c52e8e29) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (1ea4d3e46387f4610c006f4378cd6eec) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (1ea4d3e46387f4610c006f4378cd6eec) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (e1a6b228b1355ef5db7007b5985c32d1) switched from CREATED to SCHEDULED.
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-10 23:01:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (e1a6b228b1355ef5db7007b5985c32d1) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:01:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-10 23:01:47 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:47	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (1/4) (9c9a2a6083ebb9c49d87419e7e204aeb) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (2/4) (dca9cf561e80bfd0b038d1bc8e48e512) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6939101e19203d2f01126179ed370392) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@779f2536 for Source: Custom Source -> Map (3/4)
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3d3f0380 for Source: Custom Source -> Map (1/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (6939101e19203d2f01126179ed370392) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (9c9a2a6083ebb9c49d87419e7e204aeb) [DEPLOYING].
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7992fa7c for Source: Custom Source -> Map (2/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (dca9cf561e80bfd0b038d1bc8e48e512) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (dca9cf561e80bfd0b038d1bc8e48e512) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (9c9a2a6083ebb9c49d87419e7e204aeb) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (6939101e19203d2f01126179ed370392) [DEPLOYING].
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5548cbe325b502c50ca3238ee52f520e) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (3/4) (6939101e19203d2f01126179ed370392) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@553b85b4 for Source: Custom Source -> Map (4/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (5548cbe325b502c50ca3238ee52f520e) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (2/4) (dca9cf561e80bfd0b038d1bc8e48e512) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (1/4) (9c9a2a6083ebb9c49d87419e7e204aeb) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (5548cbe325b502c50ca3238ee52f520e) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:873 - Source: Custom Source -> Map (4/4) (5548cbe325b502c50ca3238ee52f520e) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:01:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:01:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:01:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (591a60832a658c1eaf614a8bcf19e16e) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5333f39f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (591a60832a658c1eaf614a8bcf19e16e) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (591a60832a658c1eaf614a8bcf19e16e) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (591a60832a658c1eaf614a8bcf19e16e) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (a4f54d125db92fe74112af5541a80c5c) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@35cf7daf for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (a4f54d125db92fe74112af5541a80c5c) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (a4f54d125db92fe74112af5541a80c5c) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (a4f54d125db92fe74112af5541a80c5c) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (c90ea4548302e073ad33c7a234a26bc8) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (7f189ecbcc5279b06ec657c4254fc726) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (66fc4f4754337c37abd6ec7dcf50db65) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (c45e1f96e875ae4e73b5f0c8c52e8e29) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4933942f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (c90ea4548302e073ad33c7a234a26bc8) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (1ea4d3e46387f4610c006f4378cd6eec) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@55fcbc76 for Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (1ea4d3e46387f4610c006f4378cd6eec) [DEPLOYING].
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@450837b1 for Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (c45e1f96e875ae4e73b5f0c8c52e8e29) [DEPLOYING].
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@ccf95fb for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (66fc4f4754337c37abd6ec7dcf50db65) [DEPLOYING].
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@11b8a021 for Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (7f189ecbcc5279b06ec657c4254fc726) [DEPLOYING].
2017-04-10 23:01:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (e1a6b228b1355ef5db7007b5985c32d1) switched from CREATED to DEPLOYING.
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (7f189ecbcc5279b06ec657c4254fc726) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (66fc4f4754337c37abd6ec7dcf50db65) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (c45e1f96e875ae4e73b5f0c8c52e8e29) [DEPLOYING].
2017-04-10 23:01:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3265a8a4 for Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:01:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (e1a6b228b1355ef5db7007b5985c32d1) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (c90ea4548302e073ad33c7a234a26bc8) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (1ea4d3e46387f4610c006f4378cd6eec) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (c90ea4548302e073ad33c7a234a26bc8) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (66fc4f4754337c37abd6ec7dcf50db65) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (c45e1f96e875ae4e73b5f0c8c52e8e29) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (1ea4d3e46387f4610c006f4378cd6eec) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (e1a6b228b1355ef5db7007b5985c32d1) [DEPLOYING].
2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (7f189ecbcc5279b06ec657c4254fc726) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (e1a6b228b1355ef5db7007b5985c32d1) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:01:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (dca9cf561e80bfd0b038d1bc8e48e512) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (6939101e19203d2f01126179ed370392) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (5548cbe325b502c50ca3238ee52f520e) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (9c9a2a6083ebb9c49d87419e7e204aeb) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (591a60832a658c1eaf614a8bcf19e16e) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (a4f54d125db92fe74112af5541a80c5c) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (c90ea4548302e073ad33c7a234a26bc8) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (66fc4f4754337c37abd6ec7dcf50db65) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@7b5a0b8e}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (c45e1f96e875ae4e73b5f0c8c52e8e29) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (1ea4d3e46387f4610c006f4378cd6eec) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (7f189ecbcc5279b06ec657c4254fc726) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (e1a6b228b1355ef5db7007b5985c32d1) switched from DEPLOYING to RUNNING.
2017-04-10 23:01:48 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:01:48	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:01:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:01:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:01:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:01:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:01:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:01:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:01:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:01:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:01:49 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:01:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:49 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:01:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:01:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:01:49 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:01:49 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:01:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 23:01:49 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 23:01:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 150, so the initial offset will be set to 149
2017-04-10 23:01:49 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 138, so the initial offset will be set to 137
2017-04-10 23:39:20 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-10 23:39:21 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-10 23:39:22 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-10 23:39:22 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-10 23:39:22 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-10 23:39:22 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-8a70e0a8-7689-4a9a-ae56-468215af3d95
2017-04-10 23:39:22 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:65519 - max concurrent requests: 50 - max backlog: 1000
2017-04-10 23:39:22 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 23:39:22 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-10 23:39:22 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-10 23:39:22 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-10 23:39:22 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-10 23:39:22 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-10 23:39:22 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-10 23:39:22 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-10 23:39:22 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1076231874] - leader session null
2017-04-10 23:39:23 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-10 23:39:23 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-10 23:39:23 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-d40f65b7-ad14-4e6f-a322-8bc64a68056e for spill files.
2017-04-10 23:39:23 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 23:39:23 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-d8200e19-0353-4632-a717-da58750a2936
2017-04-10 23:39:23 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1278292674.
2017-04-10 23:39:23 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='36b96e2e2adb59034d781724f912afbc'} @ localhost (dataPort=-1)
2017-04-10 23:39:23 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-10 23:39:23 INFO  TaskManager:128 - Memory usage stats: [HEAP: 175/867/910 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-10 23:39:23 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-10 23:39:23 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='36b96e2e2adb59034d781724f912afbc'} has started.
2017-04-10 23:39:23 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as d92e1248efd72dd5284f19ae4db5cde5. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-10 23:39:23 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-10 23:39:23 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:65519. Starting BLOB cache.
2017-04-10 23:39:23 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-09f36cbd-8332-4d5a-8633-bb793cf14b1f
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: a826b6823bc7019132276f3837819641)) but there is no connection to a JobManager yet.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (a826b6823bc7019132276f3837819641).
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1076231874].
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1076231874]
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (a826b6823bc7019132276f3837819641) and wait for progress
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-10 23:39:23 INFO  JobManager:128 - Submitting job a826b6823bc7019132276f3837819641 (Flink Streaming Job).
2017-04-10 23:39:23 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for a826b6823bc7019132276f3837819641.
2017-04-10 23:39:23 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (a826b6823bc7019132276f3837819641).
2017-04-10 23:39:23 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:111 - Job a826b6823bc7019132276f3837819641 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-10 23:39:23 INFO  JobManager:128 - Scheduling job a826b6823bc7019132276f3837819641 (Flink Streaming Job).
2017-04-10 23:39:23 INFO  ExecutionGraph:965 - Job Flink Streaming Job (a826b6823bc7019132276f3837819641) switched from state CREATED to RUNNING.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:275 - 04/10/2017 23:39:23	Job execution switched to status RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from CREATED to SCHEDULED.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:39:23 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1a5630fa for Source: Custom Source -> Map (1/4)
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4b1bdcf for Source: Custom Source -> Map (3/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) [DEPLOYING].
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7834d4c3 for Source: Custom Source -> Map (2/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) [DEPLOYING].
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6d17de60 for Source: Custom Source -> Map (4/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) [DEPLOYING].
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@760011ed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) [DEPLOYING].
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6087ee3a for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@418ed92b for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1ad0b83 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6bd93d4c for Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) [DEPLOYING].
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@560fec97 for Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) [DEPLOYING].
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@26582492 for Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) [DEPLOYING].
2017-04-10 23:39:23 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from CREATED to DEPLOYING.
2017-04-10 23:39:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@53175431 for Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:39:23 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) [DEPLOYING].
2017-04-10 23:39:23 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) [DEPLOYING].
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:39:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from DEPLOYING to RUNNING.
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:39:23	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-10 23:39:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:39:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:39:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:39:23 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:39:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:39:24 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:39:24 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:39:24 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:39:24 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:39:24 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:39:24 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:39:24 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:39:24 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:39:24 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:39:24 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:39:24 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:39:24 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:39:24 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 23:39:24 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 23:39:24 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 138, so the initial offset will be set to 137
2017-04-10 23:39:24 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 151, so the initial offset will be set to 150
2017-04-10 23:40:46 INFO  Task:875 - Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) switched from RUNNING to FAILED.
scala.MatchError: Some(1) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (98c00abd4108635bd0f66ca81eff55e6)
2017-04-10 23:40:46 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (2/4) (98c00abd4108635bd0f66ca81eff55e6) switched from RUNNING to FAILED.
scala.MatchError: Some(1) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:40:46 INFO  ExecutionGraph:965 - Job Flink Streaming Job (a826b6823bc7019132276f3837819641) switched from state RUNNING to FAILING.
scala.MatchError: Some(1) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Flat Map -> Sink: Unnamed(2/4) switched to FAILED 
scala.MatchError: Some(1) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-10 23:40:46 INFO  JobSubmissionClientActor:280 - 04/10/2017 23:40:46	Job execution switched to status FAILING.
scala.MatchError: Some(1) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0).
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0).
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (7c17d1dfed5c19f19ecf83b3d3e77ee0)
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f).
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f).
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20).
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f).
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Flat Map -> Sink: Unnamed(4/4) switched to CANCELING 
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20).
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647).
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647).
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20).
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:873 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b).
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (7c17d1dfed5c19f19ecf83b3d3e77ee0) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17).
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17).
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b).
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba).
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17).
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7).
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7).
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242).
2017-04-10 23:40:46 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242).
2017-04-10 23:40:46 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:40:46 INFO  TaskManager:128 - Discarding the results produced by task execution 98c00abd4108635bd0f66ca81eff55e6
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58).
2017-04-10 23:40:46 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58).
2017-04-10 23:40:46 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81).
2017-04-10 23:40:46 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from RUNNING to CANCELING.
2017-04-10 23:40:46 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58).
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:40:46 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81).
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (08a27675d97476ba114eb17e3a8e8c6f)
2017-04-10 23:40:46 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81).
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (550743f214dee12338ec7ee4bb46cb20)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (9d89586d8c8696416ed94f1429bb2647)
2017-04-10 23:40:46 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (39bb3eba77c1d3cfad98230a9b00347b)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (dcf450d60ecbc8ab86fd001d30fcdc17)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (8a1fea7b0f5c15562c21a671979307ba)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (7e506b92ff7ddc7851ca9786057a6ac7)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (77094593644346eb8654ddcf96520242)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (82b20c982c02e44f45f08ec153c76e58)
2017-04-10 23:40:46 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (322977ca325b426b60917d7bed179b81)
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (08a27675d97476ba114eb17e3a8e8c6f) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (550743f214dee12338ec7ee4bb46cb20) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (dcf450d60ecbc8ab86fd001d30fcdc17) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (82b20c982c02e44f45f08ec153c76e58) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (39bb3eba77c1d3cfad98230a9b00347b) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a1fea7b0f5c15562c21a671979307ba) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (7e506b92ff7ddc7851ca9786057a6ac7) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$13$$anon$4@5c1d5989}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (9d89586d8c8696416ed94f1429bb2647) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (322977ca325b426b60917d7bed179b81) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (77094593644346eb8654ddcf96520242) switched from CANCELING to CANCELED.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Flat Map -> Sink: Unnamed(4/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:40:46	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-10 23:40:46 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (a826b6823bc7019132276f3837819641) if no longer possible.
2017-04-10 23:40:46 INFO  ExecutionGraph:965 - Job Flink Streaming Job (a826b6823bc7019132276f3837819641) switched from state FAILING to FAILED.
scala.MatchError: Some(1) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:275 - 04/10/2017 23:40:46	Job execution switched to status FAILED.
2017-04-10 23:40:46 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (a826b6823bc7019132276f3837819641) because the restart strategy prevented it.
scala.MatchError: Some(1) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:40:46 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job a826b6823bc7019132276f3837819641
2017-04-10 23:40:46 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-10 23:40:46 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#1076231874].
2017-04-10 23:40:46 INFO  JobClient:320 - Job execution failed
2017-04-10 23:40:46 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-10 23:40:47 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#1278292674.
2017-04-10 23:40:47 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-10 23:40:47 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-10 23:40:47 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-10 23:40:47 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:65519
2017-04-10 23:40:47 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-d40f65b7-ad14-4e6f-a322-8bc64a68056e
2017-04-10 23:40:47 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-10 23:40:47 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-10 23:52:07 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-10 23:52:08 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-10 23:52:08 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-10 23:52:08 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-10 23:52:09 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-10 23:52:09 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-ecae4467-e4d0-422b-91be-8f01f2fd4891
2017-04-10 23:52:09 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:49256 - max concurrent requests: 50 - max backlog: 1000
2017-04-10 23:52:09 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 23:52:09 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-10 23:52:09 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-10 23:52:09 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-10 23:52:09 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-10 23:52:09 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-10 23:52:09 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-10 23:52:09 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-10 23:52:09 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1029980978] - leader session null
2017-04-10 23:52:09 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-10 23:52:09 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-10 23:52:09 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-fe84eba0-5ed3-4bfc-a2d5-f9717379e194 for spill files.
2017-04-10 23:52:09 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-10 23:52:09 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-b0fc9568-2779-4404-b3ef-6aece867da0c
2017-04-10 23:52:09 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1097065230.
2017-04-10 23:52:09 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='3b8ead1ad1530ffc1812fa5efc7ac9eb'} @ localhost (dataPort=-1)
2017-04-10 23:52:09 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-10 23:52:09 INFO  TaskManager:128 - Memory usage stats: [HEAP: 174/877/910 MB, NON HEAP: 125/128/-1 MB (used/committed/max)]
2017-04-10 23:52:09 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-10 23:52:09 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='3b8ead1ad1530ffc1812fa5efc7ac9eb'} has started.
2017-04-10 23:52:09 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 95ac7a63e167695dcd6e9376033aa252. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-10 23:52:09 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-10 23:52:09 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:49256. Starting BLOB cache.
2017-04-10 23:52:09 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-7b958188-d3f3-422d-9a63-6cb4379f6899
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 7b5c0100fd3aa42fec9d1048531a7610)) but there is no connection to a JobManager yet.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610).
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1029980978].
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1029980978]
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610) and wait for progress
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-10 23:52:09 INFO  JobManager:128 - Submitting job 7b5c0100fd3aa42fec9d1048531a7610 (Flink Streaming Job).
2017-04-10 23:52:09 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 7b5c0100fd3aa42fec9d1048531a7610.
2017-04-10 23:52:09 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610).
2017-04-10 23:52:09 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:111 - Job 7b5c0100fd3aa42fec9d1048531a7610 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-10 23:52:09 INFO  JobManager:128 - Scheduling job 7b5c0100fd3aa42fec9d1048531a7610 (Flink Streaming Job).
2017-04-10 23:52:09 INFO  ExecutionGraph:965 - Job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610) switched from state CREATED to RUNNING.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:275 - 04/10/2017 23:52:09	Job execution switched to status RUNNING.
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from CREATED to SCHEDULED.
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-10 23:52:09 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from SCHEDULED to DEPLOYING.
2017-04-10 23:52:09 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-10 23:52:09 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:09	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7fafb09e for Source: Custom Source -> Map (1/4)
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@198772ba for Source: Custom Source -> Map (3/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) [DEPLOYING].
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@8e3981 for Source: Custom Source -> Map (2/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) [DEPLOYING].
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@cae5d95 for Source: Custom Source -> Map (4/4)
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:52:10 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:52:10 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:52:10 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@416472a3 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@68007b8f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@645cfa84 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@36d84750 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@48b75391 for Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7e2dcaa4 for Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@23d5a5ab for Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from CREATED to DEPLOYING.
2017-04-10 23:52:10 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@549daa25 for Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:52:10 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) [DEPLOYING].
2017-04-10 23:52:10 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-10 23:52:10 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from DEPLOYING to RUNNING.
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:52:10	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:52:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:52:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:52:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:52:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:52:10 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:52:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:52:10 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-10 23:52:11 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-10 23:52:11 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:11 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:11 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:11 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:52:11 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:52:11 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-10 23:52:11 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-10 23:52:11 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-10 23:52:11 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 23:52:11 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-10 23:52:11 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 138, so the initial offset will be set to 137
2017-04-10 23:52:11 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 152, so the initial offset will be set to 151
2017-04-10 23:54:23 INFO  Task:875 - Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) switched from RUNNING to FAILED.
scala.MatchError: Some((2017-04-10,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4).
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (e15ce541079b76c1af86c355d0b4fbd4)
2017-04-10 23:54:23 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (2/4) (e15ce541079b76c1af86c355d0b4fbd4) switched from RUNNING to FAILED.
scala.MatchError: Some((2017-04-10,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:54:23 INFO  ExecutionGraph:965 - Job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610) switched from state RUNNING to FAILING.
scala.MatchError: Some((2017-04-10,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Flat Map -> Sink: Unnamed(2/4) switched to FAILED 
scala.MatchError: Some((2017-04-10,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-10 23:54:23 INFO  JobSubmissionClientActor:280 - 04/10/2017 23:54:23	Job execution switched to status FAILING.
scala.MatchError: Some((2017-04-10,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e).
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e).
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471).
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471).
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e).
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750).
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750).
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471).
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04).
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04).
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750).
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b).
2017-04-10 23:54:23 INFO  Task:873 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04).
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Flat Map -> Sink: Unnamed(4/4) switched to CANCELING 
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b).
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6).
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b).
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6).
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (5a3a14b10a50a1518738203968dcf88e)
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6).
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da).
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da).
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f).
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da).
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f).
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d).
2017-04-10 23:54:23 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f).
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-10 23:54:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d).
2017-04-10 23:54:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d).
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-10 23:54:23 INFO  TaskManager:128 - Discarding the results produced by task execution e15ce541079b76c1af86c355d0b4fbd4
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de).
2017-04-10 23:54:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de).
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (c40d063fd74f541489c3eb95a3821471)
2017-04-10 23:54:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de).
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-10 23:54:23 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38).
2017-04-10 23:54:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from RUNNING to CANCELING.
2017-04-10 23:54:23 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38).
2017-04-10 23:54:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38).
2017-04-10 23:54:23 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (d7a11e661224506cc22f4d823cde9750)
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (954cc66aabe52a053fc44b06559ccc04)
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (0676cc0c5ed271f1a8f2a4c0946ed36b)
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1ecafbfa428c7f2397ec35642f89e0e6)
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5a3a14b10a50a1518738203968dcf88e) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (44778c5929e8c6f3d1fea032ee9c86da)
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (e9bd574187e9c59dd6044f8af392132f)
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (e5889037c6c9972c37828b4273f2603d)
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (c40d063fd74f541489c3eb95a3821471) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (94acdb09e0a2fb9ca48ba1a5fb08f5de)
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (feaa47d6f8d65de4556c2f97f3025b38)
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (d7a11e661224506cc22f4d823cde9750) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (954cc66aabe52a053fc44b06559ccc04) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1ecafbfa428c7f2397ec35642f89e0e6) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (44778c5929e8c6f3d1fea032ee9c86da) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (0676cc0c5ed271f1a8f2a4c0946ed36b) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (e5889037c6c9972c37828b4273f2603d) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (e9bd574187e9c59dd6044f8af392132f) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (94acdb09e0a2fb9ca48ba1a5fb08f5de) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (feaa47d6f8d65de4556c2f97f3025b38) switched from CANCELING to CANCELED.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610) if no longer possible.
2017-04-10 23:54:23 INFO  ExecutionGraph:965 - Job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610) switched from state FAILING to FAILED.
scala.MatchError: Some((2017-04-10,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@8876a523}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:265 - 04/10/2017 23:54:23	Flat Map -> Sink: Unnamed(4/4) switched to CANCELED 
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:275 - 04/10/2017 23:54:23	Job execution switched to status FAILED.
2017-04-10 23:54:23 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (7b5c0100fd3aa42fec9d1048531a7610) because the restart strategy prevented it.
scala.MatchError: Some((2017-04-10,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-10 23:54:23 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job 7b5c0100fd3aa42fec9d1048531a7610
2017-04-10 23:54:23 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-10 23:54:23 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#1029980978].
2017-04-10 23:54:23 INFO  JobClient:320 - Job execution failed
2017-04-10 23:54:23 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-10 23:54:23 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#-1097065230.
2017-04-10 23:54:23 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-10 23:54:23 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-10 23:54:23 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-10 23:54:23 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:49256
2017-04-10 23:54:23 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-fe84eba0-5ed3-4bfc-a2d5-f9717379e194
2017-04-10 23:54:23 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-10 23:54:23 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-11 20:24:45 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-11 20:24:45 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-11 20:24:45 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-11 20:24:46 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-11 20:24:46 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-11 20:24:46 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-0c4575fd-cd2d-4b89-be62-d6bd2974638b
2017-04-11 20:24:46 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:51664 - max concurrent requests: 50 - max backlog: 1000
2017-04-11 20:24:46 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 20:24:46 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-11 20:24:46 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-11 20:24:46 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-11 20:24:46 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-11 20:24:46 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 15 GB (13,51% usable)
2017-04-11 20:24:46 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-11 20:24:46 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-11 20:24:46 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1783952701] - leader session null
2017-04-11 20:24:46 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-11 20:24:46 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-11 20:24:46 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-500714ee-2ea6-4029-8245-8ebdef24455b for spill files.
2017-04-11 20:24:46 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 20:24:46 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-50119fa3-6be8-433b-8a10-9218ad01f400
2017-04-11 20:24:46 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-1817780156.
2017-04-11 20:24:46 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='712595d6a98855a8f1412b482bc62cee'} @ localhost (dataPort=-1)
2017-04-11 20:24:46 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-11 20:24:46 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/839/910 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-11 20:24:46 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-11 20:24:46 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='712595d6a98855a8f1412b482bc62cee'} has started.
2017-04-11 20:24:46 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as ca8d38947bfc5ee93a21651f818ed2cd. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-11 20:24:46 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-11 20:24:46 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:51664. Starting BLOB cache.
2017-04-11 20:24:46 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-27a82ffb-f877-43ad-847e-1aa65802c4fd
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: d303458dd73ec83ab7797f51f9450db2)) but there is no connection to a JobManager yet.
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2).
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1783952701].
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1783952701]
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2) and wait for progress
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-11 20:24:46 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-11 20:24:47 INFO  JobManager:128 - Submitting job d303458dd73ec83ab7797f51f9450db2 (Flink Streaming Job).
2017-04-11 20:24:47 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for d303458dd73ec83ab7797f51f9450db2.
2017-04-11 20:24:47 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2).
2017-04-11 20:24:47 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:111 - Job d303458dd73ec83ab7797f51f9450db2 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-11 20:24:47 INFO  JobManager:128 - Scheduling job d303458dd73ec83ab7797f51f9450db2 (Flink Streaming Job).
2017-04-11 20:24:47 INFO  ExecutionGraph:965 - Job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2) switched from state CREATED to RUNNING.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:275 - 04/11/2017 20:24:47	Job execution switched to status RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) switched from CREATED to SCHEDULED.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) switched from SCHEDULED to DEPLOYING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-11 20:24:47 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4289c5cc for Source: Custom Source -> Map (1/4)
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d7f4423 for Source: Custom Source -> Map (3/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) [DEPLOYING].
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e417713 for Source: Custom Source -> Map (2/4)
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1ae4a79a for Source: Custom Source -> Map (4/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) [DEPLOYING].
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@25f2cb23 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4bcb1e9f for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) [DEPLOYING].
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4714bc72 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@69150234 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) [DEPLOYING].
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) [DEPLOYING].
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2f1bf433 for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) [DEPLOYING].
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) [DEPLOYING].
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6925c1ec for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) [DEPLOYING].
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@314b52a7 for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) switched from CREATED to DEPLOYING.
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) [DEPLOYING].
2017-04-11 20:24:47 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@46a4bb41 for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) [DEPLOYING].
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:873 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 20:24:47 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from DEPLOYING to RUNNING.
2017-04-11 20:24:47 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:24:47	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-11 20:24:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 20:24:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 20:24:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 20:24:47 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:47 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 20:24:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 20:24:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 20:24:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 20:24:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 20:24:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 20:24:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 20:24:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 20:24:48 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 20:24:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:48 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 20:24:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 20:24:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 20:24:48 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 20:24:48 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 20:24:48 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 20:24:48 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 20:24:48 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 152, so the initial offset will be set to 151
2017-04-11 20:24:48 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 139, so the initial offset will be set to 138
2017-04-11 20:26:05 INFO  Task:875 - Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) switched from RUNNING to FAILED.
scala.MatchError: Some((2017-04-11,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50).
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (dd4461b82b6ca07e0ec222e9bde0cf50)
2017-04-11 20:26:05 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (4/4) (dd4461b82b6ca07e0ec222e9bde0cf50) switched from RUNNING to FAILED.
scala.MatchError: Some((2017-04-11,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 20:26:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2) switched from state RUNNING to FAILING.
scala.MatchError: Some((2017-04-11,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Flat Map -> Sink: Unnamed(4/4) switched to FAILED 
scala.MatchError: Some((2017-04-11,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-11 20:26:05 INFO  JobSubmissionClientActor:280 - 04/11/2017 20:26:05	Job execution switched to status FAILING.
scala.MatchError: Some((2017-04-11,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b).
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b).
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd).
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b).
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd).
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6).
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Flat Map -> Sink: Unnamed(2/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6).
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd).
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d).
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d).
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6).
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d).
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d).
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185).
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d).
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185).
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8).
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d).
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185).
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8).
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d).
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d).
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8).
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527).
2017-04-11 20:26:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527).
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510).
2017-04-11 20:26:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510).
2017-04-11 20:26:05 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d).
2017-04-11 20:26:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from RUNNING to CANCELING.
2017-04-11 20:26:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d).
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 20:26:05 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d).
2017-04-11 20:26:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510).
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 20:26:05 INFO  TaskManager:128 - Discarding the results produced by task execution dd4461b82b6ca07e0ec222e9bde0cf50
2017-04-11 20:26:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d).
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (16f904506a851bab53c019ed08dff29b)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (427d88ff3d6ae9958da705a9e14a10bd)
2017-04-11 20:26:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527).
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (3188f95af3f88dde25804124aef82da6)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (062ae8d20600b25fc16d96fce240790d)
2017-04-11 20:26:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (ee409555414ecda9e1f5ec65261f3185)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (d5542e08c390561836156a252039766d)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (0174634003ad53d98278a4d90b7a82d8)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (f6b95d24df1b48e44f6ad66e503f5510)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (f7f7a709fd482a13bc80466f933c642d)
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (6f31873b5a02a331a3af2c417fd6b65d)
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (16f904506a851bab53c019ed08dff29b) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (427d88ff3d6ae9958da705a9e14a10bd) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (9870a60d4a699d7153ff45a4e4338527)
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (062ae8d20600b25fc16d96fce240790d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (3188f95af3f88dde25804124aef82da6) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (d5542e08c390561836156a252039766d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ee409555414ecda9e1f5ec65261f3185) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (0174634003ad53d98278a4d90b7a82d8) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f6b95d24df1b48e44f6ad66e503f5510) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (f7f7a709fd482a13bc80466f933c642d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (6f31873b5a02a331a3af2c417fd6b65d) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Flat Map -> Sink: Unnamed(2/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@376db2c3}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (9870a60d4a699d7153ff45a4e4338527) switched from CANCELING to CANCELED.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 20:26:05	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-11 20:26:05 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2) if no longer possible.
2017-04-11 20:26:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2) switched from state FAILING to FAILED.
scala.MatchError: Some((2017-04-11,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:275 - 04/11/2017 20:26:05	Job execution switched to status FAILED.
2017-04-11 20:26:05 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (d303458dd73ec83ab7797f51f9450db2) because the restart strategy prevented it.
scala.MatchError: Some((2017-04-11,1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 20:26:05 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job d303458dd73ec83ab7797f51f9450db2
2017-04-11 20:26:05 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-11 20:26:05 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#1783952701].
2017-04-11 20:26:05 INFO  JobClient:320 - Job execution failed
2017-04-11 20:26:05 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-11 20:26:05 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#-1817780156.
2017-04-11 20:26:05 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-11 20:26:05 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-11 20:26:05 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-11 20:26:05 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:51664
2017-04-11 20:26:05 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-500714ee-2ea6-4029-8245-8ebdef24455b
2017-04-11 20:26:05 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-11 20:26:05 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-11 21:55:04 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-11 21:55:05 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-11 21:55:05 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-11 21:55:05 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-11 21:55:06 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-11 21:55:06 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-eb597dd8-e653-402c-b810-d953142c2500
2017-04-11 21:55:06 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:52491 - max concurrent requests: 50 - max backlog: 1000
2017-04-11 21:55:06 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 21:55:06 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-11 21:55:06 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-11 21:55:06 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-11 21:55:06 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-11 21:55:06 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-83442520] - leader session null
2017-04-11 21:55:06 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-11 21:55:06 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-11 21:55:06 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-11 21:55:06 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-11 21:55:06 INFO  TaskManager:128 - Limiting managed memory to 263 MB, memory will be allocated lazily.
2017-04-11 21:55:06 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-490a1f0d-dd04-4744-b98a-ed611649676d for spill files.
2017-04-11 21:55:06 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 21:55:06 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-238024b8-51aa-43bd-8867-a6a9b032c320
2017-04-11 21:55:06 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-2131124887.
2017-04-11 21:55:06 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='8dc70ef288127c34a25f4c9736f23e5a'} @ localhost (dataPort=-1)
2017-04-11 21:55:06 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-11 21:55:06 INFO  TaskManager:128 - Memory usage stats: [HEAP: 175/935/935 MB, NON HEAP: 124/127/-1 MB (used/committed/max)]
2017-04-11 21:55:06 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-11 21:55:06 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='8dc70ef288127c34a25f4c9736f23e5a'} has started.
2017-04-11 21:55:06 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 6157cd3874ad0542fd353aee69785f54. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-11 21:55:06 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-11 21:55:06 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:52491. Starting BLOB cache.
2017-04-11 21:55:06 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-81972bcc-bf2e-4cd8-95ae-1e18bb8082a6
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: b4f9ecea1370bdee944d84fd29242af9)) but there is no connection to a JobManager yet.
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9).
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-83442520].
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-83442520]
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9) and wait for progress
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-11 21:55:06 INFO  JobManager:128 - Submitting job b4f9ecea1370bdee944d84fd29242af9 (Flink Streaming Job).
2017-04-11 21:55:06 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for b4f9ecea1370bdee944d84fd29242af9.
2017-04-11 21:55:06 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9).
2017-04-11 21:55:06 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:111 - Job b4f9ecea1370bdee944d84fd29242af9 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-11 21:55:06 INFO  JobManager:128 - Scheduling job b4f9ecea1370bdee944d84fd29242af9 (Flink Streaming Job).
2017-04-11 21:55:06 INFO  ExecutionGraph:965 - Job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9) switched from state CREATED to RUNNING.
2017-04-11 21:55:06 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from CREATED to SCHEDULED.
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:275 - 04/11/2017 21:55:06	Job execution switched to status RUNNING.
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:06	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-11 21:55:06 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:06 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-11 21:55:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:06	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) switched from CREATED to SCHEDULED.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:55:07 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@37229b25 for Source: Custom Source -> Map (1/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) [DEPLOYING].
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2de98b0c for Source: Custom Source -> Map (2/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5eff8682 for Source: Custom Source -> Map (3/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) [DEPLOYING].
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@ff2ff6 for Source: Custom Source -> Map (4/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:55:07 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7be8a9b6 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2ceebd5a for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@18be3e3b for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@d0017a7 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3135e030 for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@17fa5c07 for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@549daa25 for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) [DEPLOYING].
2017-04-11 21:55:07 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) switched from CREATED to DEPLOYING.
2017-04-11 21:55:07 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@669c36d5 for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 21:55:07 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) [DEPLOYING].
2017-04-11 21:55:07 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:55:07 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from DEPLOYING to RUNNING.
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:55:07	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-11 21:55:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:08 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:08 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:08 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:08 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:08 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:55:08 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:55:08 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:55:08 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:55:08 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:55:08 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:55:08 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:55:08 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:55:09 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:55:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:09 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:55:09 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:55:09 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:55:09 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:55:09 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:55:09 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 21:55:09 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 21:55:09 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 140, so the initial offset will be set to 139
2017-04-11 21:55:09 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 152, so the initial offset will be set to 151
2017-04-11 21:56:05 INFO  Task:875 - Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) switched from RUNNING to FAILED.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51).
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (73a40a1fa3b4c15dddb001893a467c51)
2017-04-11 21:56:05 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (4/4) (73a40a1fa3b4c15dddb001893a467c51) switched from RUNNING to FAILED.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:56:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9) switched from state RUNNING to FAILING.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Flat Map -> Sink: Unnamed(4/4) switched to FAILED 
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-11 21:56:05 INFO  JobSubmissionClientActor:280 - 04/11/2017 21:56:05	Job execution switched to status FAILING.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39).
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39).
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467).
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467).
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d).
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d).
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Flat Map -> Sink: Unnamed(2/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39).
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9).
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9).
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071).
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071).
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d).
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d).
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba).
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba).
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008).
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008).
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de).
2017-04-11 21:56:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de).
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd).
2017-04-11 21:56:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd).
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d).
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-11 21:56:05 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393).
2017-04-11 21:56:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from RUNNING to CANCELING.
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467).
2017-04-11 21:56:05 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393).
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d).
2017-04-11 21:56:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de).
2017-04-11 21:56:05 INFO  Task:873 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9).
2017-04-11 21:56:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd).
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  TaskManager:128 - Discarding the results produced by task execution 73a40a1fa3b4c15dddb001893a467c51
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008).
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071).
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (c9464671589dea1ebb310b5925cc7f39)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (a1674d270d9dbabaf697d18911300f6d)
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9464671589dea1ebb310b5925cc7f39) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (a1674d270d9dbabaf697d18911300f6d) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 21:56:05 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba).
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (06eb4783b6ff25a1d5deee18203d1008)
2017-04-11 21:56:05 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393).
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (8448bbe0c2bb3c1e5041c515412066ba)
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (b9e4c6b387c11dd2afe215d99b093393)
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (06eb4783b6ff25a1d5deee18203d1008) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 21:56:05 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (f16047a61eeb7281fc683102643dfdfd)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (46f859212685432ae55edb19412e0467)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (ab52fc0522b755f4ed573a490ab449c9)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2884bb85e919492dbd9df1850a296e4d)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (f93ce161a2f07b55ee5949b9ca0f9071)
2017-04-11 21:56:05 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (4f2617a112157576d35f6f494ab575de)
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (b9e4c6b387c11dd2afe215d99b093393) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f16047a61eeb7281fc683102643dfdfd) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (46f859212685432ae55edb19412e0467) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (ab52fc0522b755f4ed573a490ab449c9) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (2884bb85e919492dbd9df1850a296e4d) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8448bbe0c2bb3c1e5041c515412066ba) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (4f2617a112157576d35f6f494ab575de) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (f93ce161a2f07b55ee5949b9ca0f9071) switched from CANCELING to CANCELED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9) if no longer possible.
2017-04-11 21:56:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9) switched from state FAILING to FAILED.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Flat Map -> Sink: Unnamed(2/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:56:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$14$$anon$4@dd2b25ce}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:275 - 04/11/2017 21:56:05	Job execution switched to status FAILED.
2017-04-11 21:56:05 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (b4f9ecea1370bdee944d84fd29242af9) because the restart strategy prevented it.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:56:05 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job b4f9ecea1370bdee944d84fd29242af9
2017-04-11 21:56:05 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-11 21:56:05 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#-83442520].
2017-04-11 21:56:05 INFO  JobClient:320 - Job execution failed
2017-04-11 21:56:05 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-11 21:56:05 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#-2131124887.
2017-04-11 21:56:05 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-11 21:56:05 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-11 21:56:05 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-11 21:56:05 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:52491
2017-04-11 21:56:05 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-490a1f0d-dd04-4744-b98a-ed611649676d
2017-04-11 21:56:05 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-11 21:56:05 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-11 21:57:03 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-11 21:57:04 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-11 21:57:04 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-11 21:57:04 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-11 21:57:05 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-11 21:57:05 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-04c9d1b1-e583-42d7-8471-e627031b03d0
2017-04-11 21:57:05 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:52518 - max concurrent requests: 50 - max backlog: 1000
2017-04-11 21:57:05 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 21:57:05 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-11 21:57:05 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-11 21:57:05 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-11 21:57:05 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-11 21:57:05 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-1622971900] - leader session null
2017-04-11 21:57:05 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-11 21:57:05 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-11 21:57:05 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-11 21:57:05 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-11 21:57:05 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-11 21:57:05 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-10cb132b-e3df-4244-b545-4ed538b019cf for spill files.
2017-04-11 21:57:05 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 21:57:05 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-409bd76b-3afc-4e41-bf89-9b7a7bb8dc68
2017-04-11 21:57:05 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#497420819.
2017-04-11 21:57:05 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='ea4d4c37ed6c054cb0be1f520b421519'} @ localhost (dataPort=-1)
2017-04-11 21:57:05 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-11 21:57:05 INFO  TaskManager:128 - Memory usage stats: [HEAP: 174/903/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-11 21:57:05 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-11 21:57:05 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='ea4d4c37ed6c054cb0be1f520b421519'} has started.
2017-04-11 21:57:05 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 2cae512558328aea28df88ccb102bec0. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-11 21:57:05 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-11 21:57:05 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:52518. Starting BLOB cache.
2017-04-11 21:57:05 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-7bab1963-2bd7-49cd-8460-f0b0d96543ad
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 72bfc349d82efa54b567bc7fd6283691)) but there is no connection to a JobManager yet.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691).
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-1622971900].
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-1622971900]
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691) and wait for progress
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-11 21:57:05 INFO  JobManager:128 - Submitting job 72bfc349d82efa54b567bc7fd6283691 (Flink Streaming Job).
2017-04-11 21:57:05 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 72bfc349d82efa54b567bc7fd6283691.
2017-04-11 21:57:05 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691).
2017-04-11 21:57:05 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-11 21:57:05 INFO  JobManager:128 - Scheduling job 72bfc349d82efa54b567bc7fd6283691 (Flink Streaming Job).
2017-04-11 21:57:05 INFO  ExecutionGraph:965 - Job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691) switched from state CREATED to RUNNING.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:111 - Job 72bfc349d82efa54b567bc7fd6283691 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:275 - 04/11/2017 21:57:05	Job execution switched to status RUNNING.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) switched from CREATED to SCHEDULED.
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-11 21:57:05 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) switched from SCHEDULED to DEPLOYING.
2017-04-11 21:57:05 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-11 21:57:05 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:05	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6c11b48a for Source: Custom Source -> Map (1/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) [DEPLOYING].
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5aedf9bc for Source: Custom Source -> Map (2/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) [DEPLOYING].
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3fc8fae9 for Source: Custom Source -> Map (3/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@22bea6e6 for Source: Custom Source -> Map (4/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5666e9f4 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@67d8e349 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@11decf35 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@60faba0c for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@246ec421 for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:57:06 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-11 21:57:06 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@685fb17c for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) [DEPLOYING].
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@48b75391 for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) [DEPLOYING].
2017-04-11 21:57:06 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 21:57:06 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) switched from CREATED to DEPLOYING.
2017-04-11 21:57:06 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@444576b3 for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 21:57:06 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) [DEPLOYING].
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 21:57:06 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) switched from DEPLOYING to RUNNING.
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:57:06	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-11 21:57:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:06 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:57:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:57:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:57:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:57:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:57:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:57:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:57:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 21:57:07 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 21:57:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:57:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:57:07 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 21:57:07 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 21:57:07 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 21:57:07 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 21:57:07 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 152, so the initial offset will be set to 151
2017-04-11 21:57:07 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 141, so the initial offset will be set to 140
2017-04-11 21:59:35 INFO  Task:875 - Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) switched from RUNNING to FAILED.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b).
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (001e12b58de67ea305d586530273443b)
2017-04-11 21:59:35 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (4/4) (001e12b58de67ea305d586530273443b) switched from RUNNING to FAILED.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Flat Map -> Sink: Unnamed(4/4) switched to FAILED 
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-11 21:59:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691) switched from state RUNNING to FAILING.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:280 - 04/11/2017 21:59:35	Job execution switched to status FAILING.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e).
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e).
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6).
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e).
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6).
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336).
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336).
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Flat Map -> Sink: Unnamed(2/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf).
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf).
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6).
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856).
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336).
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856).
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807).
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807).
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d).
2017-04-11 21:59:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf).
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d).
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c).
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d).
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856).
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807).
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c).
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11).
2017-04-11 21:59:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c).
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11).
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8).
2017-04-11 21:59:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11).
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 21:59:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8).
2017-04-11 21:59:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033).
2017-04-11 21:59:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8).
2017-04-11 21:59:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from RUNNING to CANCELING.
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 21:59:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033).
2017-04-11 21:59:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033).
2017-04-11 21:59:35 INFO  TaskManager:128 - Discarding the results produced by task execution 001e12b58de67ea305d586530273443b
2017-04-11 21:59:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (8a69f5031ae9900a769a09132e30ed6d)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (870be1dbc4449e4b695e595571c1b856)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (2545579616f8d165cb983132692850c6)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (ce046dbbdcee067e3ec19a033efc5336)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (a581fa66e1bca059302b3d2233d31dbf)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (c9d25876e96ca12db4dee04b25c4fd0e)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (c705e1a19596999d81d6f24b2a4fd807)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (d340c98dbb8f7e442c2a64a104a0833c)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (bcf7ec46b584a42cb85e998e67728d11)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (43044397edf2ca6eb21dea4c757becb8)
2017-04-11 21:59:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (52fd8975b9cad661b0f8b8eb99f3a033)
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (8a69f5031ae9900a769a09132e30ed6d) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (870be1dbc4449e4b695e595571c1b856) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (ce046dbbdcee067e3ec19a033efc5336) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (a581fa66e1bca059302b3d2233d31dbf) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (c9d25876e96ca12db4dee04b25c4fd0e) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (2545579616f8d165cb983132692850c6) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (c705e1a19596999d81d6f24b2a4fd807) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (bcf7ec46b584a42cb85e998e67728d11) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (d340c98dbb8f7e442c2a64a104a0833c) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (43044397edf2ca6eb21dea4c757becb8) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (52fd8975b9cad661b0f8b8eb99f3a033) switched from CANCELING to CANCELED.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691) if no longer possible.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691) switched from state FAILING to FAILED.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@8652fbee}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Flat Map -> Sink: Unnamed(2/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 21:59:35	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:275 - 04/11/2017 21:59:35	Job execution switched to status FAILED.
2017-04-11 21:59:35 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (72bfc349d82efa54b567bc7fd6283691) because the restart strategy prevented it.
scala.MatchError: Some(List((2017-04-11,1))) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 21:59:35 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job 72bfc349d82efa54b567bc7fd6283691
2017-04-11 21:59:35 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-11 21:59:35 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#-1622971900].
2017-04-11 21:59:35 INFO  JobClient:320 - Job execution failed
2017-04-11 21:59:35 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-11 21:59:35 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#497420819.
2017-04-11 21:59:35 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-11 21:59:35 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-11 21:59:35 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-10cb132b-e3df-4244-b545-4ed538b019cf
2017-04-11 21:59:35 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-11 21:59:35 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-11 21:59:35 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-11 21:59:35 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:52518
2017-04-11 22:04:19 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-11 22:04:20 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-11 22:04:20 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-11 22:04:21 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-11 22:04:21 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-11 22:04:21 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-235c51d6-d80d-4428-b6d7-f0514e80e837
2017-04-11 22:04:21 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:52614 - max concurrent requests: 50 - max backlog: 1000
2017-04-11 22:04:21 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 22:04:21 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-11 22:04:21 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-11 22:04:22 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-11 22:04:22 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-11 22:04:22 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-11 22:04:22 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-11 22:04:22 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1356790433] - leader session null
2017-04-11 22:04:22 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-11 22:04:22 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-11 22:04:22 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-11 22:04:22 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-04bd8b41-08b8-4c26-b96d-6e928a558cb1 for spill files.
2017-04-11 22:04:22 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 22:04:22 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-51d65f28-117d-424c-868c-f99056edb22a
2017-04-11 22:04:22 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#295500528.
2017-04-11 22:04:22 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='b934476ae5bcf06b655f6c383f278f45'} @ localhost (dataPort=-1)
2017-04-11 22:04:22 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-11 22:04:22 INFO  TaskManager:128 - Memory usage stats: [HEAP: 176/899/910 MB, NON HEAP: 125/129/-1 MB (used/committed/max)]
2017-04-11 22:04:22 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-11 22:04:22 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='b934476ae5bcf06b655f6c383f278f45'} has started.
2017-04-11 22:04:22 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as c4e488376204dfb336957ec248ec0a6c. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-11 22:04:22 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-11 22:04:22 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:52614. Starting BLOB cache.
2017-04-11 22:04:22 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-3de24ed8-6584-4c61-b99a-eb9fb2fbd2cd
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: ed384108a6204ac38579ed58f6f3b9b6)) but there is no connection to a JobManager yet.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (ed384108a6204ac38579ed58f6f3b9b6).
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1356790433].
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1356790433]
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (ed384108a6204ac38579ed58f6f3b9b6) and wait for progress
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-11 22:04:22 INFO  JobManager:128 - Submitting job ed384108a6204ac38579ed58f6f3b9b6 (Flink Streaming Job).
2017-04-11 22:04:22 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for ed384108a6204ac38579ed58f6f3b9b6.
2017-04-11 22:04:22 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (ed384108a6204ac38579ed58f6f3b9b6).
2017-04-11 22:04:22 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:111 - Job ed384108a6204ac38579ed58f6f3b9b6 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-11 22:04:22 INFO  JobManager:128 - Scheduling job ed384108a6204ac38579ed58f6f3b9b6 (Flink Streaming Job).
2017-04-11 22:04:22 INFO  ExecutionGraph:965 - Job Flink Streaming Job (ed384108a6204ac38579ed58f6f3b9b6) switched from state CREATED to RUNNING.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:275 - 04/11/2017 22:04:22	Job execution switched to status RUNNING.
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (6a52b44ba05b90c48bdc3e8cc51d8fb8) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (6a52b44ba05b90c48bdc3e8cc51d8fb8) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (cd63939ccf0d0414a19f3b4be34821cc) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (cd63939ccf0d0414a19f3b4be34821cc) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (37efab2cdb6c2aba4a8b22872017705d) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (37efab2cdb6c2aba4a8b22872017705d) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d3d0b143884107bc8f367ea9636f1034) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d3d0b143884107bc8f367ea9636f1034) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (c374f1ebf6d57a993482ef83a69289b0) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (c374f1ebf6d57a993482ef83a69289b0) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (decac37507e0d9c01abcf2c9d8d0b741) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (decac37507e0d9c01abcf2c9d8d0b741) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (a1760af1035c5d16b8bc3c94f1cc73ee) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (a1760af1035c5d16b8bc3c94f1cc73ee) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c381d0b80d8a58755c869fe029bc99d0) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c381d0b80d8a58755c869fe029bc99d0) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (c184c41f03010c90461e9d6985fcd3ca) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (c184c41f03010c90461e9d6985fcd3ca) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (29ffe4e5aeba4627c937870b413d5095) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (29ffe4e5aeba4627c937870b413d5095) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c1b31862342688ddc6ed539af61bfdc6) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c1b31862342688ddc6ed539af61bfdc6) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (594893d81a93a16f402dfc5a9b8cabfe) switched from CREATED to SCHEDULED.
2017-04-11 22:04:22 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (594893d81a93a16f402dfc5a9b8cabfe) switched from SCHEDULED to DEPLOYING.
2017-04-11 22:04:22 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-11 22:04:22 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:22	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (1/4) (6a52b44ba05b90c48bdc3e8cc51d8fb8) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (2/4) (cd63939ccf0d0414a19f3b4be34821cc) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (3/4) (37efab2cdb6c2aba4a8b22872017705d) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (4/4) (d3d0b143884107bc8f367ea9636f1034) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@504df98e for Source: Custom Source -> Map (4/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (d3d0b143884107bc8f367ea9636f1034) [DEPLOYING].
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3e0df2a2 for Source: Custom Source -> Map (1/4)
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3c674c8e for Source: Custom Source -> Map (2/4)
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@29461c52 for Source: Custom Source -> Map (3/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (cd63939ccf0d0414a19f3b4be34821cc) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (6a52b44ba05b90c48bdc3e8cc51d8fb8) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (37efab2cdb6c2aba4a8b22872017705d) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (6a52b44ba05b90c48bdc3e8cc51d8fb8) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (cd63939ccf0d0414a19f3b4be34821cc) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (37efab2cdb6c2aba4a8b22872017705d) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (d3d0b143884107bc8f367ea9636f1034) [DEPLOYING].
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (c374f1ebf6d57a993482ef83a69289b0) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@13ab77a for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (c374f1ebf6d57a993482ef83a69289b0) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (3/4) (37efab2cdb6c2aba4a8b22872017705d) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (2/4) (cd63939ccf0d0414a19f3b4be34821cc) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (4/4) (d3d0b143884107bc8f367ea9636f1034) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 INFO  Task:873 - Source: Custom Source -> Map (1/4) (6a52b44ba05b90c48bdc3e8cc51d8fb8) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (c374f1ebf6d57a993482ef83a69289b0) [DEPLOYING].
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (c374f1ebf6d57a993482ef83a69289b0) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (decac37507e0d9c01abcf2c9d8d0b741) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1f62c498 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (decac37507e0d9c01abcf2c9d8d0b741) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (decac37507e0d9c01abcf2c9d8d0b741) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (decac37507e0d9c01abcf2c9d8d0b741) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (a1760af1035c5d16b8bc3c94f1cc73ee) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4ddc83df for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (a1760af1035c5d16b8bc3c94f1cc73ee) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (a1760af1035c5d16b8bc3c94f1cc73ee) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (a1760af1035c5d16b8bc3c94f1cc73ee) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c381d0b80d8a58755c869fe029bc99d0) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4df53e1e for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c381d0b80d8a58755c869fe029bc99d0) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c381d0b80d8a58755c869fe029bc99d0) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c381d0b80d8a58755c869fe029bc99d0) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 22:04:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 22:04:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 22:04:22 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-11 22:04:22 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (c184c41f03010c90461e9d6985fcd3ca) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1a024bd1 for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (c184c41f03010c90461e9d6985fcd3ca) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (c184c41f03010c90461e9d6985fcd3ca) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (c184c41f03010c90461e9d6985fcd3ca) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:22 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-11 22:04:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:22 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (29ffe4e5aeba4627c937870b413d5095) switched from CREATED to DEPLOYING.
2017-04-11 22:04:22 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4577a937 for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 22:04:22 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (29ffe4e5aeba4627c937870b413d5095) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (29ffe4e5aeba4627c937870b413d5095) [DEPLOYING].
2017-04-11 22:04:22 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (29ffe4e5aeba4627c937870b413d5095) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:22 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:22 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:22 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:23 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-11 22:04:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c1b31862342688ddc6ed539af61bfdc6) switched from CREATED to DEPLOYING.
2017-04-11 22:04:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3afd7fe1 for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 22:04:23 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (c1b31862342688ddc6ed539af61bfdc6) [DEPLOYING].
2017-04-11 22:04:23 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (c1b31862342688ddc6ed539af61bfdc6) [DEPLOYING].
2017-04-11 22:04:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c1b31862342688ddc6ed539af61bfdc6) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:23 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-11 22:04:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (594893d81a93a16f402dfc5a9b8cabfe) switched from CREATED to DEPLOYING.
2017-04-11 22:04:23 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3779d14e for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 22:04:23 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (594893d81a93a16f402dfc5a9b8cabfe) [DEPLOYING].
2017-04-11 22:04:23 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (594893d81a93a16f402dfc5a9b8cabfe) [DEPLOYING].
2017-04-11 22:04:23 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (594893d81a93a16f402dfc5a9b8cabfe) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 22:04:23 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 22:04:23 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (cd63939ccf0d0414a19f3b4be34821cc) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (d3d0b143884107bc8f367ea9636f1034) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (c374f1ebf6d57a993482ef83a69289b0) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (decac37507e0d9c01abcf2c9d8d0b741) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (a1760af1035c5d16b8bc3c94f1cc73ee) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (c381d0b80d8a58755c869fe029bc99d0) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (c184c41f03010c90461e9d6985fcd3ca) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (29ffe4e5aeba4627c937870b413d5095) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (37efab2cdb6c2aba4a8b22872017705d) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (6a52b44ba05b90c48bdc3e8cc51d8fb8) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (594893d81a93a16f402dfc5a9b8cabfe) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c1b31862342688ddc6ed539af61bfdc6) switched from DEPLOYING to RUNNING.
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@4c1f0129}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  JobSubmissionClientActor:265 - 04/11/2017 22:04:23	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 22:04:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 22:04:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 22:04:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 22:04:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 22:04:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 22:04:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 22:04:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 22:04:23 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 22:04:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 22:04:23 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 22:04:23 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 22:04:23 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 22:04:23 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 22:04:23 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 142, so the initial offset will be set to 141
2017-04-11 22:04:23 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 152, so the initial offset will be set to 151
2017-04-11 22:40:59 WARN  ConsumerCoordinator:476 - Auto offset commit failed for group test: Commit offsets failed with retriable exception. You should retry committing offsets.
2017-04-11 22:41:01 INFO  AbstractCoordinator:542 - Marking the coordinator localhost:9092 (id: 2147482646 rack: null) dead for group test
2017-04-11 22:41:01 INFO  AbstractCoordinator:542 - Marking the coordinator localhost:9092 (id: 2147482646 rack: null) dead for group test
2017-04-11 22:41:01 WARN  ConsumerCoordinator:476 - Auto offset commit failed for group test: Commit offsets failed with retriable exception. You should retry committing offsets.
2017-04-11 22:41:01 WARN  ConsumerCoordinator:476 - Auto offset commit failed for group test: Commit offsets failed with retriable exception. You should retry committing offsets.
2017-04-11 22:41:01 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 22:41:01 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 23:42:25 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-11 23:42:25 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-11 23:42:26 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-11 23:42:26 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-11 23:42:26 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-11 23:42:26 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-46793929-ef1e-45ab-8248-e79c62a58bc1
2017-04-11 23:42:26 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:53799 - max concurrent requests: 50 - max backlog: 1000
2017-04-11 23:42:26 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 23:42:26 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-11 23:42:26 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-11 23:42:26 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-11 23:42:26 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-11 23:42:26 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-11 23:42:26 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-11 23:42:26 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-11 23:42:26 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-346201729] - leader session null
2017-04-11 23:42:26 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-11 23:42:26 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-11 23:42:26 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-89fcaa9a-ebbf-47d3-a07d-5520404d648e for spill files.
2017-04-11 23:42:26 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-11 23:42:26 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-0c1d947f-d44a-43e8-8600-38a4ca147997
2017-04-11 23:42:26 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#1674328905.
2017-04-11 23:42:26 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='8bd82778b0754fe863a6cad7125ad737'} @ localhost (dataPort=-1)
2017-04-11 23:42:26 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-11 23:42:26 INFO  TaskManager:128 - Memory usage stats: [HEAP: 177/889/910 MB, NON HEAP: 124/128/-1 MB (used/committed/max)]
2017-04-11 23:42:26 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-11 23:42:26 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='8bd82778b0754fe863a6cad7125ad737'} has started.
2017-04-11 23:42:26 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as d01982e19d5253c495ac2850578df6b9. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-11 23:42:26 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-11 23:42:26 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:53799. Starting BLOB cache.
2017-04-11 23:42:26 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-5d2174f0-abe5-4f9c-b58f-a686896181b0
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 6a6b6ea2be6387ddea8316aeb6d8120a)) but there is no connection to a JobManager yet.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a).
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-346201729].
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-346201729]
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a) and wait for progress
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-11 23:42:26 INFO  JobManager:128 - Submitting job 6a6b6ea2be6387ddea8316aeb6d8120a (Flink Streaming Job).
2017-04-11 23:42:26 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 6a6b6ea2be6387ddea8316aeb6d8120a.
2017-04-11 23:42:26 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a).
2017-04-11 23:42:26 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:111 - Job 6a6b6ea2be6387ddea8316aeb6d8120a was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-11 23:42:26 INFO  JobManager:128 - Scheduling job 6a6b6ea2be6387ddea8316aeb6d8120a (Flink Streaming Job).
2017-04-11 23:42:26 INFO  ExecutionGraph:965 - Job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a) switched from state CREATED to RUNNING.
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:275 - 04/11/2017 23:42:26	Job execution switched to status RUNNING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) switched from CREATED to SCHEDULED.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-11 23:42:26 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) switched from SCHEDULED to DEPLOYING.
2017-04-11 23:42:26 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:26	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-11 23:42:26 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@58852d6a for Source: Custom Source -> Map (3/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) [DEPLOYING].
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@62deee25 for Source: Custom Source -> Map (1/4)
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@118ce379 for Source: Custom Source -> Map (4/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) [DEPLOYING].
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@62a4c0c8 for Source: Custom Source -> Map (2/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) [DEPLOYING].
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5dc2259 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) [DEPLOYING].
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) [DEPLOYING].
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@654a4485 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) [DEPLOYING].
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@19cf52dd for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) [DEPLOYING].
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@def98d4 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) [DEPLOYING].
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@a2f0035 for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) [DEPLOYING].
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-11 23:42:27 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  Task:873 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@77b0b5bc for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) [DEPLOYING].
2017-04-11 23:42:27 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) [DEPLOYING].
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@46d41d93 for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) switched from CREATED to DEPLOYING.
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7591b3cd for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) [DEPLOYING].
2017-04-11 23:42:27 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-11 23:42:27 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from DEPLOYING to RUNNING.
2017-04-11 23:42:27 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:42:27	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-11 23:42:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 23:42:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 23:42:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 23:42:27 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 23:42:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 23:42:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 23:42:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 23:42:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 23:42:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 23:42:27 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 23:42:27 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 23:42:27 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 23:42:27 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 23:42:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 23:42:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 23:42:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 23:42:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 23:42:28 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-11 23:42:28 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-11 23:42:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:28 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-11 23:42:28 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 23:42:28 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 23:42:28 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-11 23:42:28 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-11 23:42:28 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 23:42:28 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-11 23:42:28 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 142, so the initial offset will be set to 141
2017-04-11 23:42:28 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 153, so the initial offset will be set to 152
2017-04-11 23:43:35 INFO  Task:875 - Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) switched from RUNNING to FAILED.
scala.MatchError: Some(Map(1491946959411.c3d91185-4cf7-4192-8d51-d4d1160f6e3f -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c).
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (b8ebb0f1dd41adfba14fb10253a0a95c)
2017-04-11 23:43:35 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (4/4) (b8ebb0f1dd41adfba14fb10253a0a95c) switched from RUNNING to FAILED.
scala.MatchError: Some(Map(1491946959411.c3d91185-4cf7-4192-8d51-d4d1160f6e3f -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 23:43:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a) switched from state RUNNING to FAILING.
scala.MatchError: Some(Map(1491946959411.c3d91185-4cf7-4192-8d51-d4d1160f6e3f -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Flat Map -> Sink: Unnamed(4/4) switched to FAILED 
scala.MatchError: Some(Map(1491946959411.c3d91185-4cf7-4192-8d51-d4d1160f6e3f -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-11 23:43:35 INFO  JobSubmissionClientActor:280 - 04/11/2017 23:43:35	Job execution switched to status FAILING.
scala.MatchError: Some(Map(1491946959411.c3d91185-4cf7-4192-8d51-d4d1160f6e3f -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9).
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9).
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77).
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77).
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37).
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77).
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9).
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37).
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Flat Map -> Sink: Unnamed(2/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5).
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5).
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e).
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e).
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5).
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37).
2017-04-11 23:43:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5).
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5).
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf).
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5).
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf).
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e).
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf).
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97).
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97).
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71).
2017-04-11 23:43:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97).
2017-04-11 23:43:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71).
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b).
2017-04-11 23:43:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71).
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-11 23:43:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b).
2017-04-11 23:43:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc).
2017-04-11 23:43:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b).
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-11 23:43:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from RUNNING to CANCELING.
2017-04-11 23:43:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc).
2017-04-11 23:43:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc).
2017-04-11 23:43:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-11 23:43:35 INFO  TaskManager:128 - Discarding the results produced by task execution b8ebb0f1dd41adfba14fb10253a0a95c
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (69accb14eb9b322c448e94706ea7ef77)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (995ccb28c965cbe2bab7885c09418eb9)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (cd103cfa074c928cad02879301cc6ee5)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1a7bb78cd1c3b49eb788597e1e17d1e5)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (670e8bc96e0b1fb30eb95b9872be8c37)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4c47f370e0930a51f9e47f5288d8e88e)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (814ce3be3553a99535c09eefc56d5bbf)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (da80d30b7e01385b12a9dd36c66b6f97)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (3b9799f28d073aa1694bc6a9c5c22a71)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (f240df8d28ba439876db0914936aa00b)
2017-04-11 23:43:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (c422985706a742ef7ec565fc6ae972bc)
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (69accb14eb9b322c448e94706ea7ef77) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (995ccb28c965cbe2bab7885c09418eb9) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (cd103cfa074c928cad02879301cc6ee5) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (1a7bb78cd1c3b49eb788597e1e17d1e5) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (4c47f370e0930a51f9e47f5288d8e88e) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (3b9799f28d073aa1694bc6a9c5c22a71) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (f240df8d28ba439876db0914936aa00b) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (c422985706a742ef7ec565fc6ae972bc) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Flat Map -> Sink: Unnamed(2/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (670e8bc96e0b1fb30eb95b9872be8c37) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (da80d30b7e01385b12a9dd36c66b6f97) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (814ce3be3553a99535c09eefc56d5bbf) switched from CANCELING to CANCELED.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a) if no longer possible.
2017-04-11 23:43:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a) switched from state FAILING to FAILED.
scala.MatchError: Some(Map(1491946959411.c3d91185-4cf7-4192-8d51-d4d1160f6e3f -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@b3782dac}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:265 - 04/11/2017 23:43:35	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:275 - 04/11/2017 23:43:35	Job execution switched to status FAILED.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-11 23:43:35 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#-346201729].
2017-04-11 23:43:35 INFO  JobClient:320 - Job execution failed
2017-04-11 23:43:35 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-11 23:43:35 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (6a6b6ea2be6387ddea8316aeb6d8120a) because the restart strategy prevented it.
scala.MatchError: Some(Map(1491946959411.c3d91185-4cf7-4192-8d51-d4d1160f6e3f -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-11 23:43:35 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job 6a6b6ea2be6387ddea8316aeb6d8120a
2017-04-11 23:43:35 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-11 23:43:35 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#1674328905.
2017-04-11 23:43:35 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-11 23:43:35 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-11 23:43:35 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-11 23:43:35 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:53799
2017-04-11 23:43:35 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-89fcaa9a-ebbf-47d3-a07d-5520404d648e
2017-04-11 23:43:35 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-11 23:43:35 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-12 21:37:07 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-12 21:37:09 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-12 21:37:09 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-12 21:37:09 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-12 21:37:10 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-12 21:37:10 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-87137f92-955e-43c1-963d-514b1dd394c7
2017-04-12 21:37:10 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:56422 - max concurrent requests: 50 - max backlog: 1000
2017-04-12 21:37:10 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-12 21:37:10 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-12 21:37:10 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-12 21:37:10 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-12 21:37:10 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-12 21:37:10 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-12 21:37:10 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-12 21:37:10 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#-258003259] - leader session null
2017-04-12 21:37:10 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-12 21:37:10 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-12 21:37:10 INFO  TaskManager:128 - Limiting managed memory to 256 MB, memory will be allocated lazily.
2017-04-12 21:37:10 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-6563fed3-0240-47ee-bbb9-ff3084c8685b for spill files.
2017-04-12 21:37:10 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-12 21:37:10 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-07170b21-e443-4227-a4c6-03add227556a
2017-04-12 21:37:11 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-794693943.
2017-04-12 21:37:11 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='0206915391569f2b10ee6ae12bfd27e7'} @ localhost (dataPort=-1)
2017-04-12 21:37:11 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-12 21:37:11 INFO  TaskManager:128 - Memory usage stats: [HEAP: 170/591/910 MB, NON HEAP: 79/81/-1 MB (used/committed/max)]
2017-04-12 21:37:11 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-12 21:37:11 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='0206915391569f2b10ee6ae12bfd27e7'} has started.
2017-04-12 21:37:11 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 1eb89701b31c1ae2132cd478bc674f69. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-12 21:37:11 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-12 21:37:11 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:56422. Starting BLOB cache.
2017-04-12 21:37:11 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-b83e7def-2d6e-40e8-b567-b74f415183ec
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: acff16e15992f07a5b1c67c4e1740028)) but there is no connection to a JobManager yet.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028).
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#-258003259].
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#-258003259]
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028) and wait for progress
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-12 21:37:11 INFO  JobManager:128 - Submitting job acff16e15992f07a5b1c67c4e1740028 (Flink Streaming Job).
2017-04-12 21:37:11 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for acff16e15992f07a5b1c67c4e1740028.
2017-04-12 21:37:11 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028).
2017-04-12 21:37:11 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:111 - Job acff16e15992f07a5b1c67c4e1740028 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-12 21:37:11 INFO  JobManager:128 - Scheduling job acff16e15992f07a5b1c67c4e1740028 (Flink Streaming Job).
2017-04-12 21:37:11 INFO  ExecutionGraph:965 - Job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028) switched from state CREATED to RUNNING.
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:275 - 04/12/2017 21:37:11	Job execution switched to status RUNNING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) switched from CREATED to SCHEDULED.
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-12 21:37:11 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:37:11 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-12 21:37:11 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:11	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4438e194 for Source: Custom Source -> Map (1/4)
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@5f01ca91 for Source: Custom Source -> Map (3/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) [DEPLOYING].
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6051656d for Source: Custom Source -> Map (2/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) [DEPLOYING].
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@3a7e2fdf for Source: Custom Source -> Map (4/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:11 INFO  Task:873 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:11 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:11 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:11 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:11 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:11 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:11 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:11 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:11 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-12 21:37:11 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6c9f3ef0 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) [DEPLOYING].
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-12 21:37:11 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-12 21:37:11 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2e34d8bd for Flat Map -> Sink: Unnamed (1/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) [DEPLOYING].
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7bee0305 for Flat Map -> Sink: Unnamed (2/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) [DEPLOYING].
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@160318dc for Flat Map -> Sink: Unnamed (4/4)
2017-04-12 21:37:11 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from CREATED to DEPLOYING.
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@57cf1646 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@6726bc53 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) [DEPLOYING].
2017-04-12 21:37:11 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@150d3410 for Flat Map -> Sink: Unnamed (3/4)
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) [DEPLOYING].
2017-04-12 21:37:11 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from CREATED to DEPLOYING.
2017-04-12 21:37:12 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4e4e1743 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-12 21:37:12 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) [DEPLOYING].
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) [DEPLOYING].
2017-04-12 21:37:12 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:37:12 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:37:12 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:37:12 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from DEPLOYING to RUNNING.
2017-04-12 21:37:12 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:37:12 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:37:12	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:12 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:37:12 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:37:12 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:37:12 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:37:12 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:37:12 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:37:12 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:37:12 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:37:12 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:37:12 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:37:12 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:37:12 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:37:13 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:37:13 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:37:13 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:37:13 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:37:13 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:13 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:13 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:13 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:37:13 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:37:13 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:37:13 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:37:13 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:37:13 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-12 21:37:13 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-12 21:37:13 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 143, so the initial offset will be set to 142
2017-04-12 21:37:13 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 153, so the initial offset will be set to 152
2017-04-12 21:40:35 INFO  Task:875 - Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) switched from RUNNING to FAILED.
scala.MatchError: Some(Map(1492025984992.f44e028c-4277-4703-b580-cc92aecbe7e6 -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071).
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (4/4)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state FAILED to JobManager for task Flat Map -> Sink: Unnamed (0d369fe80a0cc504201ded80d2b34071)
2017-04-12 21:40:35 INFO  ExecutionGraph:1027 - Flat Map -> Sink: Unnamed (4/4) (0d369fe80a0cc504201ded80d2b34071) switched from RUNNING to FAILED.
scala.MatchError: Some(Map(1492025984992.f44e028c-4277-4703-b580-cc92aecbe7e6 -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-12 21:40:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028) switched from state RUNNING to FAILING.
scala.MatchError: Some(Map(1492025984992.f44e028c-4277-4703-b580-cc92aecbe7e6 -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Flat Map -> Sink: Unnamed(4/4) switched to FAILED 
scala.MatchError: Some(Map(1492025984992.f44e028c-4277-4703-b580-cc92aecbe7e6 -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)

2017-04-12 21:40:35 INFO  JobSubmissionClientActor:280 - 04/12/2017 21:40:35	Job execution switched to status FAILING.
scala.MatchError: Some(Map(1492025984992.f44e028c-4277-4703-b580-cc92aecbe7e6 -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(1/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78).
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78).
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(2/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(3/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(4/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6).
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6).
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a).
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Flat Map -> Sink: Unnamed(1/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Flat Map -> Sink: Unnamed(2/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Flat Map -> Sink: Unnamed(3/4) switched to CANCELING 
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6).
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a).
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee).
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee).
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e).
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e).
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c).
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c).
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78).
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e).
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e).
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a).
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (2/4)
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce).
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:873 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee).
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce).
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883).
2017-04-12 21:40:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c).
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883).
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e).
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e).
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559).
2017-04-12 21:40:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559).
2017-04-12 21:40:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883).
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (3/4)
2017-04-12 21:40:35 INFO  Task:926 - Attempting to cancel task Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8).
2017-04-12 21:40:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from RUNNING to CANCELING.
2017-04-12 21:40:35 INFO  Task:987 - Triggering cancellation of task code Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8).
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (1/4)
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (1/4)
2017-04-12 21:40:35 INFO  TaskManager:128 - Discarding the results produced by task execution 0d369fe80a0cc504201ded80d2b34071
2017-04-12 21:40:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559).
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-12 21:40:35 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce).
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (ac331e753d7cc2cda143f5f93697beb6)
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (da3aef3ceab7d1e6dd5a889615e76a6a)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (5c6806d1efa0602d052d2d61a8ee6c78)
2017-04-12 21:40:35 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  Task:744 - Freeing task resources for Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8).
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (d6b6e5b06ec90fdd813d274d2d2e1883)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (20efbe5fcced105afad430375edc312e)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1c394b52a7676b37c55754682ed513ce)
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Source: Custom Source -> Map (4/4)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (91756122f9a050bf203a69d74036a57e)
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (3/4)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (bf8b99b39d572bc3f2a9ae5fbe99a22c)
2017-04-12 21:40:35 INFO  FileSystem:121 - Ensuring all FileSystem streams are closed for Flat Map -> Sink: Unnamed (2/4)
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (ac331e753d7cc2cda143f5f93697beb6) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(2/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map (e268f5c288bce091263ee67596dd7aee)
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (da3aef3ceab7d1e6dd5a889615e76a6a) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (5c6806d1efa0602d052d2d61a8ee6c78) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (9507be445621b7711da6c854016c48c8)
2017-04-12 21:40:35 INFO  TaskManager:128 - Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map -> Sink: Unnamed (5fe3d0b068ad7f89de7e0144ea475559)
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(3/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(1/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (91756122f9a050bf203a69d74036a57e) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (d6b6e5b06ec90fdd813d274d2d2e1883) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Flat Map -> Sink: Unnamed(1/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (bf8b99b39d572bc3f2a9ae5fbe99a22c) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (e268f5c288bce091263ee67596dd7aee) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (9507be445621b7711da6c854016c48c8) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (5fe3d0b068ad7f89de7e0144ea475559) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Source: Custom Source -> Map(4/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Flat Map -> Sink: Unnamed(3/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	Flat Map -> Sink: Unnamed(2/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (1c394b52a7676b37c55754682ed513ce) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (20efbe5fcced105afad430375edc312e) switched from CANCELING to CANCELED.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:40:35	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@e15830e7}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to CANCELED 
2017-04-12 21:40:35 INFO  ExecutionGraph:1046 - Try to restart or fail the job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028) if no longer possible.
2017-04-12 21:40:35 INFO  ExecutionGraph:965 - Job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028) switched from state FAILING to FAILED.
scala.MatchError: Some(Map(1492025984992.f44e028c-4277-4703-b580-cc92aecbe7e6 -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:275 - 04/12/2017 21:40:35	Job execution switched to status FAILED.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:322 - Terminate JobClientActor.
2017-04-12 21:40:35 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager Actor[akka://flink/user/jobmanager_1#-258003259].
2017-04-12 21:40:35 INFO  JobClient:320 - Job execution failed
2017-04-12 21:40:35 INFO  FlinkMiniCluster:407 - Stopping FlinkMiniCluster.
2017-04-12 21:40:35 INFO  ExecutionGraph:1067 - Could not restart the job Flink Streaming Job (acff16e15992f07a5b1c67c4e1740028) because the restart strategy prevented it.
scala.MatchError: Some(Map(1492025984992.f44e028c-4277-4703-b580-cc92aecbe7e6 -> 1)) (of class scala.Some)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:60)
	at io.neons.streamer.Application$$anonfun$main$1.apply(Application.scala:58)
	at org.apache.flink.streaming.api.scala.function.StatefulFunction$class.applyWithState(StatefulFunction.scala:41)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.applyWithState(KeyedStream.scala:455)
	at org.apache.flink.streaming.api.scala.KeyedStream$$anon$3.flatMap(KeyedStream.scala:460)
	at org.apache.flink.streaming.api.operators.StreamFlatMap.processElement(StreamFlatMap.java:47)
	at org.apache.flink.streaming.runtime.io.StreamInputProcessor.processInput(StreamInputProcessor.java:185)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask.run(OneInputStreamTask.java:63)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:272)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:655)
	at java.lang.Thread.run(Thread.java:745)
2017-04-12 21:40:35 INFO  CheckpointCoordinator:256 - Stopping checkpoint coordinator for job acff16e15992f07a5b1c67c4e1740028
2017-04-12 21:40:35 INFO  StandaloneCompletedCheckpointStore:89 - Shutting down
2017-04-12 21:40:35 INFO  TaskManager:128 - Stopping TaskManager akka://flink/user/taskmanager_1#-794693943.
2017-04-12 21:40:35 INFO  TaskManager:128 - Disassociating from JobManager
2017-04-12 21:40:35 INFO  BlobCache:227 - Shutting down BlobCache
2017-04-12 21:40:35 INFO  JobManager:128 - Stopping JobManager akka://flink/user/jobmanager_1.
2017-04-12 21:40:35 INFO  IOManager:110 - I/O manager removed spill file directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-6563fed3-0240-47ee-bbb9-ff3084c8685b
2017-04-12 21:40:35 INFO  NetworkEnvironment:298 - Shutting down the network environment and its components.
2017-04-12 21:40:35 INFO  BlobServer:341 - Stopped BLOB server at 0.0.0.0:56422
2017-04-12 21:40:35 INFO  TaskManager:128 - Task manager akka://flink/user/taskmanager_1 is completely shut down.
2017-04-12 21:50:51 INFO  TypeExtractor:1812 - class io.neons.common.log.Log is not a valid POJO type
2017-04-12 21:50:53 INFO  LocalStreamEnvironment:101 - Running job on local embedded Flink mini cluster
2017-04-12 21:50:53 INFO  FlinkMiniCluster:79 - Disabled queryable state server
2017-04-12 21:50:54 INFO  FlinkMiniCluster:313 - Starting FlinkMiniCluster.
2017-04-12 21:50:54 INFO  Slf4jLogger:80 - Slf4jLogger started
2017-04-12 21:50:54 INFO  BlobServer:109 - Created BLOB server storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-6fc2caf0-ed60-438b-aa6e-0c9780f62749
2017-04-12 21:50:54 INFO  BlobServer:187 - Started BLOB server at 0.0.0.0:56608 - max concurrent requests: 50 - max backlog: 1000
2017-04-12 21:50:54 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-12 21:50:55 INFO  MemoryArchivist:128 - Started memory archivist akka://flink/user/archive_1
2017-04-12 21:50:55 INFO  JobManager:128 - Starting JobManager at akka://flink/user/jobmanager_1.
2017-04-12 21:50:55 INFO  StandaloneResourceManager:431 - Trying to associate with JobManager leader akka://flink/user/jobmanager_1
2017-04-12 21:50:55 INFO  TaskManager:128 - Messages between TaskManager and JobManager have a max timeout of 10000 milliseconds
2017-04-12 21:50:55 INFO  TaskManager:128 - Temporary file directory '/var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T': total 111 GB, usable 14 GB (12,61% usable)
2017-04-12 21:50:55 INFO  JobManager:128 - JobManager akka://flink/user/jobmanager_1 was granted leadership with leader session ID None.
2017-04-12 21:50:55 INFO  StandaloneResourceManager:489 - Resource Manager associating with leading JobManager Actor[akka://flink/user/jobmanager_1#1844184462] - leader session null
2017-04-12 21:50:55 INFO  NetworkBufferPool:121 - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
2017-04-12 21:50:55 INFO  NetworkEnvironment:268 - Starting the network environment and its components.
2017-04-12 21:50:55 INFO  TaskManager:128 - Limiting managed memory to 254 MB, memory will be allocated lazily.
2017-04-12 21:50:55 INFO  IOManager:95 - I/O manager uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-io-a746792b-0fbd-45f5-85b6-8004c796df7d for spill files.
2017-04-12 21:50:55 INFO  MetricRegistry:83 - No metrics reporter configured, no metrics will be exposed/reported.
2017-04-12 21:50:55 INFO  FileCache:87 - User file cache uses directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/flink-dist-cache-84e615ed-19b1-4640-8457-2c89dd5b29a0
2017-04-12 21:50:55 INFO  TaskManager:128 - Starting TaskManager actor at akka://flink/user/taskmanager_1#-805530069.
2017-04-12 21:50:55 INFO  TaskManager:128 - TaskManager data connection information: ResourceID{resourceId='7fcc61dc3f962d6b52f554511e76d8fd'} @ localhost (dataPort=-1)
2017-04-12 21:50:55 INFO  TaskManager:128 - TaskManager has 4 task slot(s).
2017-04-12 21:50:55 INFO  TaskManager:128 - Memory usage stats: [HEAP: 173/847/910 MB, NON HEAP: 127/130/-1 MB (used/committed/max)]
2017-04-12 21:50:55 INFO  TaskManager:128 - Trying to register at JobManager akka://flink/user/jobmanager_1 (attempt 1, timeout: 500 milliseconds)
2017-04-12 21:50:55 INFO  StandaloneResourceManager:368 - TaskManager ResourceID{resourceId='7fcc61dc3f962d6b52f554511e76d8fd'} has started.
2017-04-12 21:50:55 INFO  InstanceManager:176 - Registered TaskManager at localhost (akka://flink/user/taskmanager_1) as 8eb742a209bcc33da16c5e2339970597. Current number of registered hosts is 1. Current number of alive task slots is 4.
2017-04-12 21:50:55 INFO  TaskManager:128 - Successful registration at JobManager (akka://flink/user/jobmanager_1), starting network stack and library cache.
2017-04-12 21:50:55 INFO  TaskManager:128 - Determined BLOB server address to be localhost/127.0.0.1:56608. Starting BLOB cache.
2017-04-12 21:50:55 INFO  BlobCache:76 - Created BLOB cache storage directory /var/folders/ss/gn9ylgn520x4_svxjp_dzx5r0000gn/T/blobStore-973b385c-7005-4fe3-b32b-520e904841b3
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:223 - Received SubmitJobAndWait(JobGraph(jobId: 4363626f7ae53d3be85a0bed7ef095a4)) but there is no connection to a JobManager yet.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:91 - Received job Flink Streaming Job (4363626f7ae53d3be85a0bed7ef095a4).
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:302 - Disconnect from JobManager null.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:310 - Connect to JobManager Actor[akka://flink/user/jobmanager_1#1844184462].
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:315 - Connected to new JobManager akka://flink/user/jobmanager_1.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:258 - Connected to JobManager at Actor[akka://flink/user/jobmanager_1#1844184462]
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:137 - Sending message to JobManager akka://flink/user/jobmanager_1 to submit job Flink Streaming Job (4363626f7ae53d3be85a0bed7ef095a4) and wait for progress
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:145 - Upload jar files to job manager akka://flink/user/jobmanager_1.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:163 - Submit job to the job manager akka://flink/user/jobmanager_1.
2017-04-12 21:50:55 INFO  JobManager:128 - Submitting job 4363626f7ae53d3be85a0bed7ef095a4 (Flink Streaming Job).
2017-04-12 21:50:55 INFO  JobManager:128 - Using restart strategy NoRestartStrategy for 4363626f7ae53d3be85a0bed7ef095a4.
2017-04-12 21:50:55 INFO  JobManager:119 - Running initialization on master for job Flink Streaming Job (4363626f7ae53d3be85a0bed7ef095a4).
2017-04-12 21:50:55 INFO  JobManager:141 - Successfully ran initialization on master in 0 ms.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:111 - Job 4363626f7ae53d3be85a0bed7ef095a4 was successfully submitted to the JobManager akka://flink/deadLetters.
2017-04-12 21:50:55 INFO  JobManager:128 - Scheduling job 4363626f7ae53d3be85a0bed7ef095a4 (Flink Streaming Job).
2017-04-12 21:50:55 INFO  ExecutionGraph:965 - Job Flink Streaming Job (4363626f7ae53d3be85a0bed7ef095a4) switched from state CREATED to RUNNING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:275 - 04/12/2017 21:50:55	Job execution switched to status RUNNING.
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d3a9b4fd30ec98e6c9819b2380cf4aa1) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(1/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d3a9b4fd30ec98e6c9819b2380cf4aa1) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(1/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (1/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a1dad7615bd4ee13b0e2bf0ab228e3b7) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(2/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a1dad7615bd4ee13b0e2bf0ab228e3b7) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(2/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (2/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (b8f1b71f5a03b77b36e575c75bc85c67) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(3/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (b8f1b71f5a03b77b36e575c75bc85c67) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(3/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (3/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (7d7badad82adad2bb9ce0e0c8259a5b9) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(4/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (7d7badad82adad2bb9ce0e0c8259a5b9) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Source: Custom Source -> Map(4/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Source: Custom Source -> Map (4/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (fc344127a3fbe1026e0f8dd23fc3d0a2) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (fc344127a3fbe1026e0f8dd23fc3d0a2) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ed3894ca4d05a532e0c9d6d24da99892) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ed3894ca4d05a532e0c9d6d24da99892) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (d30869775db0c2c5e937db0c3a80bde7) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (d30869775db0c2c5e937db0c3a80bde7) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (2b76ae3634f2001650ffe144574a3077) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (2b76ae3634f2001650ffe144574a3077) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (07ab06f6bbc5c2cc34fec7212dafb5c3) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(1/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (07ab06f6bbc5c2cc34fec7212dafb5c3) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(1/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (1/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (8aeba0afab27f754c797d98063350a0b) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(2/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (8aeba0afab27f754c797d98063350a0b) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(2/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (2/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (479f2ad44d01a0dcdf8915d1e2a3dcce) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(3/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (479f2ad44d01a0dcdf8915d1e2a3dcce) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(3/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (3/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (649a7db3438a3d02492fc18b99b658de) switched from CREATED to SCHEDULED.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(4/4) switched to SCHEDULED 
2017-04-12 21:50:55 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (649a7db3438a3d02492fc18b99b658de) switched from SCHEDULED to DEPLOYING.
2017-04-12 21:50:55 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:55	Flat Map -> Sink: Unnamed(4/4) switched to DEPLOYING 
2017-04-12 21:50:55 INFO  ExecutionGraph:354 - Deploying Flat Map -> Sink: Unnamed (4/4) (attempt #0) to localhost
2017-04-12 21:50:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (1/4)
2017-04-12 21:50:55 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d3a9b4fd30ec98e6c9819b2380cf4aa1) switched from CREATED to DEPLOYING.
2017-04-12 21:50:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (2/4)
2017-04-12 21:50:55 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (3/4)
2017-04-12 21:50:55 INFO  Task:873 - Source: Custom Source -> Map (3/4) (b8f1b71f5a03b77b36e575c75bc85c67) switched from CREATED to DEPLOYING.
2017-04-12 21:50:55 INFO  Task:873 - Source: Custom Source -> Map (2/4) (a1dad7615bd4ee13b0e2bf0ab228e3b7) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@14e65d87 for Source: Custom Source -> Map (3/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (3/4) (b8f1b71f5a03b77b36e575c75bc85c67) [DEPLOYING].
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7d415fd0 for Source: Custom Source -> Map (2/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (2/4) (a1dad7615bd4ee13b0e2bf0ab228e3b7) [DEPLOYING].
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@23cc7f70 for Source: Custom Source -> Map (1/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (1/4) (d3a9b4fd30ec98e6c9819b2380cf4aa1) [DEPLOYING].
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task Source: Custom Source -> Map (4/4)
2017-04-12 21:50:56 INFO  Task:873 - Source: Custom Source -> Map (4/4) (7d7badad82adad2bb9ce0e0c8259a5b9) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@7d130b42 for Source: Custom Source -> Map (4/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Source: Custom Source -> Map (4/4) (7d7badad82adad2bb9ce0e0c8259a5b9) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (2/4) (a1dad7615bd4ee13b0e2bf0ab228e3b7) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (1/4) (d3a9b4fd30ec98e6c9819b2380cf4aa1) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (3/4) (b8f1b71f5a03b77b36e575c75bc85c67) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Source: Custom Source -> Map (4/4) (7d7badad82adad2bb9ce0e0c8259a5b9) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - Source: Custom Source -> Map (2/4) (a1dad7615bd4ee13b0e2bf0ab228e3b7) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  Task:873 - Source: Custom Source -> Map (3/4) (b8f1b71f5a03b77b36e575c75bc85c67) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  Task:873 - Source: Custom Source -> Map (4/4) (7d7badad82adad2bb9ce0e0c8259a5b9) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  Task:873 - Source: Custom Source -> Map (1/4) (d3a9b4fd30ec98e6c9819b2380cf4aa1) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (fc344127a3fbe1026e0f8dd23fc3d0a2) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4300ea74 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (fc344127a3fbe1026e0f8dd23fc3d0a2) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (fc344127a3fbe1026e0f8dd23fc3d0a2) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (fc344127a3fbe1026e0f8dd23fc3d0a2) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ed3894ca4d05a532e0c9d6d24da99892) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@4564eee8 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ed3894ca4d05a532e0c9d6d24da99892) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ed3894ca4d05a532e0c9d6d24da99892) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ed3894ca4d05a532e0c9d6d24da99892) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (d30869775db0c2c5e937db0c3a80bde7) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@19b7ffef for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (d30869775db0c2c5e937db0c3a80bde7) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (d30869775db0c2c5e937db0c3a80bde7) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (d30869775db0c2c5e937db0c3a80bde7) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (2b76ae3634f2001650ffe144574a3077) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@48f50ab5 for TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (2b76ae3634f2001650ffe144574a3077) [DEPLOYING].
2017-04-12 21:50:56 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:50:56 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:50:56 INFO  FlinkKafkaConsumerBase:338 - No restore state for FlinkKafkaConsumer.
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (2b76ae3634f2001650ffe144574a3077) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (2b76ae3634f2001650ffe144574a3077) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (1/4)
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (07ab06f6bbc5c2cc34fec7212dafb5c3) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@2400f711 for Flat Map -> Sink: Unnamed (1/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (1/4) (07ab06f6bbc5c2cc34fec7212dafb5c3) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (1/4) (07ab06f6bbc5c2cc34fec7212dafb5c3) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (1/4) (07ab06f6bbc5c2cc34fec7212dafb5c3) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (2/4)
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (8aeba0afab27f754c797d98063350a0b) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@36dc9673 for Flat Map -> Sink: Unnamed (2/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (2/4) (8aeba0afab27f754c797d98063350a0b) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (2/4) (8aeba0afab27f754c797d98063350a0b) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (2/4) (8aeba0afab27f754c797d98063350a0b) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (3/4)
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (479f2ad44d01a0dcdf8915d1e2a3dcce) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@1fcc626b for Flat Map -> Sink: Unnamed (3/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (3/4) (479f2ad44d01a0dcdf8915d1e2a3dcce) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (3/4) (479f2ad44d01a0dcdf8915d1e2a3dcce) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (3/4) (479f2ad44d01a0dcdf8915d1e2a3dcce) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  TaskManager:128 - Received task Flat Map -> Sink: Unnamed (4/4)
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (649a7db3438a3d02492fc18b99b658de) switched from CREATED to DEPLOYING.
2017-04-12 21:50:56 INFO  FileSystem:110 - Created new CloseableRegistry org.apache.flink.core.fs.SafetyNetCloseableRegistry@24dfab0 for Flat Map -> Sink: Unnamed (4/4)
2017-04-12 21:50:56 INFO  Task:546 - Loading JAR files for task Flat Map -> Sink: Unnamed (4/4) (649a7db3438a3d02492fc18b99b658de) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:575 - Registering task at network: Flat Map -> Sink: Unnamed (4/4) (649a7db3438a3d02492fc18b99b658de) [DEPLOYING].
2017-04-12 21:50:56 INFO  Task:873 - Flat Map -> Sink: Unnamed (4/4) (649a7db3438a3d02492fc18b99b658de) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 WARN  StreamTask:708 - No state backend has been specified, using default state backend (Memory / JobManager)
2017-04-12 21:50:56 INFO  StreamTask:714 - State backend is set to heap memory (checkpoint to jobmanager)
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (2/4) (a1dad7615bd4ee13b0e2bf0ab228e3b7) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (3/4) (b8f1b71f5a03b77b36e575c75bc85c67) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Source: Custom Source -> Map(2/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Source: Custom Source -> Map(3/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (4/4) (7d7badad82adad2bb9ce0e0c8259a5b9) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (1/4) (fc344127a3fbe1026e0f8dd23fc3d0a2) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (2/4) (ed3894ca4d05a532e0c9d6d24da99892) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (3/4) (d30869775db0c2c5e937db0c3a80bde7) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map) (4/4) (2b76ae3634f2001650ffe144574a3077) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (3/4) (479f2ad44d01a0dcdf8915d1e2a3dcce) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (4/4) (649a7db3438a3d02492fc18b99b658de) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Source: Custom Source -> Map(4/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(1/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(2/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Source: Custom Source -> Map (1/4) (d3a9b4fd30ec98e6c9819b2380cf4aa1) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(3/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (2/4) (8aeba0afab27f754c797d98063350a0b) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  ExecutionGraph:1025 - Flat Map -> Sink: Unnamed (1/4) (07ab06f6bbc5c2cc34fec7212dafb5c3) switched from DEPLOYING to RUNNING.
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	TriggerWindow(EventTimeSessionWindows(1800000), ListStateDescriptor{serializer=io.neons.streamer.Application$$anon$15$$anon$4@901d6450}, ContinuousEventTimeTrigger(30000), WindowedStream.apply(WindowedStream.scala:316)) -> (Sink: Unnamed, Map)(4/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Flat Map -> Sink: Unnamed(3/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Flat Map -> Sink: Unnamed(4/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Source: Custom Source -> Map(1/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Flat Map -> Sink: Unnamed(2/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  JobSubmissionClientActor:265 - 04/12/2017 21:50:56	Flat Map -> Sink: Unnamed(1/4) switched to RUNNING 
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  HeapKeyedStateBackend:101 - Initializing heap keyed state backend with stream factory.
2017-04-12 21:50:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:56 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-2
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-1
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-4
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-3
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:50:57 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:50:57 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:50:57 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:50:57 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:50:57 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:50:57 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:50:57 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:222 - Got 2 partitions from these topics: [neons_logs]
2017-04-12 21:50:57 INFO  FlinkKafkaConsumer09:570 - Consumer is going to read the following topics (with number of partitions): neons_logs (2), 
2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = 
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-6
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  ConsumerConfig:178 - ConsumerConfig values: 
	metric.reporters = []
	metadata.max.age.ms = 300000
	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
	reconnect.backoff.ms = 50
	sasl.kerberos.ticket.renew.window.factor = 0.8
	max.partition.fetch.bytes = 1048576
	bootstrap.servers = [localhost:9092]
	ssl.keystore.type = JKS
	enable.auto.commit = true
	sasl.mechanism = GSSAPI
	interceptor.classes = null
	exclude.internal.topics = true
	ssl.truststore.password = null
	client.id = consumer-5
	ssl.endpoint.identification.algorithm = null
	max.poll.records = 2147483647
	check.crcs = true
	request.timeout.ms = 40000
	heartbeat.interval.ms = 3000
	auto.commit.interval.ms = 5000
	receive.buffer.bytes = 65536
	ssl.truststore.type = JKS
	ssl.truststore.location = null
	ssl.keystore.password = null
	fetch.min.bytes = 1
	send.buffer.bytes = 131072
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	group.id = test
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	ssl.trustmanager.algorithm = PKIX
	ssl.key.password = null
	fetch.max.wait.ms = 500
	sasl.kerberos.min.time.before.relogin = 60000
	connections.max.idle.ms = 540000
	session.timeout.ms = 30000
	metrics.num.samples = 2
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	ssl.protocol = TLS
	ssl.provider = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.keystore.location = null
	ssl.cipher.suites = null
	security.protocol = PLAINTEXT
	ssl.keymanager.algorithm = SunX509
	metrics.sample.window.ms = 30000
	auto.offset.reset = latest

2017-04-12 21:50:57 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:50:57 INFO  AppInfoParser:83 - Kafka version : 0.10.0.1
2017-04-12 21:50:57 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:50:57 INFO  AppInfoParser:84 - Kafka commitId : a7a17cdec9eaa6c5
2017-04-12 21:50:57 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-12 21:50:57 INFO  AbstractCoordinator:505 - Discovered coordinator localhost:9092 (id: 2147482646 rack: null) for group test.
2017-04-12 21:50:57 INFO  Kafka09Fetcher:190 - Partition neons_logs-1 has no initial offset; the consumer has position 154, so the initial offset will be set to 153
2017-04-12 21:50:57 INFO  Kafka09Fetcher:190 - Partition neons_logs-0 has no initial offset; the consumer has position 143, so the initial offset will be set to 142
